{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "versions = ['v06', 'v09', 'v10', 'v11']\n",
    "version = None  #'xg boost'\n",
    "#version = 'all'\n",
    "original_version = version\n",
    "h = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T00:00:52.632296Z",
     "iopub.status.busy": "2022-12-14T00:00:52.631912Z",
     "iopub.status.idle": "2022-12-14T00:00:53.255004Z",
     "shell.execute_reply": "2022-12-14T00:00:53.254157Z",
     "shell.execute_reply.started": "2022-12-14T00:00:52.632223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4: v11\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                   best score  best time  \\\nxg boost (v11) rs                                    0.721019        NaN   \ncatboost (v11)                                       0.689818      12.81   \nxg boost (tree) (v11)                                0.603614  14.210391   \nneural network m15 mega + dropout (v11)                0.5707    1191.61   \nneural network - random search [i64,norm,d64^6,...   0.533579        NaN   \nneural network with autoencoding m15 mega + dro...   0.488747    1276.23   \nxg boost (v11)                                       0.484341   1.663234   \nxg boost (linear) (v11)                              0.484341  12.681655   \nlinear regression (ridge) (v11)                      0.484311     0.2412   \nknn (v11)                                            0.465113   0.618877   \n\n                                                   Mean Absolute Error Accuracy  \\\nxg boost (v11) rs                                                  42603.011667   \ncatboost (v11)                                                      70705.72771   \nxg boost (tree) (v11)                                              52330.434568   \nneural network m15 mega + dropout (v11)                            53709.702226   \nneural network - random search [i64,norm,d64^6,...                 57201.738174   \nneural network with autoencoding m15 mega + dro...                 58773.731907   \nxg boost (v11)                                                     61556.686774   \nxg boost (linear) (v11)                                            62224.321741   \nlinear regression (ridge) (v11)                                    61567.465046   \nknn (v11)                                                          62944.705459   \n\n                                                   Mean Squared Error Accuracy  \\\nxg boost (v11) rs                                            3151478137.618505   \ncatboost (v11)                                               7672277461.395934   \nxg boost (tree) (v11)                                        4477737747.935365   \nneural network m15 mega + dropout (v11)                      4849542517.605685   \nneural network - random search [i64,norm,d64^6,...           5268876368.550115   \nneural network with autoencoding m15 mega + dro...           5775319278.568146   \nxg boost (v11)                                               5825092993.841407   \nxg boost (linear) (v11)                                      5901034500.694016   \nlinear regression (ridge) (v11)                              5825535717.872867   \nknn (v11)                                                    6042299808.369307   \n\n                                                   R square Accuracy  \\\nxg boost (v11) rs                                           0.721019   \ncatboost (v11)                                              0.320821   \nxg boost (tree) (v11)                                       0.603614   \nneural network m15 mega + dropout (v11)                       0.5707   \nneural network - random search [i64,norm,d64^6,...          0.533579   \nneural network with autoencoding m15 mega + dro...          0.488747   \nxg boost (v11)                                              0.484341   \nxg boost (linear) (v11)                                     0.477618   \nlinear regression (ridge) (v11)                             0.484302   \nknn (v11)                                                   0.465113   \n\n                                                   Root Mean Squared Error  \\\nxg boost (v11) rs                                             56138.027554   \ncatboost (v11)                                                87591.537613   \nxg boost (tree) (v11)                                         66915.900561   \nneural network m15 mega + dropout (v11)                       69638.656776   \nneural network - random search [i64,norm,d64^6,...            72587.026172   \nneural network with autoencoding m15 mega + dro...            75995.521438   \nxg boost (v11)                                                76322.296833   \nxg boost (linear) (v11)                                       76818.191209   \nlinear regression (ridge) (v11)                               76325.197136   \nknn (v11)                                                     77732.231464   \n\n                                                                 best run date  \\\nxg boost (v11) rs                                                          NaN   \ncatboost (v11)                                      2022-11-30 16:14:29.405177   \nxg boost (tree) (v11)                               2022-11-30 20:18:59.876471   \nneural network m15 mega + dropout (v11)             2022-12-21 02:55:33.483148   \nneural network - random search [i64,norm,d64^6,...                         NaN   \nneural network with autoencoding m15 mega + dro...  2022-12-22 19:06:48.049482   \nxg boost (v11)                                      2022-11-30 16:55:55.436173   \nxg boost (linear) (v11)                             2022-11-30 19:47:04.498556   \nlinear regression (ridge) (v11)                     2023-01-01 10:07:22.564855   \nknn (v11)                                           2022-11-30 16:20:53.948815   \n\n                                                                                          best method  \\\nxg boost (v11) rs                                                                                 NaN   \ncatboost (v11)                                                              random search(no dummies)   \nxg boost (tree) (v11)                                                                   random search   \nneural network m15 mega + dropout (v11)             loss=4.43e+04 valloss=5.35e+04 +valsplit=0.1 +...   \nneural network - random search [i64,norm,d64^6,...                                                NaN   \nneural network with autoencoding m15 mega + dro...  loss=5.27e+04 valloss=5.91e+04 +valsplit=0.1 +...   \nxg boost (v11)                                                                          random search   \nxg boost (linear) (v11)                                                                 random search   \nlinear regression (ridge) (v11)                                        random search(pca,1.0% retain)   \nknn (v11)                                                                               random search   \n\n                                                   best is shared  suboptimal  \nxg boost (v11) rs                                             NaN     pending  \ncatboost (v11)                                              False  suboptimal  \nxg boost (tree) (v11)                                       False     pending  \nneural network m15 mega + dropout (v11)                     False     pending  \nneural network - random search [i64,norm,d64^6,...            NaN     pending  \nneural network with autoencoding m15 mega + dro...          False     pending  \nxg boost (v11)                                              False     pending  \nxg boost (linear) (v11)                                     False  suboptimal  \nlinear regression (ridge) (v11)                             False  suboptimal  \nknn (v11)                                                   False     pending  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best score</th>\n      <th>best time</th>\n      <th>Mean Absolute Error Accuracy</th>\n      <th>Mean Squared Error Accuracy</th>\n      <th>R square Accuracy</th>\n      <th>Root Mean Squared Error</th>\n      <th>best run date</th>\n      <th>best method</th>\n      <th>best is shared</th>\n      <th>suboptimal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>xg boost (v11) rs</th>\n      <td>0.721019</td>\n      <td>NaN</td>\n      <td>42603.011667</td>\n      <td>3151478137.618505</td>\n      <td>0.721019</td>\n      <td>56138.027554</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>catboost (v11)</th>\n      <td>0.689818</td>\n      <td>12.81</td>\n      <td>70705.72771</td>\n      <td>7672277461.395934</td>\n      <td>0.320821</td>\n      <td>87591.537613</td>\n      <td>2022-11-30 16:14:29.405177</td>\n      <td>random search(no dummies)</td>\n      <td>False</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>xg boost (tree) (v11)</th>\n      <td>0.603614</td>\n      <td>14.210391</td>\n      <td>52330.434568</td>\n      <td>4477737747.935365</td>\n      <td>0.603614</td>\n      <td>66915.900561</td>\n      <td>2022-11-30 20:18:59.876471</td>\n      <td>random search</td>\n      <td>False</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>neural network m15 mega + dropout (v11)</th>\n      <td>0.5707</td>\n      <td>1191.61</td>\n      <td>53709.702226</td>\n      <td>4849542517.605685</td>\n      <td>0.5707</td>\n      <td>69638.656776</td>\n      <td>2022-12-21 02:55:33.483148</td>\n      <td>loss=4.43e+04 valloss=5.35e+04 +valsplit=0.1 +...</td>\n      <td>False</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>neural network - random search [i64,norm,d64^6,d1] (v11)</th>\n      <td>0.533579</td>\n      <td>NaN</td>\n      <td>57201.738174</td>\n      <td>5268876368.550115</td>\n      <td>0.533579</td>\n      <td>72587.026172</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>neural network with autoencoding m15 mega + dropout (v11)</th>\n      <td>0.488747</td>\n      <td>1276.23</td>\n      <td>58773.731907</td>\n      <td>5775319278.568146</td>\n      <td>0.488747</td>\n      <td>75995.521438</td>\n      <td>2022-12-22 19:06:48.049482</td>\n      <td>loss=5.27e+04 valloss=5.91e+04 +valsplit=0.1 +...</td>\n      <td>False</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>xg boost (v11)</th>\n      <td>0.484341</td>\n      <td>1.663234</td>\n      <td>61556.686774</td>\n      <td>5825092993.841407</td>\n      <td>0.484341</td>\n      <td>76322.296833</td>\n      <td>2022-11-30 16:55:55.436173</td>\n      <td>random search</td>\n      <td>False</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>xg boost (linear) (v11)</th>\n      <td>0.484341</td>\n      <td>12.681655</td>\n      <td>62224.321741</td>\n      <td>5901034500.694016</td>\n      <td>0.477618</td>\n      <td>76818.191209</td>\n      <td>2022-11-30 19:47:04.498556</td>\n      <td>random search</td>\n      <td>False</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v11)</th>\n      <td>0.484311</td>\n      <td>0.2412</td>\n      <td>61567.465046</td>\n      <td>5825535717.872867</td>\n      <td>0.484302</td>\n      <td>76325.197136</td>\n      <td>2023-01-01 10:07:22.564855</td>\n      <td>random search(pca,1.0% retain)</td>\n      <td>False</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>knn (v11)</th>\n      <td>0.465113</td>\n      <td>0.618877</td>\n      <td>62944.705459</td>\n      <td>6042299808.369307</td>\n      <td>0.465113</td>\n      <td>77732.231464</td>\n      <td>2022-11-30 16:20:53.948815</td>\n      <td>random search</td>\n      <td>False</td>\n      <td>pending</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if not original_version:\n",
    "    version = versions[h]\n",
    "    print(f'{h + 1}/{len(versions)}: {version}')\n",
    "    h = (h + 1) % len(versions)\n",
    "\n",
    "dff = pd.read_json('results.json')\n",
    "\n",
    "vNN_columns = dff.columns if version == 'all' else [c for c in dff.columns if version in c]\n",
    "\n",
    "dataset_versions_df = dff[vNN_columns].T.sort_values(\"best score\", ascending=False)\n",
    "dataset_versions_df_summary = dataset_versions_df[\n",
    "    ['best score', 'best time', 'Mean Absolute Error Accuracy', 'Mean Squared Error Accuracy', 'R square Accuracy',\n",
    "     'Root Mean Squared Error', 'best run date', 'best method', 'best is shared', \"suboptimal\"]]\n",
    "dataset_versions_df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T17:58:27.432682Z",
     "iopub.status.busy": "2022-12-11T17:58:27.432324Z",
     "iopub.status.idle": "2022-12-11T17:58:27.457488Z",
     "shell.execute_reply": "2022-12-11T17:58:27.455698Z",
     "shell.execute_reply.started": "2022-12-11T17:58:27.432654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   Mean Absolute Error Accuracy  \\\nxg boost (tree) (v09)                                              42675.746856   \nxg boost (v09)                                                     51922.608639   \ncatboost (v09)                                                     74210.938931   \nrandom forest (v09)                                                46294.554857   \nknn (v09)                                                          48389.098294   \nneural network m15 mega + dropout (v09)                     212534587876.077087   \ndecision tree (v09)                                                51319.080582   \nneural network m14 mega (v09)                                      51080.541252   \nneural network m13 mega (v09)                                      50938.566359   \nneural network m11 mega (v09)                                       53873.03808   \nneural network m12 mega (v09)                                      54695.968258   \nneural network m05 rec deep (v09)                                  56357.458454   \nneural network m02 two layers (v09)                                 59659.87364   \nneural network m04 3 layers+wider (v09)                            60774.606195   \nneural network m01 simple (v09)                                    71376.935786   \nlinear regression (ridge) (v09)                                    75320.739699   \nneural network m03 2 layers+wider (v09)                            64123.564083   \nneural network with autoencoding m15 mega + dro...                 64379.512251   \n\n                                                   Mean Squared Error Accuracy  \\\nxg boost (tree) (v09)                                         3147715326.58041   \nxg boost (v09)                                               4355546020.138196   \ncatboost (v09)                                               8569097506.139938   \nrandom forest (v09)                                          3613817488.991202   \nknn (v09)                                                    4157374530.888747   \nneural network m15 mega + dropout (v09)              47995052450841435832320.0   \ndecision tree (v09)                                          4315241833.852664   \nneural network m14 mega (v09)                                4395484312.865142   \nneural network m13 mega (v09)                                4437747297.256148   \nneural network m11 mega (v09)                                4663875436.065661   \nneural network m12 mega (v09)                                4835177161.720935   \nneural network m05 rec deep (v09)                             5015665639.26466   \nneural network m02 two layers (v09)                          5504782893.089812   \nneural network m04 3 layers+wider (v09)                       5662801657.51863   \nneural network m01 simple (v09)                               7550556480.57456   \nlinear regression (ridge) (v09)                              8376872406.903015   \nneural network m03 2 layers+wider (v09)                      6242932923.632053   \nneural network with autoencoding m15 mega + dro...           6474086836.603735   \n\n                                                   R square Accuracy  \\\nxg boost (tree) (v09)                                       0.721352   \nxg boost (v09)                                              0.614431   \ncatboost (v09)                                              0.241431   \nrandom forest (v09)                                         0.680091   \nknn (v09)                                                   0.631974   \nneural network m15 mega + dropout (v09)                   -15.994805   \ndecision tree (v09)                                         0.617999   \nneural network m14 mega (v09)                               0.610895   \nneural network m13 mega (v09)                               0.607154   \nneural network m11 mega (v09)                               0.587136   \nneural network m12 mega (v09)                               0.571972   \nneural network m05 rec deep (v09)                           0.555995   \nneural network m02 two layers (v09)                         0.512696   \nneural network m04 3 layers+wider (v09)                     0.498708   \nneural network m01 simple (v09)                             0.331597   \nlinear regression (ridge) (v09)                             0.258448   \nneural network m03 2 layers+wider (v09)                     0.447352   \nneural network with autoencoding m15 mega + dro...           0.42689   \n\n                                                   Root Mean Squared Error  \\\nxg boost (tree) (v09)                                         56104.503621   \nxg boost (v09)                                                65996.560669   \ncatboost (v09)                                                 92569.41993   \nrandom forest (v09)                                           60115.035465   \nknn (v09)                                                     64477.705689   \nneural network m15 mega + dropout (v09)                219077731526.600952   \ndecision tree (v09)                                           65690.500332   \nneural network m14 mega (v09)                                 66298.448797   \nneural network m13 mega (v09)                                 66616.419127   \nneural network m11 mega (v09)                                 68292.572335   \nneural network m12 mega (v09)                                 69535.438172   \nneural network m05 rec deep (v09)                             70821.364286   \nneural network m02 two layers (v09)                           74194.224122   \nneural network m04 3 layers+wider (v09)                        75251.58907   \nneural network m01 simple (v09)                               86893.938112   \nlinear regression (ridge) (v09)                               91525.255569   \nneural network m03 2 layers+wider (v09)                       79012.232747   \nneural network with autoencoding m15 mega + dro...            80461.710376   \n\n                                                                                              _method  \\\nxg boost (tree) (v09)                                                                   random search   \nxg boost (v09)                                                                          random search   \ncatboost (v09)                                                                     random search(pca)   \nrandom forest (v09)                                                                     random search   \nknn (v09)                                                                               random search   \nneural network m15 mega + dropout (v09)             loss=8.53e-02 valloss=9.72e-02 +valsplit=0.1 +...   \ndecision tree (v09)                                                                     random search   \nneural network m14 mega (v09)                       loss=4.68e+04 valloss=5.01e+04 +valsplit=0.1 +...   \nneural network m13 mega (v09)                       loss=4.55e+04 valloss=5.03e+04 +valsplit=0.1 +...   \nneural network m11 mega (v09)                       loss=4.26e+09 valloss=4.72e+09 +valsplit=0.1 +...   \nneural network m12 mega (v09)                       loss=4.76e+09 valloss=4.77e+09 +valsplit=0.1 +...   \nneural network m05 rec deep (v09)                   loss=5.10e+09 valloss=5.01e+09 +valsplit=0.1 +...   \nneural network m02 two layers (v09)                 loss=5.64e+09 valloss=5.60e+09 +valsplit=0.1 +...   \nneural network m04 3 layers+wider (v09)             loss=5.80e+09 valloss=5.76e+09 +valsplit=0.1 +...   \nneural network m01 simple (v09)                     loss=7.75e+09 valloss=7.68e+09 +valsplit=0.1 +...   \nlinear regression (ridge) (v09)                                        random search(pca,0.5% retain)   \nneural network m03 2 layers+wider (v09)             loss=6.44e+09 valloss=6.46e+09 +valsplit=0.1 +...   \nneural network with autoencoding m15 mega + dro...  loss=6.51e+04 valloss=6.52e+04 +valsplit=0.1 +...   \n\n                                                                                              _params  \\\nxg boost (tree) (v09)                               {'model__booster': 'dart', 'model__colsample_b...   \nxg boost (v09)                                      {'model__booster': 'dart', 'model__early_stopp...   \ncatboost (v09)                                      {'depth': 9, 'l2_leaf_reg': 1, 'learning_rate'...   \nrandom forest (v09)                                 {'model__bootstrap': True, 'model__ccp_alpha':...   \nknn (v09)                                           {'model__algorithm': 'ball_tree', 'model__leaf...   \nneural network m15 mega + dropout (v09)                                 mae +epochs=400 +learn=0.0003   \ndecision tree (v09)                                 {'model__ccp_alpha': 0.05, 'model__criterion':...   \nneural network m14 mega (v09)                                           mae +epochs=400 +learn=0.0003   \nneural network m13 mega (v09)                                           mae +epochs=400 +learn=0.0003   \nneural network m11 mega (v09)                                           mse +epochs=400 +learn=0.0003   \nneural network m12 mega (v09)                                           mse +epochs=400 +learn=0.0003   \nneural network m05 rec deep (v09)                                       mse +epochs=500 +learn=0.0003   \nneural network m02 two layers (v09)                                      mse +epochs=500 +learn=0.003   \nneural network m04 3 layers+wider (v09)                                  mse +epochs=500 +learn=0.003   \nneural network m01 simple (v09)                                           mse +epochs=50 +learn=0.003   \nlinear regression (ridge) (v09)                     {'model__alpha': 1e-05, 'model__copy_X': False...   \nneural network m03 2 layers+wider (v09)                                 mse +epochs=500 +learn=0.0003   \nneural network with autoencoding m15 mega + dro...                      mae +epochs=400 +learn=0.0003   \n\n                                                       _score  _train time  \\\nxg boost (tree) (v09)                                0.721352   179.820912   \nxg boost (v09)                                       0.614431    21.169572   \ncatboost (v09)                                       0.241431          999   \nrandom forest (v09)                                  0.680091  1127.317849   \nknn (v09)                                            0.631974     0.053487   \nneural network m15 mega + dropout (v09)            -15.994805      1005.59   \ndecision tree (v09)                                  0.617999     0.325321   \nneural network m14 mega (v09)                        0.610895      2179.86   \nneural network m13 mega (v09)                        0.607154       500.16   \nneural network m11 mega (v09)                        0.587136       994.87   \nneural network m12 mega (v09)                        0.571972        848.7   \nneural network m05 rec deep (v09)                    0.555995      1418.24   \nneural network m02 two layers (v09)                  0.512696       822.12   \nneural network m04 3 layers+wider (v09)              0.498708       781.31   \nneural network m01 simple (v09)                      0.331597       162.26   \nlinear regression (ridge) (v09)                      0.258448     0.087033   \nneural network m03 2 layers+wider (v09)              0.447352      1404.21   \nneural network with autoencoding m15 mega + dro...    0.42689      1641.39   \n\n                                                   best is shared  \\\nxg boost (tree) (v09)                                       False   \nxg boost (v09)                                              False   \ncatboost (v09)                                              False   \nrandom forest (v09)                                         False   \nknn (v09)                                                   False   \nneural network m15 mega + dropout (v09)                     False   \ndecision tree (v09)                                         False   \nneural network m14 mega (v09)                               False   \nneural network m13 mega (v09)                               False   \nneural network m11 mega (v09)                               False   \nneural network m12 mega (v09)                               False   \nneural network m05 rec deep (v09)                           False   \nneural network m02 two layers (v09)                         False   \nneural network m04 3 layers+wider (v09)                     False   \nneural network m01 simple (v09)                             False   \nlinear regression (ridge) (v09)                             False   \nneural network m03 2 layers+wider (v09)                     False   \nneural network with autoencoding m15 mega + dro...          False   \n\n                                                                                          best method  \\\nxg boost (tree) (v09)                                                                   random search   \nxg boost (v09)                                                                          random search   \ncatboost (v09)                                                              random search(no dummies)   \nrandom forest (v09)                                                                     random search   \nknn (v09)                                                                               random search   \nneural network m15 mega + dropout (v09)             loss=4.38e+04 valloss=4.85e+04 +valsplit=0.1 +...   \ndecision tree (v09)                                                                     random search   \nneural network m14 mega (v09)                       loss=4.68e+04 valloss=5.01e+04 +valsplit=0.1 +...   \nneural network m13 mega (v09)                       loss=4.55e+04 valloss=5.03e+04 +valsplit=0.1 +...   \nneural network m11 mega (v09)                       loss=4.26e+09 valloss=4.72e+09 +valsplit=0.1 +...   \nneural network m12 mega (v09)                       loss=4.76e+09 valloss=4.77e+09 +valsplit=0.1 +...   \nneural network m05 rec deep (v09)                   loss=4.87e+09 valloss=4.84e+09 +valsplit=0.1 +...   \nneural network m02 two layers (v09)                 loss=5424.62 valloss=5263.41 +valsplit=0.1 sto...   \nneural network m04 3 layers+wider (v09)             loss=5.20e+09 valloss=5.09e+09 +valsplit=0.1 +...   \nneural network m01 simple (v09)                     loss=5724.92 valloss=5608.12 +valsplit=0.1 sto...   \nlinear regression (ridge) (v09)                                                    random search(pca)   \nneural network m03 2 layers+wider (v09)             loss=6.38e+09 valloss=6.41e+09 +valsplit=0.1 +...   \nneural network with autoencoding m15 mega + dro...  loss=6.51e+04 valloss=6.52e+04 +valsplit=0.1 +...   \n\n                                                    ...  \\\nxg boost (tree) (v09)                               ...   \nxg boost (v09)                                      ...   \ncatboost (v09)                                      ...   \nrandom forest (v09)                                 ...   \nknn (v09)                                           ...   \nneural network m15 mega + dropout (v09)             ...   \ndecision tree (v09)                                 ...   \nneural network m14 mega (v09)                       ...   \nneural network m13 mega (v09)                       ...   \nneural network m11 mega (v09)                       ...   \nneural network m12 mega (v09)                       ...   \nneural network m05 rec deep (v09)                   ...   \nneural network m02 two layers (v09)                 ...   \nneural network m04 3 layers+wider (v09)             ...   \nneural network m01 simple (v09)                     ...   \nlinear regression (ridge) (v09)                     ...   \nneural network m03 2 layers+wider (v09)             ...   \nneural network with autoencoding m15 mega + dro...  ...   \n\n                                                                          date  \\\nxg boost (tree) (v09)                               2022-12-14 00:46:51.090690   \nxg boost (v09)                                      2022-11-30 14:16:09.155790   \ncatboost (v09)                                      2023-01-01 09:20:34.767185   \nrandom forest (v09)                                 2022-12-11 19:26:14.332459   \nknn (v09)                                           2022-11-30 13:08:30.813219   \nneural network m15 mega + dropout (v09)             2022-12-20 15:17:28.052366   \ndecision tree (v09)                                 2022-12-11 15:04:40.788720   \nneural network m14 mega (v09)                       2022-12-12 16:01:42.195065   \nneural network m13 mega (v09)                       2022-12-12 15:25:17.070719   \nneural network m11 mega (v09)                       2022-12-12 15:02:24.649254   \nneural network m12 mega (v09)                       2022-12-12 15:16:52.189760   \nneural network m05 rec deep (v09)                   2022-12-12 14:43:41.363154   \nneural network m02 two layers (v09)                 2022-12-12 13:43:24.161642   \nneural network m04 3 layers+wider (v09)             2022-12-12 14:19:59.845538   \nneural network m01 simple (v09)                     2022-12-11 18:16:39.373845   \nlinear regression (ridge) (v09)                     2023-01-01 09:59:18.171520   \nneural network m03 2 layers+wider (v09)             2022-12-12 14:06:54.197268   \nneural network with autoencoding m15 mega + dro...  2022-12-21 01:26:33.005210   \n\n                                                                     first run  \\\nxg boost (tree) (v09)                               2022-12-14 00:46:51.092108   \nxg boost (v09)                                      2022-11-30 09:33:31.526343   \ncatboost (v09)                                      2022-11-30 13:14:23.328891   \nrandom forest (v09)                                 2022-11-29 20:45:43.376227   \nknn (v09)                                           2022-11-29 21:54:47.673877   \nneural network m15 mega + dropout (v09)             2022-12-13 23:57:56.105918   \ndecision tree (v09)                                 2022-11-29 20:03:38.095283   \nneural network m14 mega (v09)                       2022-12-12 16:01:42.251643   \nneural network m13 mega (v09)                       2022-12-12 15:25:17.113812   \nneural network m11 mega (v09)                       2022-12-12 15:02:24.663846   \nneural network m12 mega (v09)                       2022-11-29 20:45:17.449108   \nneural network m05 rec deep (v09)                   2022-12-12 13:21:58.503303   \nneural network m02 two layers (v09)                 2022-11-30 13:34:57.705226   \nneural network m04 3 layers+wider (v09)             2022-12-12 11:55:30.668773   \nneural network m01 simple (v09)                     2022-11-30 12:38:21.832825   \nlinear regression (ridge) (v09)                     2022-11-29 15:13:33.267574   \nneural network m03 2 layers+wider (v09)             2022-12-11 18:56:27.306218   \nneural network with autoencoding m15 mega + dro...  2022-12-21 01:26:33.013203   \n\n                                                   random_state   run_env  \\\nxg boost (tree) (v09)                                       101  gradient   \nxg boost (v09)                                              101  gradient   \ncatboost (v09)                                              101  gradient   \nrandom forest (v09)                                         101  gradient   \nknn (v09)                                                   101  gradient   \nneural network m15 mega + dropout (v09)                     101  gradient   \ndecision tree (v09)                                         101  gradient   \nneural network m14 mega (v09)                               101  gradient   \nneural network m13 mega (v09)                               101  gradient   \nneural network m11 mega (v09)                               101  gradient   \nneural network m12 mega (v09)                               101  gradient   \nneural network m05 rec deep (v09)                           101  gradient   \nneural network m02 two layers (v09)                         101  gradient   \nneural network m04 3 layers+wider (v09)                     101  gradient   \nneural network m01 simple (v09)                             101  gradient   \nlinear regression (ridge) (v09)                             101  gradient   \nneural network m03 2 layers+wider (v09)                     101  gradient   \nneural network with autoencoding m15 mega + dro...          101  gradient   \n\n                                                                                        silver method  \\\nxg boost (tree) (v09)                                                                             NaN   \nxg boost (v09)                                                                          random search   \ncatboost (v09)                                                              random search(no dummies)   \nrandom forest (v09)                                                                     random search   \nknn (v09)                                                                               random search   \nneural network m15 mega + dropout (v09)             loss=8.53e-02 valloss=9.72e-02 +valsplit=0.1 +...   \ndecision tree (v09)                                                                     random search   \nneural network m14 mega (v09)                                                                     NaN   \nneural network m13 mega (v09)                                                                     NaN   \nneural network m11 mega (v09)                                                                     NaN   \nneural network m12 mega (v09)                                                                     NaN   \nneural network m05 rec deep (v09)                   loss=5.10e+09 valloss=5.01e+09 +valsplit=0.1 +...   \nneural network m02 two layers (v09)                 loss=5.64e+09 valloss=5.60e+09 +valsplit=0.1 +...   \nneural network m04 3 layers+wider (v09)             loss=5.60e+09 valloss=5.50e+09 +valsplit=0.1 +...   \nneural network m01 simple (v09)                     loss=7.75e+09 valloss=7.68e+09 +valsplit=0.1 +...   \nlinear regression (ridge) (v09)                                        random search(pca,1.0% retain)   \nneural network m03 2 layers+wider (v09)             loss=6.44e+09 valloss=6.46e+09 +valsplit=0.1 +...   \nneural network with autoencoding m15 mega + dro...                                                NaN   \n\n                                                                                        silver params  \\\nxg boost (tree) (v09)                                                                             NaN   \nxg boost (v09)                                      {'model__booster': 'dart', 'model__early_stopp...   \ncatboost (v09)                                      {'depth': 9, 'l2_leaf_reg': 5, 'learning_rate'...   \nrandom forest (v09)                                 {'model__bootstrap': True, 'model__ccp_alpha':...   \nknn (v09)                                           {'model__algorithm': 'kd_tree', 'model__leaf_s...   \nneural network m15 mega + dropout (v09)                                 mae +epochs=400 +learn=0.0003   \ndecision tree (v09)                                 {'model__ccp_alpha': 0.05, 'model__criterion':...   \nneural network m14 mega (v09)                                                                     NaN   \nneural network m13 mega (v09)                                                                     NaN   \nneural network m11 mega (v09)                                                                     NaN   \nneural network m12 mega (v09)                                                                     NaN   \nneural network m05 rec deep (v09)                                       mse +epochs=500 +learn=0.0003   \nneural network m02 two layers (v09)                                      mse +epochs=500 +learn=0.003   \nneural network m04 3 layers+wider (v09)                                  mse +epochs=500 +learn=0.003   \nneural network m01 simple (v09)                                           mse +epochs=50 +learn=0.003   \nlinear regression (ridge) (v09)                     {'model__alpha': 0.0001, 'model__copy_X': True...   \nneural network m03 2 layers+wider (v09)                                 mse +epochs=500 +learn=0.0003   \nneural network with autoencoding m15 mega + dro...                                                NaN   \n\n                                                               silver run date  \\\nxg boost (tree) (v09)                                                      NaN   \nxg boost (v09)                                      2022-11-30 14:16:09.155790   \ncatboost (v09)                                      2022-11-30 13:23:28.812813   \nrandom forest (v09)                                 2022-11-29 20:45:43.360554   \nknn (v09)                                           2022-11-29 21:54:47.669723   \nneural network m15 mega + dropout (v09)             2022-12-20 15:17:28.052366   \ndecision tree (v09)                                 2022-12-11 15:04:40.788720   \nneural network m14 mega (v09)                                              NaN   \nneural network m13 mega (v09)                                              NaN   \nneural network m11 mega (v09)                                              NaN   \nneural network m12 mega (v09)                                              NaN   \nneural network m05 rec deep (v09)                   2022-12-12 14:43:41.363154   \nneural network m02 two layers (v09)                 2022-12-12 13:43:24.161642   \nneural network m04 3 layers+wider (v09)             2022-12-12 12:57:25.286949   \nneural network m01 simple (v09)                     2022-12-11 18:16:39.373845   \nlinear regression (ridge) (v09)                     2023-01-01 09:53:55.211064   \nneural network m03 2 layers+wider (v09)             2022-12-12 11:32:40.064934   \nneural network with autoencoding m15 mega + dro...                         NaN   \n\n                                                   silver score silver time  \\\nxg boost (tree) (v09)                                       NaN         NaN   \nxg boost (v09)                                         0.614431   21.169572   \ncatboost (v09)                                         0.686818        0.16   \nrandom forest (v09)                                    0.254902     4.46726   \nknn (v09)                                              0.644898    0.070961   \nneural network m15 mega + dropout (v09)              -15.994805     1005.59   \ndecision tree (v09)                                    0.617999    0.325321   \nneural network m14 mega (v09)                               NaN         NaN   \nneural network m13 mega (v09)                               NaN         NaN   \nneural network m11 mega (v09)                               NaN         NaN   \nneural network m12 mega (v09)                               NaN         NaN   \nneural network m05 rec deep (v09)                      0.555995     1418.24   \nneural network m02 two layers (v09)                    0.512696      822.12   \nneural network m04 3 layers+wider (v09)                0.516225      610.23   \nneural network m01 simple (v09)                        0.331597      162.26   \nlinear regression (ridge) (v09)                        0.459955    0.109841   \nneural network m03 2 layers+wider (v09)                0.447425     1293.81   \nneural network with autoencoding m15 mega + dro...          NaN         NaN   \n\n                                                    suboptimal  \nxg boost (tree) (v09)                                  pending  \nxg boost (v09)                                      suboptimal  \ncatboost (v09)                                      suboptimal  \nrandom forest (v09)                                    pending  \nknn (v09)                                           suboptimal  \nneural network m15 mega + dropout (v09)             suboptimal  \ndecision tree (v09)                                 suboptimal  \nneural network m14 mega (v09)                          pending  \nneural network m13 mega (v09)                          pending  \nneural network m11 mega (v09)                          pending  \nneural network m12 mega (v09)                          pending  \nneural network m05 rec deep (v09)                   suboptimal  \nneural network m02 two layers (v09)                 suboptimal  \nneural network m04 3 layers+wider (v09)             suboptimal  \nneural network m01 simple (v09)                     suboptimal  \nlinear regression (ridge) (v09)                     suboptimal  \nneural network m03 2 layers+wider (v09)             suboptimal  \nneural network with autoencoding m15 mega + dro...     pending  \n\n[18 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean Absolute Error Accuracy</th>\n      <th>Mean Squared Error Accuracy</th>\n      <th>R square Accuracy</th>\n      <th>Root Mean Squared Error</th>\n      <th>_method</th>\n      <th>_params</th>\n      <th>_score</th>\n      <th>_train time</th>\n      <th>best is shared</th>\n      <th>best method</th>\n      <th>...</th>\n      <th>date</th>\n      <th>first run</th>\n      <th>random_state</th>\n      <th>run_env</th>\n      <th>silver method</th>\n      <th>silver params</th>\n      <th>silver run date</th>\n      <th>silver score</th>\n      <th>silver time</th>\n      <th>suboptimal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>xg boost (tree) (v09)</th>\n      <td>42675.746856</td>\n      <td>3147715326.58041</td>\n      <td>0.721352</td>\n      <td>56104.503621</td>\n      <td>random search</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>0.721352</td>\n      <td>179.820912</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2022-12-14 00:46:51.090690</td>\n      <td>2022-12-14 00:46:51.092108</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>xg boost (v09)</th>\n      <td>51922.608639</td>\n      <td>4355546020.138196</td>\n      <td>0.614431</td>\n      <td>65996.560669</td>\n      <td>random search</td>\n      <td>{'model__booster': 'dart', 'model__early_stopp...</td>\n      <td>0.614431</td>\n      <td>21.169572</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2022-11-30 14:16:09.155790</td>\n      <td>2022-11-30 09:33:31.526343</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search</td>\n      <td>{'model__booster': 'dart', 'model__early_stopp...</td>\n      <td>2022-11-30 14:16:09.155790</td>\n      <td>0.614431</td>\n      <td>21.169572</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>catboost (v09)</th>\n      <td>74210.938931</td>\n      <td>8569097506.139938</td>\n      <td>0.241431</td>\n      <td>92569.41993</td>\n      <td>random search(pca)</td>\n      <td>{'depth': 9, 'l2_leaf_reg': 1, 'learning_rate'...</td>\n      <td>0.241431</td>\n      <td>999</td>\n      <td>False</td>\n      <td>random search(no dummies)</td>\n      <td>...</td>\n      <td>2023-01-01 09:20:34.767185</td>\n      <td>2022-11-30 13:14:23.328891</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search(no dummies)</td>\n      <td>{'depth': 9, 'l2_leaf_reg': 5, 'learning_rate'...</td>\n      <td>2022-11-30 13:23:28.812813</td>\n      <td>0.686818</td>\n      <td>0.16</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>random forest (v09)</th>\n      <td>46294.554857</td>\n      <td>3613817488.991202</td>\n      <td>0.680091</td>\n      <td>60115.035465</td>\n      <td>random search</td>\n      <td>{'model__bootstrap': True, 'model__ccp_alpha':...</td>\n      <td>0.680091</td>\n      <td>1127.317849</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2022-12-11 19:26:14.332459</td>\n      <td>2022-11-29 20:45:43.376227</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search</td>\n      <td>{'model__bootstrap': True, 'model__ccp_alpha':...</td>\n      <td>2022-11-29 20:45:43.360554</td>\n      <td>0.254902</td>\n      <td>4.46726</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>knn (v09)</th>\n      <td>48389.098294</td>\n      <td>4157374530.888747</td>\n      <td>0.631974</td>\n      <td>64477.705689</td>\n      <td>random search</td>\n      <td>{'model__algorithm': 'ball_tree', 'model__leaf...</td>\n      <td>0.631974</td>\n      <td>0.053487</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2022-11-30 13:08:30.813219</td>\n      <td>2022-11-29 21:54:47.673877</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__leaf_s...</td>\n      <td>2022-11-29 21:54:47.669723</td>\n      <td>0.644898</td>\n      <td>0.070961</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network m15 mega + dropout (v09)</th>\n      <td>212534587876.077087</td>\n      <td>47995052450841435832320.0</td>\n      <td>-15.994805</td>\n      <td>219077731526.600952</td>\n      <td>loss=8.53e-02 valloss=9.72e-02 +valsplit=0.1 +...</td>\n      <td>mae +epochs=400 +learn=0.0003</td>\n      <td>-15.994805</td>\n      <td>1005.59</td>\n      <td>False</td>\n      <td>loss=4.38e+04 valloss=4.85e+04 +valsplit=0.1 +...</td>\n      <td>...</td>\n      <td>2022-12-20 15:17:28.052366</td>\n      <td>2022-12-13 23:57:56.105918</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>loss=8.53e-02 valloss=9.72e-02 +valsplit=0.1 +...</td>\n      <td>mae +epochs=400 +learn=0.0003</td>\n      <td>2022-12-20 15:17:28.052366</td>\n      <td>-15.994805</td>\n      <td>1005.59</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>decision tree (v09)</th>\n      <td>51319.080582</td>\n      <td>4315241833.852664</td>\n      <td>0.617999</td>\n      <td>65690.500332</td>\n      <td>random search</td>\n      <td>{'model__ccp_alpha': 0.05, 'model__criterion':...</td>\n      <td>0.617999</td>\n      <td>0.325321</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2022-12-11 15:04:40.788720</td>\n      <td>2022-11-29 20:03:38.095283</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search</td>\n      <td>{'model__ccp_alpha': 0.05, 'model__criterion':...</td>\n      <td>2022-12-11 15:04:40.788720</td>\n      <td>0.617999</td>\n      <td>0.325321</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network m14 mega (v09)</th>\n      <td>51080.541252</td>\n      <td>4395484312.865142</td>\n      <td>0.610895</td>\n      <td>66298.448797</td>\n      <td>loss=4.68e+04 valloss=5.01e+04 +valsplit=0.1 +...</td>\n      <td>mae +epochs=400 +learn=0.0003</td>\n      <td>0.610895</td>\n      <td>2179.86</td>\n      <td>False</td>\n      <td>loss=4.68e+04 valloss=5.01e+04 +valsplit=0.1 +...</td>\n      <td>...</td>\n      <td>2022-12-12 16:01:42.195065</td>\n      <td>2022-12-12 16:01:42.251643</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>neural network m13 mega (v09)</th>\n      <td>50938.566359</td>\n      <td>4437747297.256148</td>\n      <td>0.607154</td>\n      <td>66616.419127</td>\n      <td>loss=4.55e+04 valloss=5.03e+04 +valsplit=0.1 +...</td>\n      <td>mae +epochs=400 +learn=0.0003</td>\n      <td>0.607154</td>\n      <td>500.16</td>\n      <td>False</td>\n      <td>loss=4.55e+04 valloss=5.03e+04 +valsplit=0.1 +...</td>\n      <td>...</td>\n      <td>2022-12-12 15:25:17.070719</td>\n      <td>2022-12-12 15:25:17.113812</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>neural network m11 mega (v09)</th>\n      <td>53873.03808</td>\n      <td>4663875436.065661</td>\n      <td>0.587136</td>\n      <td>68292.572335</td>\n      <td>loss=4.26e+09 valloss=4.72e+09 +valsplit=0.1 +...</td>\n      <td>mse +epochs=400 +learn=0.0003</td>\n      <td>0.587136</td>\n      <td>994.87</td>\n      <td>False</td>\n      <td>loss=4.26e+09 valloss=4.72e+09 +valsplit=0.1 +...</td>\n      <td>...</td>\n      <td>2022-12-12 15:02:24.649254</td>\n      <td>2022-12-12 15:02:24.663846</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>neural network m12 mega (v09)</th>\n      <td>54695.968258</td>\n      <td>4835177161.720935</td>\n      <td>0.571972</td>\n      <td>69535.438172</td>\n      <td>loss=4.76e+09 valloss=4.77e+09 +valsplit=0.1 +...</td>\n      <td>mse +epochs=400 +learn=0.0003</td>\n      <td>0.571972</td>\n      <td>848.7</td>\n      <td>False</td>\n      <td>loss=4.76e+09 valloss=4.77e+09 +valsplit=0.1 +...</td>\n      <td>...</td>\n      <td>2022-12-12 15:16:52.189760</td>\n      <td>2022-11-29 20:45:17.449108</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>neural network m05 rec deep (v09)</th>\n      <td>56357.458454</td>\n      <td>5015665639.26466</td>\n      <td>0.555995</td>\n      <td>70821.364286</td>\n      <td>loss=5.10e+09 valloss=5.01e+09 +valsplit=0.1 +...</td>\n      <td>mse +epochs=500 +learn=0.0003</td>\n      <td>0.555995</td>\n      <td>1418.24</td>\n      <td>False</td>\n      <td>loss=4.87e+09 valloss=4.84e+09 +valsplit=0.1 +...</td>\n      <td>...</td>\n      <td>2022-12-12 14:43:41.363154</td>\n      <td>2022-12-12 13:21:58.503303</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>loss=5.10e+09 valloss=5.01e+09 +valsplit=0.1 +...</td>\n      <td>mse +epochs=500 +learn=0.0003</td>\n      <td>2022-12-12 14:43:41.363154</td>\n      <td>0.555995</td>\n      <td>1418.24</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network m02 two layers (v09)</th>\n      <td>59659.87364</td>\n      <td>5504782893.089812</td>\n      <td>0.512696</td>\n      <td>74194.224122</td>\n      <td>loss=5.64e+09 valloss=5.60e+09 +valsplit=0.1 +...</td>\n      <td>mse +epochs=500 +learn=0.003</td>\n      <td>0.512696</td>\n      <td>822.12</td>\n      <td>False</td>\n      <td>loss=5424.62 valloss=5263.41 +valsplit=0.1 sto...</td>\n      <td>...</td>\n      <td>2022-12-12 13:43:24.161642</td>\n      <td>2022-11-30 13:34:57.705226</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>loss=5.64e+09 valloss=5.60e+09 +valsplit=0.1 +...</td>\n      <td>mse +epochs=500 +learn=0.003</td>\n      <td>2022-12-12 13:43:24.161642</td>\n      <td>0.512696</td>\n      <td>822.12</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network m04 3 layers+wider (v09)</th>\n      <td>60774.606195</td>\n      <td>5662801657.51863</td>\n      <td>0.498708</td>\n      <td>75251.58907</td>\n      <td>loss=5.80e+09 valloss=5.76e+09 +valsplit=0.1 +...</td>\n      <td>mse +epochs=500 +learn=0.003</td>\n      <td>0.498708</td>\n      <td>781.31</td>\n      <td>False</td>\n      <td>loss=5.20e+09 valloss=5.09e+09 +valsplit=0.1 +...</td>\n      <td>...</td>\n      <td>2022-12-12 14:19:59.845538</td>\n      <td>2022-12-12 11:55:30.668773</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>loss=5.60e+09 valloss=5.50e+09 +valsplit=0.1 +...</td>\n      <td>mse +epochs=500 +learn=0.003</td>\n      <td>2022-12-12 12:57:25.286949</td>\n      <td>0.516225</td>\n      <td>610.23</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network m01 simple (v09)</th>\n      <td>71376.935786</td>\n      <td>7550556480.57456</td>\n      <td>0.331597</td>\n      <td>86893.938112</td>\n      <td>loss=7.75e+09 valloss=7.68e+09 +valsplit=0.1 +...</td>\n      <td>mse +epochs=50 +learn=0.003</td>\n      <td>0.331597</td>\n      <td>162.26</td>\n      <td>False</td>\n      <td>loss=5724.92 valloss=5608.12 +valsplit=0.1 sto...</td>\n      <td>...</td>\n      <td>2022-12-11 18:16:39.373845</td>\n      <td>2022-11-30 12:38:21.832825</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>loss=7.75e+09 valloss=7.68e+09 +valsplit=0.1 +...</td>\n      <td>mse +epochs=50 +learn=0.003</td>\n      <td>2022-12-11 18:16:39.373845</td>\n      <td>0.331597</td>\n      <td>162.26</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v09)</th>\n      <td>75320.739699</td>\n      <td>8376872406.903015</td>\n      <td>0.258448</td>\n      <td>91525.255569</td>\n      <td>random search(pca,0.5% retain)</td>\n      <td>{'model__alpha': 1e-05, 'model__copy_X': False...</td>\n      <td>0.258448</td>\n      <td>0.087033</td>\n      <td>False</td>\n      <td>random search(pca)</td>\n      <td>...</td>\n      <td>2023-01-01 09:59:18.171520</td>\n      <td>2022-11-29 15:13:33.267574</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search(pca,1.0% retain)</td>\n      <td>{'model__alpha': 0.0001, 'model__copy_X': True...</td>\n      <td>2023-01-01 09:53:55.211064</td>\n      <td>0.459955</td>\n      <td>0.109841</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network m03 2 layers+wider (v09)</th>\n      <td>64123.564083</td>\n      <td>6242932923.632053</td>\n      <td>0.447352</td>\n      <td>79012.232747</td>\n      <td>loss=6.44e+09 valloss=6.46e+09 +valsplit=0.1 +...</td>\n      <td>mse +epochs=500 +learn=0.0003</td>\n      <td>0.447352</td>\n      <td>1404.21</td>\n      <td>False</td>\n      <td>loss=6.38e+09 valloss=6.41e+09 +valsplit=0.1 +...</td>\n      <td>...</td>\n      <td>2022-12-12 14:06:54.197268</td>\n      <td>2022-12-11 18:56:27.306218</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>loss=6.44e+09 valloss=6.46e+09 +valsplit=0.1 +...</td>\n      <td>mse +epochs=500 +learn=0.0003</td>\n      <td>2022-12-12 11:32:40.064934</td>\n      <td>0.447425</td>\n      <td>1293.81</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network with autoencoding m15 mega + dropout (v09)</th>\n      <td>64379.512251</td>\n      <td>6474086836.603735</td>\n      <td>0.42689</td>\n      <td>80461.710376</td>\n      <td>loss=6.51e+04 valloss=6.52e+04 +valsplit=0.1 +...</td>\n      <td>mae +epochs=400 +learn=0.0003</td>\n      <td>0.42689</td>\n      <td>1641.39</td>\n      <td>False</td>\n      <td>loss=6.51e+04 valloss=6.52e+04 +valsplit=0.1 +...</td>\n      <td>...</td>\n      <td>2022-12-21 01:26:33.005210</td>\n      <td>2022-12-21 01:26:33.013203</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>pending</td>\n    </tr>\n  </tbody>\n</table>\n<p>18 rows  24 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_versions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-11T17:58:27.459481Z",
     "iopub.status.busy": "2022-12-11T17:58:27.459230Z",
     "iopub.status.idle": "2022-12-11T17:58:27.472176Z",
     "shell.execute_reply": "2022-12-11T17:58:27.471352Z",
     "shell.execute_reply.started": "2022-12-11T17:58:27.459459Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   best score    best time  \\\nxg boost (tree) (v09)                                0.721352   179.820912   \nxg boost (v09)                                       0.701117    119.28102   \ncatboost (v09)                                       0.700506         2.82   \nrandom forest (v09)                                  0.680091  1127.317849   \nknn (v09)                                            0.644916     0.112408   \nneural network m15 mega + dropout (v09)              0.622235      2077.84   \ndecision tree (v09)                                  0.619635     0.409451   \nneural network m14 mega (v09)                        0.610895      2179.86   \nneural network m13 mega (v09)                        0.607154       500.16   \nneural network m11 mega (v09)                        0.587136       994.87   \nneural network m12 mega (v09)                        0.571972        848.7   \nneural network m05 rec deep (v09)                    0.558413      1471.09   \nneural network m02 two layers (v09)                  0.540824       178.62   \nneural network m04 3 layers+wider (v09)              0.540678       1367.3   \nneural network m01 simple (v09)                      0.508847       188.63   \nlinear regression (ridge) (v09)                      0.459955     0.100284   \nneural network m03 2 layers+wider (v09)                0.4523      1822.49   \nneural network with autoencoding m15 mega + dro...    0.42689      1641.39   \n\n                                                   silver score silver time  \\\nxg boost (tree) (v09)                                       NaN         NaN   \nxg boost (v09)                                         0.614431   21.169572   \ncatboost (v09)                                         0.686818        0.16   \nrandom forest (v09)                                    0.254902     4.46726   \nknn (v09)                                              0.644898    0.070961   \nneural network m15 mega + dropout (v09)              -15.994805     1005.59   \ndecision tree (v09)                                    0.617999    0.325321   \nneural network m14 mega (v09)                               NaN         NaN   \nneural network m13 mega (v09)                               NaN         NaN   \nneural network m11 mega (v09)                               NaN         NaN   \nneural network m12 mega (v09)                               NaN         NaN   \nneural network m05 rec deep (v09)                      0.555995     1418.24   \nneural network m02 two layers (v09)                    0.512696      822.12   \nneural network m04 3 layers+wider (v09)                0.516225      610.23   \nneural network m01 simple (v09)                        0.331597      162.26   \nlinear regression (ridge) (v09)                        0.459955    0.109841   \nneural network m03 2 layers+wider (v09)                0.447425     1293.81   \nneural network with autoencoding m15 mega + dro...          NaN         NaN   \n\n                                                                                          best method  \\\nxg boost (tree) (v09)                                                                   random search   \nxg boost (v09)                                                                          random search   \ncatboost (v09)                                                              random search(no dummies)   \nrandom forest (v09)                                                                     random search   \nknn (v09)                                                                               random search   \nneural network m15 mega + dropout (v09)             loss=4.38e+04 valloss=4.85e+04 +valsplit=0.1 +...   \ndecision tree (v09)                                                                     random search   \nneural network m14 mega (v09)                       loss=4.68e+04 valloss=5.01e+04 +valsplit=0.1 +...   \nneural network m13 mega (v09)                       loss=4.55e+04 valloss=5.03e+04 +valsplit=0.1 +...   \nneural network m11 mega (v09)                       loss=4.26e+09 valloss=4.72e+09 +valsplit=0.1 +...   \nneural network m12 mega (v09)                       loss=4.76e+09 valloss=4.77e+09 +valsplit=0.1 +...   \nneural network m05 rec deep (v09)                   loss=4.87e+09 valloss=4.84e+09 +valsplit=0.1 +...   \nneural network m02 two layers (v09)                 loss=5424.62 valloss=5263.41 +valsplit=0.1 sto...   \nneural network m04 3 layers+wider (v09)             loss=5.20e+09 valloss=5.09e+09 +valsplit=0.1 +...   \nneural network m01 simple (v09)                     loss=5724.92 valloss=5608.12 +valsplit=0.1 sto...   \nlinear regression (ridge) (v09)                                                    random search(pca)   \nneural network m03 2 layers+wider (v09)             loss=6.38e+09 valloss=6.41e+09 +valsplit=0.1 +...   \nneural network with autoencoding m15 mega + dro...  loss=6.51e+04 valloss=6.52e+04 +valsplit=0.1 +...   \n\n                                                                                        silver method  \\\nxg boost (tree) (v09)                                                                             NaN   \nxg boost (v09)                                                                          random search   \ncatboost (v09)                                                              random search(no dummies)   \nrandom forest (v09)                                                                     random search   \nknn (v09)                                                                               random search   \nneural network m15 mega + dropout (v09)             loss=8.53e-02 valloss=9.72e-02 +valsplit=0.1 +...   \ndecision tree (v09)                                                                     random search   \nneural network m14 mega (v09)                                                                     NaN   \nneural network m13 mega (v09)                                                                     NaN   \nneural network m11 mega (v09)                                                                     NaN   \nneural network m12 mega (v09)                                                                     NaN   \nneural network m05 rec deep (v09)                   loss=5.10e+09 valloss=5.01e+09 +valsplit=0.1 +...   \nneural network m02 two layers (v09)                 loss=5.64e+09 valloss=5.60e+09 +valsplit=0.1 +...   \nneural network m04 3 layers+wider (v09)             loss=5.60e+09 valloss=5.50e+09 +valsplit=0.1 +...   \nneural network m01 simple (v09)                     loss=7.75e+09 valloss=7.68e+09 +valsplit=0.1 +...   \nlinear regression (ridge) (v09)                                        random search(pca,1.0% retain)   \nneural network m03 2 layers+wider (v09)             loss=6.44e+09 valloss=6.46e+09 +valsplit=0.1 +...   \nneural network with autoencoding m15 mega + dro...                                                NaN   \n\n                                                   best is shared  \nxg boost (tree) (v09)                                       False  \nxg boost (v09)                                              False  \ncatboost (v09)                                              False  \nrandom forest (v09)                                         False  \nknn (v09)                                                   False  \nneural network m15 mega + dropout (v09)                     False  \ndecision tree (v09)                                         False  \nneural network m14 mega (v09)                               False  \nneural network m13 mega (v09)                               False  \nneural network m11 mega (v09)                               False  \nneural network m12 mega (v09)                               False  \nneural network m05 rec deep (v09)                           False  \nneural network m02 two layers (v09)                         False  \nneural network m04 3 layers+wider (v09)                     False  \nneural network m01 simple (v09)                             False  \nlinear regression (ridge) (v09)                             False  \nneural network m03 2 layers+wider (v09)                     False  \nneural network with autoencoding m15 mega + dro...          False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best score</th>\n      <th>best time</th>\n      <th>silver score</th>\n      <th>silver time</th>\n      <th>best method</th>\n      <th>silver method</th>\n      <th>best is shared</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>xg boost (tree) (v09)</th>\n      <td>0.721352</td>\n      <td>179.820912</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>random search</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>xg boost (v09)</th>\n      <td>0.701117</td>\n      <td>119.28102</td>\n      <td>0.614431</td>\n      <td>21.169572</td>\n      <td>random search</td>\n      <td>random search</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>catboost (v09)</th>\n      <td>0.700506</td>\n      <td>2.82</td>\n      <td>0.686818</td>\n      <td>0.16</td>\n      <td>random search(no dummies)</td>\n      <td>random search(no dummies)</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>random forest (v09)</th>\n      <td>0.680091</td>\n      <td>1127.317849</td>\n      <td>0.254902</td>\n      <td>4.46726</td>\n      <td>random search</td>\n      <td>random search</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>knn (v09)</th>\n      <td>0.644916</td>\n      <td>0.112408</td>\n      <td>0.644898</td>\n      <td>0.070961</td>\n      <td>random search</td>\n      <td>random search</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m15 mega + dropout (v09)</th>\n      <td>0.622235</td>\n      <td>2077.84</td>\n      <td>-15.994805</td>\n      <td>1005.59</td>\n      <td>loss=4.38e+04 valloss=4.85e+04 +valsplit=0.1 +...</td>\n      <td>loss=8.53e-02 valloss=9.72e-02 +valsplit=0.1 +...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>decision tree (v09)</th>\n      <td>0.619635</td>\n      <td>0.409451</td>\n      <td>0.617999</td>\n      <td>0.325321</td>\n      <td>random search</td>\n      <td>random search</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m14 mega (v09)</th>\n      <td>0.610895</td>\n      <td>2179.86</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>loss=4.68e+04 valloss=5.01e+04 +valsplit=0.1 +...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m13 mega (v09)</th>\n      <td>0.607154</td>\n      <td>500.16</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>loss=4.55e+04 valloss=5.03e+04 +valsplit=0.1 +...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m11 mega (v09)</th>\n      <td>0.587136</td>\n      <td>994.87</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>loss=4.26e+09 valloss=4.72e+09 +valsplit=0.1 +...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m12 mega (v09)</th>\n      <td>0.571972</td>\n      <td>848.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>loss=4.76e+09 valloss=4.77e+09 +valsplit=0.1 +...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m05 rec deep (v09)</th>\n      <td>0.558413</td>\n      <td>1471.09</td>\n      <td>0.555995</td>\n      <td>1418.24</td>\n      <td>loss=4.87e+09 valloss=4.84e+09 +valsplit=0.1 +...</td>\n      <td>loss=5.10e+09 valloss=5.01e+09 +valsplit=0.1 +...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m02 two layers (v09)</th>\n      <td>0.540824</td>\n      <td>178.62</td>\n      <td>0.512696</td>\n      <td>822.12</td>\n      <td>loss=5424.62 valloss=5263.41 +valsplit=0.1 sto...</td>\n      <td>loss=5.64e+09 valloss=5.60e+09 +valsplit=0.1 +...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m04 3 layers+wider (v09)</th>\n      <td>0.540678</td>\n      <td>1367.3</td>\n      <td>0.516225</td>\n      <td>610.23</td>\n      <td>loss=5.20e+09 valloss=5.09e+09 +valsplit=0.1 +...</td>\n      <td>loss=5.60e+09 valloss=5.50e+09 +valsplit=0.1 +...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m01 simple (v09)</th>\n      <td>0.508847</td>\n      <td>188.63</td>\n      <td>0.331597</td>\n      <td>162.26</td>\n      <td>loss=5724.92 valloss=5608.12 +valsplit=0.1 sto...</td>\n      <td>loss=7.75e+09 valloss=7.68e+09 +valsplit=0.1 +...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v09)</th>\n      <td>0.459955</td>\n      <td>0.100284</td>\n      <td>0.459955</td>\n      <td>0.109841</td>\n      <td>random search(pca)</td>\n      <td>random search(pca,1.0% retain)</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m03 2 layers+wider (v09)</th>\n      <td>0.4523</td>\n      <td>1822.49</td>\n      <td>0.447425</td>\n      <td>1293.81</td>\n      <td>loss=6.38e+09 valloss=6.41e+09 +valsplit=0.1 +...</td>\n      <td>loss=6.44e+09 valloss=6.46e+09 +valsplit=0.1 +...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network with autoencoding m15 mega + dropout (v09)</th>\n      <td>0.42689</td>\n      <td>1641.39</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>loss=6.51e+04 valloss=6.52e+04 +valsplit=0.1 +...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_1_vs_2 = dataset_versions_df[\n",
    "    ['best score', 'best time', 'silver score', 'silver time', 'best method', 'silver method', 'best is shared']]\n",
    "df_summary_1_vs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-11T17:58:27.473783Z",
     "iopub.status.busy": "2022-12-11T17:58:27.473530Z",
     "iopub.status.idle": "2022-12-11T17:58:27.490023Z",
     "shell.execute_reply": "2022-12-11T17:58:27.489187Z",
     "shell.execute_reply.started": "2022-12-11T17:58:27.473760Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   best score    best time  \\\nxg boost (tree) (v09)                                0.721352   179.820912   \nxg boost (v09)                                       0.701117    119.28102   \ncatboost (v09)                                       0.700506         2.82   \nrandom forest (v09)                                  0.680091  1127.317849   \nknn (v09)                                            0.644916     0.112408   \nneural network m15 mega + dropout (v09)              0.622235      2077.84   \ndecision tree (v09)                                  0.619635     0.409451   \nneural network m14 mega (v09)                        0.610895      2179.86   \nneural network m13 mega (v09)                        0.607154       500.16   \nneural network m11 mega (v09)                        0.587136       994.87   \nneural network m12 mega (v09)                        0.571972        848.7   \nneural network m05 rec deep (v09)                    0.558413      1471.09   \nneural network m02 two layers (v09)                  0.540824       178.62   \nneural network m04 3 layers+wider (v09)              0.540678       1367.3   \nneural network m01 simple (v09)                      0.508847       188.63   \nlinear regression (ridge) (v09)                      0.459955     0.100284   \nneural network m03 2 layers+wider (v09)                0.4523      1822.49   \nneural network with autoencoding m15 mega + dro...    0.42689      1641.39   \n\n                                                   silver score silver time  \\\nxg boost (tree) (v09)                                       NaN         NaN   \nxg boost (v09)                                         0.614431   21.169572   \ncatboost (v09)                                         0.686818        0.16   \nrandom forest (v09)                                    0.254902     4.46726   \nknn (v09)                                              0.644898    0.070961   \nneural network m15 mega + dropout (v09)              -15.994805     1005.59   \ndecision tree (v09)                                    0.617999    0.325321   \nneural network m14 mega (v09)                               NaN         NaN   \nneural network m13 mega (v09)                               NaN         NaN   \nneural network m11 mega (v09)                               NaN         NaN   \nneural network m12 mega (v09)                               NaN         NaN   \nneural network m05 rec deep (v09)                      0.555995     1418.24   \nneural network m02 two layers (v09)                    0.512696      822.12   \nneural network m04 3 layers+wider (v09)                0.516225      610.23   \nneural network m01 simple (v09)                        0.331597      162.26   \nlinear regression (ridge) (v09)                        0.459955    0.109841   \nneural network m03 2 layers+wider (v09)                0.447425     1293.81   \nneural network with autoencoding m15 mega + dro...          NaN         NaN   \n\n                                                                                          best params  \\\nxg boost (tree) (v09)                               {'model__booster': 'dart', 'model__colsample_b...   \nxg boost (v09)                                      {'model__booster': 'dart', 'model__early_stopp...   \ncatboost (v09)                                      {'depth': 15, 'l2_leaf_reg': 5, 'learning_rate...   \nrandom forest (v09)                                 {'model__bootstrap': True, 'model__ccp_alpha':...   \nknn (v09)                                           {'model__algorithm': 'kd_tree', 'model__leaf_s...   \nneural network m15 mega + dropout (v09)                                 mae +epochs=400 +learn=0.0003   \ndecision tree (v09)                                 {'model__ccp_alpha': 0.25, 'model__criterion':...   \nneural network m14 mega (v09)                                           mae +epochs=400 +learn=0.0003   \nneural network m13 mega (v09)                                           mae +epochs=400 +learn=0.0003   \nneural network m11 mega (v09)                                           mse +epochs=400 +learn=0.0003   \nneural network m12 mega (v09)                                           mse +epochs=400 +learn=0.0003   \nneural network m05 rec deep (v09)                                       mse +epochs=500 +learn=0.0003   \nneural network m02 two layers (v09)                                      mse +epochs=500 +learn=0.003   \nneural network m04 3 layers+wider (v09)                                  mse +epochs=500 +learn=0.003   \nneural network m01 simple (v09)                                           mse +epochs=50 +learn=0.003   \nlinear regression (ridge) (v09)                     {'model__alpha': 1e-05, 'model__copy_X': True,...   \nneural network m03 2 layers+wider (v09)                                 mse +epochs=500 +learn=0.0003   \nneural network with autoencoding m15 mega + dro...                      mae +epochs=400 +learn=0.0003   \n\n                                                                                        silver params  \\\nxg boost (tree) (v09)                                                                             NaN   \nxg boost (v09)                                      {'model__booster': 'dart', 'model__early_stopp...   \ncatboost (v09)                                      {'depth': 9, 'l2_leaf_reg': 5, 'learning_rate'...   \nrandom forest (v09)                                 {'model__bootstrap': True, 'model__ccp_alpha':...   \nknn (v09)                                           {'model__algorithm': 'kd_tree', 'model__leaf_s...   \nneural network m15 mega + dropout (v09)                                 mae +epochs=400 +learn=0.0003   \ndecision tree (v09)                                 {'model__ccp_alpha': 0.05, 'model__criterion':...   \nneural network m14 mega (v09)                                                                     NaN   \nneural network m13 mega (v09)                                                                     NaN   \nneural network m11 mega (v09)                                                                     NaN   \nneural network m12 mega (v09)                                                                     NaN   \nneural network m05 rec deep (v09)                                       mse +epochs=500 +learn=0.0003   \nneural network m02 two layers (v09)                                      mse +epochs=500 +learn=0.003   \nneural network m04 3 layers+wider (v09)                                  mse +epochs=500 +learn=0.003   \nneural network m01 simple (v09)                                           mse +epochs=50 +learn=0.003   \nlinear regression (ridge) (v09)                     {'model__alpha': 0.0001, 'model__copy_X': True...   \nneural network m03 2 layers+wider (v09)                                 mse +epochs=500 +learn=0.0003   \nneural network with autoencoding m15 mega + dro...                                                NaN   \n\n                                                   best is shared  \nxg boost (tree) (v09)                                       False  \nxg boost (v09)                                              False  \ncatboost (v09)                                              False  \nrandom forest (v09)                                         False  \nknn (v09)                                                   False  \nneural network m15 mega + dropout (v09)                     False  \ndecision tree (v09)                                         False  \nneural network m14 mega (v09)                               False  \nneural network m13 mega (v09)                               False  \nneural network m11 mega (v09)                               False  \nneural network m12 mega (v09)                               False  \nneural network m05 rec deep (v09)                           False  \nneural network m02 two layers (v09)                         False  \nneural network m04 3 layers+wider (v09)                     False  \nneural network m01 simple (v09)                             False  \nlinear regression (ridge) (v09)                             False  \nneural network m03 2 layers+wider (v09)                     False  \nneural network with autoencoding m15 mega + dro...          False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best score</th>\n      <th>best time</th>\n      <th>silver score</th>\n      <th>silver time</th>\n      <th>best params</th>\n      <th>silver params</th>\n      <th>best is shared</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>xg boost (tree) (v09)</th>\n      <td>0.721352</td>\n      <td>179.820912</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>xg boost (v09)</th>\n      <td>0.701117</td>\n      <td>119.28102</td>\n      <td>0.614431</td>\n      <td>21.169572</td>\n      <td>{'model__booster': 'dart', 'model__early_stopp...</td>\n      <td>{'model__booster': 'dart', 'model__early_stopp...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>catboost (v09)</th>\n      <td>0.700506</td>\n      <td>2.82</td>\n      <td>0.686818</td>\n      <td>0.16</td>\n      <td>{'depth': 15, 'l2_leaf_reg': 5, 'learning_rate...</td>\n      <td>{'depth': 9, 'l2_leaf_reg': 5, 'learning_rate'...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>random forest (v09)</th>\n      <td>0.680091</td>\n      <td>1127.317849</td>\n      <td>0.254902</td>\n      <td>4.46726</td>\n      <td>{'model__bootstrap': True, 'model__ccp_alpha':...</td>\n      <td>{'model__bootstrap': True, 'model__ccp_alpha':...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>knn (v09)</th>\n      <td>0.644916</td>\n      <td>0.112408</td>\n      <td>0.644898</td>\n      <td>0.070961</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__leaf_s...</td>\n      <td>{'model__algorithm': 'kd_tree', 'model__leaf_s...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m15 mega + dropout (v09)</th>\n      <td>0.622235</td>\n      <td>2077.84</td>\n      <td>-15.994805</td>\n      <td>1005.59</td>\n      <td>mae +epochs=400 +learn=0.0003</td>\n      <td>mae +epochs=400 +learn=0.0003</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>decision tree (v09)</th>\n      <td>0.619635</td>\n      <td>0.409451</td>\n      <td>0.617999</td>\n      <td>0.325321</td>\n      <td>{'model__ccp_alpha': 0.25, 'model__criterion':...</td>\n      <td>{'model__ccp_alpha': 0.05, 'model__criterion':...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m14 mega (v09)</th>\n      <td>0.610895</td>\n      <td>2179.86</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>mae +epochs=400 +learn=0.0003</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m13 mega (v09)</th>\n      <td>0.607154</td>\n      <td>500.16</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>mae +epochs=400 +learn=0.0003</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m11 mega (v09)</th>\n      <td>0.587136</td>\n      <td>994.87</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>mse +epochs=400 +learn=0.0003</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m12 mega (v09)</th>\n      <td>0.571972</td>\n      <td>848.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>mse +epochs=400 +learn=0.0003</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m05 rec deep (v09)</th>\n      <td>0.558413</td>\n      <td>1471.09</td>\n      <td>0.555995</td>\n      <td>1418.24</td>\n      <td>mse +epochs=500 +learn=0.0003</td>\n      <td>mse +epochs=500 +learn=0.0003</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m02 two layers (v09)</th>\n      <td>0.540824</td>\n      <td>178.62</td>\n      <td>0.512696</td>\n      <td>822.12</td>\n      <td>mse +epochs=500 +learn=0.003</td>\n      <td>mse +epochs=500 +learn=0.003</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m04 3 layers+wider (v09)</th>\n      <td>0.540678</td>\n      <td>1367.3</td>\n      <td>0.516225</td>\n      <td>610.23</td>\n      <td>mse +epochs=500 +learn=0.003</td>\n      <td>mse +epochs=500 +learn=0.003</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m01 simple (v09)</th>\n      <td>0.508847</td>\n      <td>188.63</td>\n      <td>0.331597</td>\n      <td>162.26</td>\n      <td>mse +epochs=50 +learn=0.003</td>\n      <td>mse +epochs=50 +learn=0.003</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v09)</th>\n      <td>0.459955</td>\n      <td>0.100284</td>\n      <td>0.459955</td>\n      <td>0.109841</td>\n      <td>{'model__alpha': 1e-05, 'model__copy_X': True,...</td>\n      <td>{'model__alpha': 0.0001, 'model__copy_X': True...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m03 2 layers+wider (v09)</th>\n      <td>0.4523</td>\n      <td>1822.49</td>\n      <td>0.447425</td>\n      <td>1293.81</td>\n      <td>mse +epochs=500 +learn=0.0003</td>\n      <td>mse +epochs=500 +learn=0.0003</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network with autoencoding m15 mega + dropout (v09)</th>\n      <td>0.42689</td>\n      <td>1641.39</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>mae +epochs=400 +learn=0.0003</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_vs_2b = dataset_versions_df[\n",
    "    ['best score', 'best time', 'silver score', 'silver time', 'best params', 'silver params', 'best is shared']]\n",
    "df_1_vs_2b\n",
    "#{'model__booster': 'gbtree', 'model__early_stopping_rounds': None, 'model__gamma': 100, 'model__learning_rate': None, 'model__max_delta_step': 0, 'model__max_depth': 6, 'model__min_child_weight': ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
