{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "versions = ['v06', 'v09', 'v10', 'v11']\n",
    "version = None  #'xg boost'\n",
    "#version = 'all'\n",
    "original_version = version\n",
    "h = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T00:00:52.632296Z",
     "iopub.status.busy": "2022-12-14T00:00:52.631912Z",
     "iopub.status.idle": "2022-12-14T00:00:53.255004Z",
     "shell.execute_reply": "2022-12-14T00:00:53.254157Z",
     "shell.execute_reply.started": "2022-12-14T00:00:52.632223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/4: v10\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                best score best time  \\\ncatboost (v10)                    0.694651      4.77   \nxg boost (v10)                    0.681785  9.309589   \nneural network m13 mega (v10)     0.583716    142.89   \nneural network m14 mega (v10)     0.579095   1129.09   \nneural network m12 mega (v10)     0.567453     240.1   \nknn (v10)                         0.484585   0.29179   \nlinear regression (ridge) (v10)   0.470806  0.239057   \n\n                                Mean Absolute Error Accuracy  \\\ncatboost (v10)                                  44874.996907   \nxg boost (v10)                                  46626.687574   \nneural network m13 mega (v10)                    54668.92487   \nneural network m14 mega (v10)                   53123.957462   \nneural network m12 mega (v10)                   55444.019939   \nknn (v10)                                        61764.24973   \nlinear regression (ridge) (v10)                 62596.206431   \n\n                                Mean Squared Error Accuracy R square Accuracy  \\\ncatboost (v10)                            3449348436.406789          0.694651   \nxg boost (v10)                            3594689512.156493          0.681785   \nneural network m13 mega (v10)               4948088299.4757          0.561977   \nneural network m14 mega (v10)             4754712208.689863          0.579095   \nneural network m12 mega (v10)                4886231.935939          0.567453   \nknn (v10)                                 5822338150.186446          0.484585   \nlinear regression (ridge) (v10)           5977987697.000203          0.470806   \n\n                                Root Mean Squared Error  \\\ncatboost (v10)                             58731.153883   \nxg boost (v10)                             59955.729602   \nneural network m13 mega (v10)              70342.649221   \nneural network m14 mega (v10)              68954.421241   \nneural network m12 mega (v10)              69901.587507   \nknn (v10)                                  76304.247262   \nlinear regression (ridge) (v10)            77317.447559   \n\n                                              best run date  \\\ncatboost (v10)                   2022-11-30 14:14:50.145713   \nxg boost (v10)                   2022-11-30 14:45:52.207314   \nneural network m13 mega (v10)    2022-12-01 10:27:39.663081   \nneural network m14 mega (v10)    2022-12-01 11:52:45.011704   \nneural network m12 mega (v10)    2022-12-01 09:57:17.586487   \nknn (v10)                        2022-11-30 15:12:50.989371   \nlinear regression (ridge) (v10)  2022-12-01 19:50:08.050622   \n\n                                                                       best method  \\\ncatboost (v10)                                           random search(no dummies)   \nxg boost (v10)                                                       random search   \nneural network m13 mega (v10)    loss=3878948096.0 valloss=4822886400.0 +valspl...   \nneural network m14 mega (v10)    loss=4.85e+04 valloss=5.34e+04 +valsplit=0.1 s...   \nneural network m12 mega (v10)    loss=4790.75 valloss=4998.79 +valsplit=0.1 sto...   \nknn (v10)                                                            random search   \nlinear regression (ridge) (v10)                                      random search   \n\n                                best is shared  suboptimal  \ncatboost (v10)                           False     pending  \nxg boost (v10)                           False     pending  \nneural network m13 mega (v10)            False  suboptimal  \nneural network m14 mega (v10)            False     pending  \nneural network m12 mega (v10)            False     pending  \nknn (v10)                                False     pending  \nlinear regression (ridge) (v10)          False  suboptimal  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best score</th>\n      <th>best time</th>\n      <th>Mean Absolute Error Accuracy</th>\n      <th>Mean Squared Error Accuracy</th>\n      <th>R square Accuracy</th>\n      <th>Root Mean Squared Error</th>\n      <th>best run date</th>\n      <th>best method</th>\n      <th>best is shared</th>\n      <th>suboptimal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>catboost (v10)</th>\n      <td>0.694651</td>\n      <td>4.77</td>\n      <td>44874.996907</td>\n      <td>3449348436.406789</td>\n      <td>0.694651</td>\n      <td>58731.153883</td>\n      <td>2022-11-30 14:14:50.145713</td>\n      <td>random search(no dummies)</td>\n      <td>False</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>xg boost (v10)</th>\n      <td>0.681785</td>\n      <td>9.309589</td>\n      <td>46626.687574</td>\n      <td>3594689512.156493</td>\n      <td>0.681785</td>\n      <td>59955.729602</td>\n      <td>2022-11-30 14:45:52.207314</td>\n      <td>random search</td>\n      <td>False</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>neural network m13 mega (v10)</th>\n      <td>0.583716</td>\n      <td>142.89</td>\n      <td>54668.92487</td>\n      <td>4948088299.4757</td>\n      <td>0.561977</td>\n      <td>70342.649221</td>\n      <td>2022-12-01 10:27:39.663081</td>\n      <td>loss=3878948096.0 valloss=4822886400.0 +valspl...</td>\n      <td>False</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network m14 mega (v10)</th>\n      <td>0.579095</td>\n      <td>1129.09</td>\n      <td>53123.957462</td>\n      <td>4754712208.689863</td>\n      <td>0.579095</td>\n      <td>68954.421241</td>\n      <td>2022-12-01 11:52:45.011704</td>\n      <td>loss=4.85e+04 valloss=5.34e+04 +valsplit=0.1 s...</td>\n      <td>False</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>neural network m12 mega (v10)</th>\n      <td>0.567453</td>\n      <td>240.1</td>\n      <td>55444.019939</td>\n      <td>4886231.935939</td>\n      <td>0.567453</td>\n      <td>69901.587507</td>\n      <td>2022-12-01 09:57:17.586487</td>\n      <td>loss=4790.75 valloss=4998.79 +valsplit=0.1 sto...</td>\n      <td>False</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>knn (v10)</th>\n      <td>0.484585</td>\n      <td>0.29179</td>\n      <td>61764.24973</td>\n      <td>5822338150.186446</td>\n      <td>0.484585</td>\n      <td>76304.247262</td>\n      <td>2022-11-30 15:12:50.989371</td>\n      <td>random search</td>\n      <td>False</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v10)</th>\n      <td>0.470806</td>\n      <td>0.239057</td>\n      <td>62596.206431</td>\n      <td>5977987697.000203</td>\n      <td>0.470806</td>\n      <td>77317.447559</td>\n      <td>2022-12-01 19:50:08.050622</td>\n      <td>random search</td>\n      <td>False</td>\n      <td>suboptimal</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if not original_version:\n",
    "    version = versions[h]\n",
    "    print(f'{h + 1}/{len(versions)}: {version}')\n",
    "    h = (h + 1) % len(versions)\n",
    "\n",
    "dff = pd.read_json('results.json')\n",
    "\n",
    "vNN_columns = dff.columns if version == 'all' else [c for c in dff.columns if version in c]\n",
    "\n",
    "dataset_versions_df = dff[vNN_columns].T.sort_values(\"best score\", ascending=False)\n",
    "dataset_versions_df_summary = dataset_versions_df[\n",
    "    ['best score', 'best time', 'Mean Absolute Error Accuracy', 'Mean Squared Error Accuracy', 'R square Accuracy',\n",
    "     'Root Mean Squared Error', 'best run date', 'best method', 'best is shared', \"suboptimal\"]]\n",
    "dataset_versions_df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T17:58:27.432682Z",
     "iopub.status.busy": "2022-12-11T17:58:27.432324Z",
     "iopub.status.idle": "2022-12-11T17:58:27.457488Z",
     "shell.execute_reply": "2022-12-11T17:58:27.455698Z",
     "shell.execute_reply.started": "2022-12-11T17:58:27.432654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                        Mean Absolute Error Accuracy  \\\nxg boost (tree) (v06)                                   41210.351288   \nknn (v06)                                               41531.119915   \ncatboost (v06)                                          51000.047694   \nlight gradient boosting (v06)                           44080.972643   \nxg boost (v06)                                          45988.280765   \ndecision tree (v06)                                     59431.108316   \nneural network m11 mega (v06)                           56035.854723   \nneural network m12 mega (v06)                           54967.975952   \nrandom forest (v06)                                     60536.998438   \nneural network m05 rec deep (v06)                       59357.533817   \nneural network (v06)                                    66710.702966   \nneural network m03 2 layers+wider (v06)                 64376.517431   \nneural network m01 simple (v06)                         69131.972772   \nneural network simplified (v06)                         59373.052887   \nneural network m04 3 layers+wider (v06)                 64421.234531   \nneural network m02 two layers (v06)                     64363.094125   \nlinear regression (ridge) (v06)                         63603.059705   \n\n                                        Mean Squared Error Accuracy  \\\nxg boost (tree) (v06)                             3082428096.006462   \nknn (v06)                                         3218096364.819358   \ncatboost (v06)                                    4301362532.917062   \nlight gradient boosting (v06)                     3312839956.633489   \nxg boost (v06)                                    3528869693.681411   \ndecision tree (v06)                               5743592165.314412   \nneural network m11 mega (v06)                     4929943923.096645   \nneural network m12 mega (v06)                     4807033830.676171   \nrandom forest (v06)                               5634905403.102844   \nneural network m05 rec deep (v06)                 5470834738.338646   \nneural network (v06)                              6646858211.119819   \nneural network m03 2 layers+wider (v06)           6268024253.295089   \nneural network m01 simple (v06)                   7155866825.337951   \nneural network simplified (v06)                   5531509335.791807   \nneural network m04 3 layers+wider (v06)           6266407942.292152   \nneural network m02 two layers (v06)               6262090339.685114   \nlinear regression (ridge) (v06)                    6135206763.74439   \n\n                                        R square Accuracy  \\\nxg boost (tree) (v06)                            0.727132   \nknn (v06)                                        0.715122   \ncatboost (v06)                                   0.619227   \nlight gradient boosting (v06)                    0.706735   \nxg boost (v06)                                   0.687611   \ndecision tree (v06)                              0.491556   \nneural network m11 mega (v06)                    0.563583   \nneural network m12 mega (v06)                    0.574463   \nrandom forest (v06)                              0.501177   \nneural network m05 rec deep (v06)                0.515701   \nneural network (v06)                             0.411595   \nneural network m03 2 layers+wider (v06)          0.445131   \nneural network m01 simple (v06)                  0.366536   \nneural network simplified (v06)                   0.51033   \nneural network m04 3 layers+wider (v06)          0.445274   \nneural network m02 two layers (v06)              0.445656   \nlinear regression (ridge) (v06)                  0.456889   \n\n                                        Root Mean Squared Error  \\\nxg boost (tree) (v06)                              55519.619019   \nknn (v06)                                          56728.267776   \ncatboost (v06)                                     65584.773636   \nlight gradient boosting (v06)                      57557.275445   \nxg boost (v06)                                     59404.290196   \ndecision tree (v06)                                75786.490652   \nneural network m11 mega (v06)                      70213.559396   \nneural network m12 mega (v06)                       69332.77602   \nrandom forest (v06)                                75066.006975   \nneural network m05 rec deep (v06)                  73965.091349   \nneural network (v06)                               81528.266332   \nneural network m03 2 layers+wider (v06)            79170.854822   \nneural network m01 simple (v06)                    84592.356778   \nneural network simplified (v06)                    74374.117378   \nneural network m04 3 layers+wider (v06)            79160.646424   \nneural network m02 two layers (v06)                79133.370582   \nlinear regression (ridge) (v06)                    78327.560691   \n\n                                                                                   _method  \\\nxg boost (tree) (v06)                                                        random search   \nknn (v06)                                                                    random search   \ncatboost (v06)                                                   random search(no dummies)   \nlight gradient boosting (v06)                                                random search   \nxg boost (v06)                                                               random search   \ndecision tree (v06)                                                          random search   \nneural network m11 mega (v06)            loss=5.26e+09 valloss=4.98e+09 +valsplit=0.1 s...   \nneural network m12 mega (v06)            loss=4.95e+09 valloss=4.83e+09 +valsplit=0.1 +...   \nrandom forest (v06)                                                          random search   \nneural network m05 rec deep (v06)        loss=5.68e+09 valloss=5.61e+09 +valsplit=0.1 s...   \nneural network (v06)                             recommended simple model + normalise, mse   \nneural network m03 2 layers+wider (v06)  loss=6.52e+09 valloss=6.54e+09 +valsplit=0.1 s...   \nneural network m01 simple (v06)          loss=7.39e+09 valloss=7.33e+09 +valsplit=0.1 +...   \nneural network simplified (v06)          recommended simple model/mse +norm +epochs=300...   \nneural network m04 3 layers+wider (v06)  loss=6.55e+09 valloss=6.54e+09 +valsplit=0.1 s...   \nneural network m02 two layers (v06)      loss=6.53e+09 valloss=6.54e+09 +valsplit=0.1 s...   \nlinear regression (ridge) (v06)                                              random search   \n\n                                                                                   _params  \\\nxg boost (tree) (v06)                    {'model__booster': 'dart', 'model__colsample_b...   \nknn (v06)                                {'model__algorithm': 'ball_tree', 'model__leaf...   \ncatboost (v06)                           {'depth': 15, 'l2_leaf_reg': 1, 'learning_rate...   \nlight gradient boosting (v06)            {'model__boosting_type': 'dart', 'model__colsa...   \nxg boost (v06)                           {'model__booster': 'dart', 'model__early_stopp...   \ndecision tree (v06)                      {'model__ccp_alpha': 0.05, 'model__criterion':...   \nneural network m11 mega (v06)                                mse +epochs=400 +learn=0.0003   \nneural network m12 mega (v06)                                mse +epochs=400 +learn=0.0003   \nrandom forest (v06)                      {'model__bootstrap': True, 'model__ccp_alpha':...   \nneural network m05 rec deep (v06)                            mse +epochs=500 +learn=0.0003   \nneural network (v06)                                                         not available   \nneural network m03 2 layers+wider (v06)                      mse +epochs=500 +learn=0.0003   \nneural network m01 simple (v06)                                mse +epochs=50 +learn=0.003   \nneural network simplified (v06)          recommended simple model/mse +norm +epochs=300...   \nneural network m04 3 layers+wider (v06)                       mse +epochs=500 +learn=0.003   \nneural network m02 two layers (v06)                           mse +epochs=500 +learn=0.003   \nlinear regression (ridge) (v06)          {'model__alpha': 0.001, 'model__copy_X': False...   \n\n                                           _score _train time best is shared  \\\nxg boost (tree) (v06)                    0.727132  134.174901          False   \nknn (v06)                                0.715122    0.090606          False   \ncatboost (v06)                           0.619227         999          False   \nlight gradient boosting (v06)            0.706735  111.222566           True   \nxg boost (v06)                           0.687611   11.474795            NaN   \ndecision tree (v06)                      0.491556   13.949893          False   \nneural network m11 mega (v06)            0.563583      619.04          False   \nneural network m12 mega (v06)            0.574463      701.19          False   \nrandom forest (v06)                      0.501177    5.777559          False   \nneural network m05 rec deep (v06)        0.515701      817.31          False   \nneural network (v06)                     0.411595         999            NaN   \nneural network m03 2 layers+wider (v06)  0.445131     1582.25          False   \nneural network m01 simple (v06)          0.366536      163.51          False   \nneural network simplified (v06)           0.51033         999          False   \nneural network m04 3 layers+wider (v06)  0.445274       221.2          False   \nneural network m02 two layers (v06)      0.445656      216.54          False   \nlinear regression (ridge) (v06)          0.456889    0.019823          False   \n\n                                                                               best method  \\\nxg boost (tree) (v06)                                                        random search   \nknn (v06)                                                                    random search   \ncatboost (v06)                                                               random search   \nlight gradient boosting (v06)                                                random search   \nxg boost (v06)                                                               random search   \ndecision tree (v06)                                                          random search   \nneural network m11 mega (v06)                   loss=2833.6 valloss=4034.41 stop=619/1000    \nneural network m12 mega (v06)            loss=4386.51 valloss=4438.8 +valsplit=0.1 stop...   \nrandom forest (v06)                                                          random search   \nneural network m05 rec deep (v06)               loss=4908.71 valloss=4603.08 stop=214/500    \nneural network (v06)                     random search [input11, d^20-500-500-20-5, den...   \nneural network m03 2 layers+wider (v06)  mse +epochs=500 +learn=0.003 +loss=5229.047851...   \nneural network m01 simple (v06)          recommended simple model/mse +norm +epochs=50 ...   \nneural network simplified (v06)                  recommended simple model + normalise, mse   \nneural network m04 3 layers+wider (v06)          loss=5415.7 valloss=5095.94 stop=166/500    \nneural network m02 two layers (v06)      mse +norm +epochs=50 +learn=0.003 +endloss=578...   \nlinear regression (ridge) (v06)                                              random search   \n\n                                         ...                        date  \\\nxg boost (tree) (v06)                    ...  2022-12-07 09:43:37.103009   \nknn (v06)                                ...  2022-12-07 09:04:23.321690   \ncatboost (v06)                           ...  2022-12-07 09:56:18.413405   \nlight gradient boosting (v06)            ...  2022-12-07 10:31:45.923050   \nxg boost (v06)                           ...  2022-11-14 09:42:14.670928   \ndecision tree (v06)                      ...  2022-12-11 14:27:26.758775   \nneural network m11 mega (v06)            ...  2022-12-04 10:03:27.888378   \nneural network m12 mega (v06)            ...  2022-12-07 15:08:22.867761   \nrandom forest (v06)                      ...  2022-12-11 15:19:44.579522   \nneural network m05 rec deep (v06)        ...  2022-12-04 09:04:41.398760   \nneural network (v06)                     ...  2022-11-20 14:54:25.454237   \nneural network m03 2 layers+wider (v06)  ...  2022-12-04 06:56:27.034049   \nneural network m01 simple (v06)          ...  2022-12-11 18:08:58.993466   \nneural network simplified (v06)          ...  2022-11-21 17:56:15.332238   \nneural network m04 3 layers+wider (v06)  ...  2022-12-04 06:38:01.102023   \nneural network m02 two layers (v06)      ...  2022-12-04 05:30:29.106844   \nlinear regression (ridge) (v06)          ...  2022-12-07 08:12:32.333127   \n\n                                                          first run  \\\nxg boost (tree) (v06)                    2022-12-03 00:21:25.848148   \nknn (v06)                                2022-11-21 17:07:32.229750   \ncatboost (v06)                           2022-11-13 00:13:48.870697   \nlight gradient boosting (v06)            2022-11-16 13:49:11.581923   \nxg boost (v06)                           2022-11-06 22:13:02.393884   \ndecision tree (v06)                      2022-12-11 13:59:58.016969   \nneural network m11 mega (v06)            2022-11-29 12:57:16.462242   \nneural network m12 mega (v06)            2022-11-29 14:57:19.333225   \nrandom forest (v06)                      2022-12-11 12:04:23.529045   \nneural network m05 rec deep (v06)        2022-11-29 11:41:39.687521   \nneural network (v06)                     2022-11-11 01:20:17.647823   \nneural network m03 2 layers+wider (v06)  2022-11-29 09:50:03.166282   \nneural network m01 simple (v06)          2022-11-29 09:04:10.848693   \nneural network simplified (v06)          2022-11-20 15:01:27.968593   \nneural network m04 3 layers+wider (v06)  2022-11-29 11:21:09.825167   \nneural network m02 two layers (v06)      2022-11-29 09:31:18.858404   \nlinear regression (ridge) (v06)          2022-11-15 21:02:22.079702   \n\n                                        random_state   run_env  \\\nxg boost (tree) (v06)                            101  gradient   \nknn (v06)                                        101  gradient   \ncatboost (v06)                                   101  gradient   \nlight gradient boosting (v06)                    101  gradient   \nxg boost (v06)                                   101  gradient   \ndecision tree (v06)                              101  gradient   \nneural network m11 mega (v06)                    101  gradient   \nneural network m12 mega (v06)                    101  gradient   \nrandom forest (v06)                              101  gradient   \nneural network m05 rec deep (v06)                101  gradient   \nneural network (v06)                             101  gradient   \nneural network m03 2 layers+wider (v06)          101  gradient   \nneural network m01 simple (v06)                  101  gradient   \nneural network simplified (v06)                  101  gradient   \nneural network m04 3 layers+wider (v06)          101  gradient   \nneural network m02 two layers (v06)              101  gradient   \nlinear regression (ridge) (v06)                  101  gradient   \n\n                                                                             silver method  \\\nxg boost (tree) (v06)                                                        random search   \nknn (v06)                                                                    random search   \ncatboost (v06)                                                   random search(no dummies)   \nlight gradient boosting (v06)                                                random search   \nxg boost (v06)                                                                         NaN   \ndecision tree (v06)                                                          random search   \nneural network m11 mega (v06)            loss=5.26e+09 valloss=4.98e+09 +valsplit=0.1 s...   \nneural network m12 mega (v06)                  loss=3205.55 valloss=4148.49 stop=540/1000    \nrandom forest (v06)                                                          random search   \nneural network m05 rec deep (v06)                loss=4913.25 valloss=4700.2 stop=197/500    \nneural network (v06)                                   quite simple model + normalise, mse   \nneural network m03 2 layers+wider (v06)  mse +norm +epochs=500 +learn=0.003 +stop=154 +...   \nneural network m01 simple (v06)          recommended simple model/mse +norm +epochs=50 ...   \nneural network simplified (v06)          recommended simple model/mse +norm +epochs=300...   \nneural network m04 3 layers+wider (v06)  loss=6.55e+09 valloss=6.54e+09 +valsplit=0.1 s...   \nneural network m02 two layers (v06)      mse +norm +epochs=500 +learn=0.003 +stop=32 +e...   \nlinear regression (ridge) (v06)                                              random search   \n\n                                                                             silver params  \\\nxg boost (tree) (v06)                    {'model__booster': 'dart', 'model__colsample_b...   \nknn (v06)                                {'model__algorithm': 'brute', 'model__leaf_siz...   \ncatboost (v06)                           {'depth': 15, 'l2_leaf_reg': 1, 'learning_rate...   \nlight gradient boosting (v06)            {'model__boosting_type': 'dart', 'model__colsa...   \nxg boost (v06)                                                                         NaN   \ndecision tree (v06)                      {'model__ccp_alpha': 0.1, 'model__criterion': ...   \nneural network m11 mega (v06)                                mse +epochs=400 +learn=0.0003   \nneural network m12 mega (v06)                               mse +epochs=1000 +learn=0.0003   \nrandom forest (v06)                      {'model__bootstrap': True, 'model__ccp_alpha':...   \nneural network m05 rec deep (v06)                            mse +epochs=500 +learn=0.0003   \nneural network (v06)                                                         not available   \nneural network m03 2 layers+wider (v06)  mse +norm +epochs=500 +learn=0.003 +stop=154 +...   \nneural network m01 simple (v06)          recommended simple model/mse +norm +epochs=50 ...   \nneural network simplified (v06)          recommended simple model/mse +norm +epochs=300...   \nneural network m04 3 layers+wider (v06)                       mse +epochs=500 +learn=0.003   \nneural network m02 two layers (v06)      mse +norm +epochs=500 +learn=0.003 +stop=32 +e...   \nlinear regression (ridge) (v06)          {'model__alpha': 0.0001, 'model__copy_X': Fals...   \n\n                                                    silver run date  \\\nxg boost (tree) (v06)                    2022-12-03 00:21:25.790717   \nknn (v06)                                2022-11-21 17:07:32.228547   \ncatboost (v06)                           2022-12-03 16:27:55.193043   \nlight gradient boosting (v06)            2022-12-07 10:31:45.923050   \nxg boost (v06)                                                  NaN   \ndecision tree (v06)                      2022-12-11 14:24:11.134622   \nneural network m11 mega (v06)            2022-12-04 10:03:27.888378   \nneural network m12 mega (v06)            2022-11-29 14:57:19.331629   \nrandom forest (v06)                      2022-12-11 13:02:31.973811   \nneural network m05 rec deep (v06)        2022-11-29 12:04:25.727274   \nneural network (v06)                     2022-11-20 13:46:58.237840   \nneural network m03 2 layers+wider (v06)  2022-11-29 09:50:03.096053   \nneural network m01 simple (v06)          2022-11-29 09:06:27.904880   \nneural network simplified (v06)          2022-11-21 17:56:15.332238   \nneural network m04 3 layers+wider (v06)  2022-12-04 06:38:01.102023   \nneural network m02 two layers (v06)      2022-11-29 09:35:17.501089   \nlinear regression (ridge) (v06)          2022-12-03 19:28:37.848562   \n\n                                        silver score silver time  suboptimal  \nxg boost (tree) (v06)                       0.725989  217.285686     pending  \nknn (v06)                                   0.719049    0.018388  suboptimal  \ncatboost (v06)                              0.619227         999  suboptimal  \nlight gradient boosting (v06)               0.706735  111.222566  suboptimal  \nxg boost (v06)                                   NaN         NaN     pending  \ndecision tree (v06)                         0.579448    0.101299  suboptimal  \nneural network m11 mega (v06)               0.563583      619.04  suboptimal  \nneural network m12 mega (v06)                0.59056     1714.15  suboptimal  \nrandom forest (v06)                         0.584706  286.298005  suboptimal  \nneural network m05 rec deep (v06)           0.564694      524.81  suboptimal  \nneural network (v06)                        0.471666         999  suboptimal  \nneural network m03 2 layers+wider (v06)     0.540557      343.65  suboptimal  \nneural network m01 simple (v06)              0.53227      104.31  suboptimal  \nneural network simplified (v06)              0.51033         999  suboptimal  \nneural network m04 3 layers+wider (v06)     0.445274       221.2  suboptimal  \nneural network m02 two layers (v06)         0.505803       71.81  suboptimal  \nlinear regression (ridge) (v06)               0.4569    0.244021  suboptimal  \n\n[17 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean Absolute Error Accuracy</th>\n      <th>Mean Squared Error Accuracy</th>\n      <th>R square Accuracy</th>\n      <th>Root Mean Squared Error</th>\n      <th>_method</th>\n      <th>_params</th>\n      <th>_score</th>\n      <th>_train time</th>\n      <th>best is shared</th>\n      <th>best method</th>\n      <th>...</th>\n      <th>date</th>\n      <th>first run</th>\n      <th>random_state</th>\n      <th>run_env</th>\n      <th>silver method</th>\n      <th>silver params</th>\n      <th>silver run date</th>\n      <th>silver score</th>\n      <th>silver time</th>\n      <th>suboptimal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>xg boost (tree) (v06)</th>\n      <td>41210.351288</td>\n      <td>3082428096.006462</td>\n      <td>0.727132</td>\n      <td>55519.619019</td>\n      <td>random search</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>0.727132</td>\n      <td>134.174901</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2022-12-07 09:43:37.103009</td>\n      <td>2022-12-03 00:21:25.848148</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>2022-12-03 00:21:25.790717</td>\n      <td>0.725989</td>\n      <td>217.285686</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>knn (v06)</th>\n      <td>41531.119915</td>\n      <td>3218096364.819358</td>\n      <td>0.715122</td>\n      <td>56728.267776</td>\n      <td>random search</td>\n      <td>{'model__algorithm': 'ball_tree', 'model__leaf...</td>\n      <td>0.715122</td>\n      <td>0.090606</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2022-12-07 09:04:23.321690</td>\n      <td>2022-11-21 17:07:32.229750</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search</td>\n      <td>{'model__algorithm': 'brute', 'model__leaf_siz...</td>\n      <td>2022-11-21 17:07:32.228547</td>\n      <td>0.719049</td>\n      <td>0.018388</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>catboost (v06)</th>\n      <td>51000.047694</td>\n      <td>4301362532.917062</td>\n      <td>0.619227</td>\n      <td>65584.773636</td>\n      <td>random search(no dummies)</td>\n      <td>{'depth': 15, 'l2_leaf_reg': 1, 'learning_rate...</td>\n      <td>0.619227</td>\n      <td>999</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2022-12-07 09:56:18.413405</td>\n      <td>2022-11-13 00:13:48.870697</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search(no dummies)</td>\n      <td>{'depth': 15, 'l2_leaf_reg': 1, 'learning_rate...</td>\n      <td>2022-12-03 16:27:55.193043</td>\n      <td>0.619227</td>\n      <td>999</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>light gradient boosting (v06)</th>\n      <td>44080.972643</td>\n      <td>3312839956.633489</td>\n      <td>0.706735</td>\n      <td>57557.275445</td>\n      <td>random search</td>\n      <td>{'model__boosting_type': 'dart', 'model__colsa...</td>\n      <td>0.706735</td>\n      <td>111.222566</td>\n      <td>True</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2022-12-07 10:31:45.923050</td>\n      <td>2022-11-16 13:49:11.581923</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search</td>\n      <td>{'model__boosting_type': 'dart', 'model__colsa...</td>\n      <td>2022-12-07 10:31:45.923050</td>\n      <td>0.706735</td>\n      <td>111.222566</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>xg boost (v06)</th>\n      <td>45988.280765</td>\n      <td>3528869693.681411</td>\n      <td>0.687611</td>\n      <td>59404.290196</td>\n      <td>random search</td>\n      <td>{'model__booster': 'dart', 'model__early_stopp...</td>\n      <td>0.687611</td>\n      <td>11.474795</td>\n      <td>NaN</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2022-11-14 09:42:14.670928</td>\n      <td>2022-11-06 22:13:02.393884</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>decision tree (v06)</th>\n      <td>59431.108316</td>\n      <td>5743592165.314412</td>\n      <td>0.491556</td>\n      <td>75786.490652</td>\n      <td>random search</td>\n      <td>{'model__ccp_alpha': 0.05, 'model__criterion':...</td>\n      <td>0.491556</td>\n      <td>13.949893</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2022-12-11 14:27:26.758775</td>\n      <td>2022-12-11 13:59:58.016969</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search</td>\n      <td>{'model__ccp_alpha': 0.1, 'model__criterion': ...</td>\n      <td>2022-12-11 14:24:11.134622</td>\n      <td>0.579448</td>\n      <td>0.101299</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network m11 mega (v06)</th>\n      <td>56035.854723</td>\n      <td>4929943923.096645</td>\n      <td>0.563583</td>\n      <td>70213.559396</td>\n      <td>loss=5.26e+09 valloss=4.98e+09 +valsplit=0.1 s...</td>\n      <td>mse +epochs=400 +learn=0.0003</td>\n      <td>0.563583</td>\n      <td>619.04</td>\n      <td>False</td>\n      <td>loss=2833.6 valloss=4034.41 stop=619/1000</td>\n      <td>...</td>\n      <td>2022-12-04 10:03:27.888378</td>\n      <td>2022-11-29 12:57:16.462242</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>loss=5.26e+09 valloss=4.98e+09 +valsplit=0.1 s...</td>\n      <td>mse +epochs=400 +learn=0.0003</td>\n      <td>2022-12-04 10:03:27.888378</td>\n      <td>0.563583</td>\n      <td>619.04</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network m12 mega (v06)</th>\n      <td>54967.975952</td>\n      <td>4807033830.676171</td>\n      <td>0.574463</td>\n      <td>69332.77602</td>\n      <td>loss=4.95e+09 valloss=4.83e+09 +valsplit=0.1 +...</td>\n      <td>mse +epochs=400 +learn=0.0003</td>\n      <td>0.574463</td>\n      <td>701.19</td>\n      <td>False</td>\n      <td>loss=4386.51 valloss=4438.8 +valsplit=0.1 stop...</td>\n      <td>...</td>\n      <td>2022-12-07 15:08:22.867761</td>\n      <td>2022-11-29 14:57:19.333225</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>loss=3205.55 valloss=4148.49 stop=540/1000</td>\n      <td>mse +epochs=1000 +learn=0.0003</td>\n      <td>2022-11-29 14:57:19.331629</td>\n      <td>0.59056</td>\n      <td>1714.15</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>random forest (v06)</th>\n      <td>60536.998438</td>\n      <td>5634905403.102844</td>\n      <td>0.501177</td>\n      <td>75066.006975</td>\n      <td>random search</td>\n      <td>{'model__bootstrap': True, 'model__ccp_alpha':...</td>\n      <td>0.501177</td>\n      <td>5.777559</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2022-12-11 15:19:44.579522</td>\n      <td>2022-12-11 12:04:23.529045</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search</td>\n      <td>{'model__bootstrap': True, 'model__ccp_alpha':...</td>\n      <td>2022-12-11 13:02:31.973811</td>\n      <td>0.584706</td>\n      <td>286.298005</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network m05 rec deep (v06)</th>\n      <td>59357.533817</td>\n      <td>5470834738.338646</td>\n      <td>0.515701</td>\n      <td>73965.091349</td>\n      <td>loss=5.68e+09 valloss=5.61e+09 +valsplit=0.1 s...</td>\n      <td>mse +epochs=500 +learn=0.0003</td>\n      <td>0.515701</td>\n      <td>817.31</td>\n      <td>False</td>\n      <td>loss=4908.71 valloss=4603.08 stop=214/500</td>\n      <td>...</td>\n      <td>2022-12-04 09:04:41.398760</td>\n      <td>2022-11-29 11:41:39.687521</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>loss=4913.25 valloss=4700.2 stop=197/500</td>\n      <td>mse +epochs=500 +learn=0.0003</td>\n      <td>2022-11-29 12:04:25.727274</td>\n      <td>0.564694</td>\n      <td>524.81</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network (v06)</th>\n      <td>66710.702966</td>\n      <td>6646858211.119819</td>\n      <td>0.411595</td>\n      <td>81528.266332</td>\n      <td>recommended simple model + normalise, mse</td>\n      <td>not available</td>\n      <td>0.411595</td>\n      <td>999</td>\n      <td>NaN</td>\n      <td>random search [input11, d^20-500-500-20-5, den...</td>\n      <td>...</td>\n      <td>2022-11-20 14:54:25.454237</td>\n      <td>2022-11-11 01:20:17.647823</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>quite simple model + normalise, mse</td>\n      <td>not available</td>\n      <td>2022-11-20 13:46:58.237840</td>\n      <td>0.471666</td>\n      <td>999</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network m03 2 layers+wider (v06)</th>\n      <td>64376.517431</td>\n      <td>6268024253.295089</td>\n      <td>0.445131</td>\n      <td>79170.854822</td>\n      <td>loss=6.52e+09 valloss=6.54e+09 +valsplit=0.1 s...</td>\n      <td>mse +epochs=500 +learn=0.0003</td>\n      <td>0.445131</td>\n      <td>1582.25</td>\n      <td>False</td>\n      <td>mse +epochs=500 +learn=0.003 +loss=5229.047851...</td>\n      <td>...</td>\n      <td>2022-12-04 06:56:27.034049</td>\n      <td>2022-11-29 09:50:03.166282</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>mse +norm +epochs=500 +learn=0.003 +stop=154 +...</td>\n      <td>mse +norm +epochs=500 +learn=0.003 +stop=154 +...</td>\n      <td>2022-11-29 09:50:03.096053</td>\n      <td>0.540557</td>\n      <td>343.65</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network m01 simple (v06)</th>\n      <td>69131.972772</td>\n      <td>7155866825.337951</td>\n      <td>0.366536</td>\n      <td>84592.356778</td>\n      <td>loss=7.39e+09 valloss=7.33e+09 +valsplit=0.1 +...</td>\n      <td>mse +epochs=50 +learn=0.003</td>\n      <td>0.366536</td>\n      <td>163.51</td>\n      <td>False</td>\n      <td>recommended simple model/mse +norm +epochs=50 ...</td>\n      <td>...</td>\n      <td>2022-12-11 18:08:58.993466</td>\n      <td>2022-11-29 09:04:10.848693</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>recommended simple model/mse +norm +epochs=50 ...</td>\n      <td>recommended simple model/mse +norm +epochs=50 ...</td>\n      <td>2022-11-29 09:06:27.904880</td>\n      <td>0.53227</td>\n      <td>104.31</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network simplified (v06)</th>\n      <td>59373.052887</td>\n      <td>5531509335.791807</td>\n      <td>0.51033</td>\n      <td>74374.117378</td>\n      <td>recommended simple model/mse +norm +epochs=300...</td>\n      <td>recommended simple model/mse +norm +epochs=300...</td>\n      <td>0.51033</td>\n      <td>999</td>\n      <td>False</td>\n      <td>recommended simple model + normalise, mse</td>\n      <td>...</td>\n      <td>2022-11-21 17:56:15.332238</td>\n      <td>2022-11-20 15:01:27.968593</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>recommended simple model/mse +norm +epochs=300...</td>\n      <td>recommended simple model/mse +norm +epochs=300...</td>\n      <td>2022-11-21 17:56:15.332238</td>\n      <td>0.51033</td>\n      <td>999</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network m04 3 layers+wider (v06)</th>\n      <td>64421.234531</td>\n      <td>6266407942.292152</td>\n      <td>0.445274</td>\n      <td>79160.646424</td>\n      <td>loss=6.55e+09 valloss=6.54e+09 +valsplit=0.1 s...</td>\n      <td>mse +epochs=500 +learn=0.003</td>\n      <td>0.445274</td>\n      <td>221.2</td>\n      <td>False</td>\n      <td>loss=5415.7 valloss=5095.94 stop=166/500</td>\n      <td>...</td>\n      <td>2022-12-04 06:38:01.102023</td>\n      <td>2022-11-29 11:21:09.825167</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>loss=6.55e+09 valloss=6.54e+09 +valsplit=0.1 s...</td>\n      <td>mse +epochs=500 +learn=0.003</td>\n      <td>2022-12-04 06:38:01.102023</td>\n      <td>0.445274</td>\n      <td>221.2</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>neural network m02 two layers (v06)</th>\n      <td>64363.094125</td>\n      <td>6262090339.685114</td>\n      <td>0.445656</td>\n      <td>79133.370582</td>\n      <td>loss=6.53e+09 valloss=6.54e+09 +valsplit=0.1 s...</td>\n      <td>mse +epochs=500 +learn=0.003</td>\n      <td>0.445656</td>\n      <td>216.54</td>\n      <td>False</td>\n      <td>mse +norm +epochs=50 +learn=0.003 +endloss=578...</td>\n      <td>...</td>\n      <td>2022-12-04 05:30:29.106844</td>\n      <td>2022-11-29 09:31:18.858404</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>mse +norm +epochs=500 +learn=0.003 +stop=32 +e...</td>\n      <td>mse +norm +epochs=500 +learn=0.003 +stop=32 +e...</td>\n      <td>2022-11-29 09:35:17.501089</td>\n      <td>0.505803</td>\n      <td>71.81</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v06)</th>\n      <td>63603.059705</td>\n      <td>6135206763.74439</td>\n      <td>0.456889</td>\n      <td>78327.560691</td>\n      <td>random search</td>\n      <td>{'model__alpha': 0.001, 'model__copy_X': False...</td>\n      <td>0.456889</td>\n      <td>0.019823</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2022-12-07 08:12:32.333127</td>\n      <td>2022-11-15 21:02:22.079702</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search</td>\n      <td>{'model__alpha': 0.0001, 'model__copy_X': Fals...</td>\n      <td>2022-12-03 19:28:37.848562</td>\n      <td>0.4569</td>\n      <td>0.244021</td>\n      <td>suboptimal</td>\n    </tr>\n  </tbody>\n</table>\n<p>17 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_versions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-11T17:58:27.459481Z",
     "iopub.status.busy": "2022-12-11T17:58:27.459230Z",
     "iopub.status.idle": "2022-12-11T17:58:27.472176Z",
     "shell.execute_reply": "2022-12-11T17:58:27.471352Z",
     "shell.execute_reply.started": "2022-12-11T17:58:27.459459Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                        best score   best time silver score  \\\nxg boost (tree) (v06)                     0.727132  134.174901     0.725989   \nknn (v06)                                 0.719049    0.017916     0.719049   \ncatboost (v06)                            0.715606   12.256545     0.619227   \nlight gradient boosting (v06)             0.706735   15.043873     0.706735   \nxg boost (v06)                            0.687611   11.474795          NaN   \ndecision tree (v06)                       0.616727    0.133738     0.579448   \nneural network m11 mega (v06)             0.612318     2569.45     0.563583   \nneural network m12 mega (v06)             0.594032      813.27      0.59056   \nrandom forest (v06)                       0.585876    1.769856     0.584706   \nneural network m05 rec deep (v06)         0.580348       604.9     0.564694   \nneural network (v06)                      0.556696  312.991321     0.471666   \nneural network m03 2 layers+wider (v06)   0.549647      275.71     0.540557   \nneural network m01 simple (v06)           0.541221        36.2      0.53227   \nneural network simplified (v06)           0.540642         999      0.51033   \nneural network m04 3 layers+wider (v06)   0.520933      395.14     0.445274   \nneural network m02 two layers (v06)       0.516773      112.54     0.505803   \nlinear regression (ridge) (v06)             0.4569     0.28695       0.4569   \n\n                                        silver time  \\\nxg boost (tree) (v06)                    217.285686   \nknn (v06)                                  0.018388   \ncatboost (v06)                                  999   \nlight gradient boosting (v06)            111.222566   \nxg boost (v06)                                  NaN   \ndecision tree (v06)                        0.101299   \nneural network m11 mega (v06)                619.04   \nneural network m12 mega (v06)               1714.15   \nrandom forest (v06)                      286.298005   \nneural network m05 rec deep (v06)            524.81   \nneural network (v06)                            999   \nneural network m03 2 layers+wider (v06)      343.65   \nneural network m01 simple (v06)              104.31   \nneural network simplified (v06)                 999   \nneural network m04 3 layers+wider (v06)       221.2   \nneural network m02 two layers (v06)           71.81   \nlinear regression (ridge) (v06)            0.244021   \n\n                                                                               best method  \\\nxg boost (tree) (v06)                                                        random search   \nknn (v06)                                                                    random search   \ncatboost (v06)                                                               random search   \nlight gradient boosting (v06)                                                random search   \nxg boost (v06)                                                               random search   \ndecision tree (v06)                                                          random search   \nneural network m11 mega (v06)                   loss=2833.6 valloss=4034.41 stop=619/1000    \nneural network m12 mega (v06)            loss=4386.51 valloss=4438.8 +valsplit=0.1 stop...   \nrandom forest (v06)                                                          random search   \nneural network m05 rec deep (v06)               loss=4908.71 valloss=4603.08 stop=214/500    \nneural network (v06)                     random search [input11, d^20-500-500-20-5, den...   \nneural network m03 2 layers+wider (v06)  mse +epochs=500 +learn=0.003 +loss=5229.047851...   \nneural network m01 simple (v06)          recommended simple model/mse +norm +epochs=50 ...   \nneural network simplified (v06)                  recommended simple model + normalise, mse   \nneural network m04 3 layers+wider (v06)          loss=5415.7 valloss=5095.94 stop=166/500    \nneural network m02 two layers (v06)      mse +norm +epochs=50 +learn=0.003 +endloss=578...   \nlinear regression (ridge) (v06)                                              random search   \n\n                                                                             silver method  \\\nxg boost (tree) (v06)                                                        random search   \nknn (v06)                                                                    random search   \ncatboost (v06)                                                   random search(no dummies)   \nlight gradient boosting (v06)                                                random search   \nxg boost (v06)                                                                         NaN   \ndecision tree (v06)                                                          random search   \nneural network m11 mega (v06)            loss=5.26e+09 valloss=4.98e+09 +valsplit=0.1 s...   \nneural network m12 mega (v06)                  loss=3205.55 valloss=4148.49 stop=540/1000    \nrandom forest (v06)                                                          random search   \nneural network m05 rec deep (v06)                loss=4913.25 valloss=4700.2 stop=197/500    \nneural network (v06)                                   quite simple model + normalise, mse   \nneural network m03 2 layers+wider (v06)  mse +norm +epochs=500 +learn=0.003 +stop=154 +...   \nneural network m01 simple (v06)          recommended simple model/mse +norm +epochs=50 ...   \nneural network simplified (v06)          recommended simple model/mse +norm +epochs=300...   \nneural network m04 3 layers+wider (v06)  loss=6.55e+09 valloss=6.54e+09 +valsplit=0.1 s...   \nneural network m02 two layers (v06)      mse +norm +epochs=500 +learn=0.003 +stop=32 +e...   \nlinear regression (ridge) (v06)                                              random search   \n\n                                        best is shared  \nxg boost (tree) (v06)                            False  \nknn (v06)                                        False  \ncatboost (v06)                                   False  \nlight gradient boosting (v06)                     True  \nxg boost (v06)                                     NaN  \ndecision tree (v06)                              False  \nneural network m11 mega (v06)                    False  \nneural network m12 mega (v06)                    False  \nrandom forest (v06)                              False  \nneural network m05 rec deep (v06)                False  \nneural network (v06)                               NaN  \nneural network m03 2 layers+wider (v06)          False  \nneural network m01 simple (v06)                  False  \nneural network simplified (v06)                  False  \nneural network m04 3 layers+wider (v06)          False  \nneural network m02 two layers (v06)              False  \nlinear regression (ridge) (v06)                  False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best score</th>\n      <th>best time</th>\n      <th>silver score</th>\n      <th>silver time</th>\n      <th>best method</th>\n      <th>silver method</th>\n      <th>best is shared</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>xg boost (tree) (v06)</th>\n      <td>0.727132</td>\n      <td>134.174901</td>\n      <td>0.725989</td>\n      <td>217.285686</td>\n      <td>random search</td>\n      <td>random search</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>knn (v06)</th>\n      <td>0.719049</td>\n      <td>0.017916</td>\n      <td>0.719049</td>\n      <td>0.018388</td>\n      <td>random search</td>\n      <td>random search</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>catboost (v06)</th>\n      <td>0.715606</td>\n      <td>12.256545</td>\n      <td>0.619227</td>\n      <td>999</td>\n      <td>random search</td>\n      <td>random search(no dummies)</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>light gradient boosting (v06)</th>\n      <td>0.706735</td>\n      <td>15.043873</td>\n      <td>0.706735</td>\n      <td>111.222566</td>\n      <td>random search</td>\n      <td>random search</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>xg boost (v06)</th>\n      <td>0.687611</td>\n      <td>11.474795</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>random search</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>decision tree (v06)</th>\n      <td>0.616727</td>\n      <td>0.133738</td>\n      <td>0.579448</td>\n      <td>0.101299</td>\n      <td>random search</td>\n      <td>random search</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m11 mega (v06)</th>\n      <td>0.612318</td>\n      <td>2569.45</td>\n      <td>0.563583</td>\n      <td>619.04</td>\n      <td>loss=2833.6 valloss=4034.41 stop=619/1000</td>\n      <td>loss=5.26e+09 valloss=4.98e+09 +valsplit=0.1 s...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m12 mega (v06)</th>\n      <td>0.594032</td>\n      <td>813.27</td>\n      <td>0.59056</td>\n      <td>1714.15</td>\n      <td>loss=4386.51 valloss=4438.8 +valsplit=0.1 stop...</td>\n      <td>loss=3205.55 valloss=4148.49 stop=540/1000</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>random forest (v06)</th>\n      <td>0.585876</td>\n      <td>1.769856</td>\n      <td>0.584706</td>\n      <td>286.298005</td>\n      <td>random search</td>\n      <td>random search</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m05 rec deep (v06)</th>\n      <td>0.580348</td>\n      <td>604.9</td>\n      <td>0.564694</td>\n      <td>524.81</td>\n      <td>loss=4908.71 valloss=4603.08 stop=214/500</td>\n      <td>loss=4913.25 valloss=4700.2 stop=197/500</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network (v06)</th>\n      <td>0.556696</td>\n      <td>312.991321</td>\n      <td>0.471666</td>\n      <td>999</td>\n      <td>random search [input11, d^20-500-500-20-5, den...</td>\n      <td>quite simple model + normalise, mse</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>neural network m03 2 layers+wider (v06)</th>\n      <td>0.549647</td>\n      <td>275.71</td>\n      <td>0.540557</td>\n      <td>343.65</td>\n      <td>mse +epochs=500 +learn=0.003 +loss=5229.047851...</td>\n      <td>mse +norm +epochs=500 +learn=0.003 +stop=154 +...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m01 simple (v06)</th>\n      <td>0.541221</td>\n      <td>36.2</td>\n      <td>0.53227</td>\n      <td>104.31</td>\n      <td>recommended simple model/mse +norm +epochs=50 ...</td>\n      <td>recommended simple model/mse +norm +epochs=50 ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network simplified (v06)</th>\n      <td>0.540642</td>\n      <td>999</td>\n      <td>0.51033</td>\n      <td>999</td>\n      <td>recommended simple model + normalise, mse</td>\n      <td>recommended simple model/mse +norm +epochs=300...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m04 3 layers+wider (v06)</th>\n      <td>0.520933</td>\n      <td>395.14</td>\n      <td>0.445274</td>\n      <td>221.2</td>\n      <td>loss=5415.7 valloss=5095.94 stop=166/500</td>\n      <td>loss=6.55e+09 valloss=6.54e+09 +valsplit=0.1 s...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m02 two layers (v06)</th>\n      <td>0.516773</td>\n      <td>112.54</td>\n      <td>0.505803</td>\n      <td>71.81</td>\n      <td>mse +norm +epochs=50 +learn=0.003 +endloss=578...</td>\n      <td>mse +norm +epochs=500 +learn=0.003 +stop=32 +e...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v06)</th>\n      <td>0.4569</td>\n      <td>0.28695</td>\n      <td>0.4569</td>\n      <td>0.244021</td>\n      <td>random search</td>\n      <td>random search</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_1_vs_2 = dataset_versions_df[\n",
    "    ['best score', 'best time', 'silver score', 'silver time', 'best method', 'silver method', 'best is shared']]\n",
    "df_summary_1_vs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-11T17:58:27.473783Z",
     "iopub.status.busy": "2022-12-11T17:58:27.473530Z",
     "iopub.status.idle": "2022-12-11T17:58:27.490023Z",
     "shell.execute_reply": "2022-12-11T17:58:27.489187Z",
     "shell.execute_reply.started": "2022-12-11T17:58:27.473760Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                        best score   best time silver score  \\\nxg boost (tree) (v06)                     0.727132  134.174901     0.725989   \nknn (v06)                                 0.719049    0.017916     0.719049   \ncatboost (v06)                            0.715606   12.256545     0.619227   \nlight gradient boosting (v06)             0.706735   15.043873     0.706735   \nxg boost (v06)                            0.687611   11.474795          NaN   \ndecision tree (v06)                       0.616727    0.133738     0.579448   \nneural network m11 mega (v06)             0.612318     2569.45     0.563583   \nneural network m12 mega (v06)             0.594032      813.27      0.59056   \nrandom forest (v06)                       0.585876    1.769856     0.584706   \nneural network m05 rec deep (v06)         0.580348       604.9     0.564694   \nneural network (v06)                      0.556696  312.991321     0.471666   \nneural network m03 2 layers+wider (v06)   0.549647      275.71     0.540557   \nneural network m01 simple (v06)           0.541221        36.2      0.53227   \nneural network simplified (v06)           0.540642         999      0.51033   \nneural network m04 3 layers+wider (v06)   0.520933      395.14     0.445274   \nneural network m02 two layers (v06)       0.516773      112.54     0.505803   \nlinear regression (ridge) (v06)             0.4569     0.28695       0.4569   \n\n                                        silver time  \\\nxg boost (tree) (v06)                    217.285686   \nknn (v06)                                  0.018388   \ncatboost (v06)                                  999   \nlight gradient boosting (v06)            111.222566   \nxg boost (v06)                                  NaN   \ndecision tree (v06)                        0.101299   \nneural network m11 mega (v06)                619.04   \nneural network m12 mega (v06)               1714.15   \nrandom forest (v06)                      286.298005   \nneural network m05 rec deep (v06)            524.81   \nneural network (v06)                            999   \nneural network m03 2 layers+wider (v06)      343.65   \nneural network m01 simple (v06)              104.31   \nneural network simplified (v06)                 999   \nneural network m04 3 layers+wider (v06)       221.2   \nneural network m02 two layers (v06)           71.81   \nlinear regression (ridge) (v06)            0.244021   \n\n                                                                               best params  \\\nxg boost (tree) (v06)                    {'model__booster': 'dart', 'model__colsample_b...   \nknn (v06)                                {'model__algorithm': 'brute', 'model__leaf_siz...   \ncatboost (v06)                           {'model__depth': 8, 'model__l2_leaf_reg': 1, '...   \nlight gradient boosting (v06)            {'model__boosting_type': 'dart', 'model__colsa...   \nxg boost (v06)                           {'model__booster': 'dart', 'model__early_stopp...   \ndecision tree (v06)                      {'model__ccp_alpha': 0.0, 'model__criterion': ...   \nneural network m11 mega (v06)                                mse +epochs=1000 +learn=3e-05   \nneural network m12 mega (v06)                                mse +epochs=400 +learn=0.0003   \nrandom forest (v06)                      {'model__bootstrap': True, 'model__ccp_alpha':...   \nneural network m05 rec deep (v06)                            mse +epochs=500 +learn=0.0003   \nneural network (v06)                     {'model__batch_size': 100, 'model__epochs': 50...   \nneural network m03 2 layers+wider (v06)  mse +epochs=500 +learn=0.003 +loss=5229.047851...   \nneural network m01 simple (v06)          recommended simple model/mse +norm +epochs=50 ...   \nneural network simplified (v06)                  recommended simple model + normalise, mse   \nneural network m04 3 layers+wider (v06)                       mse +epochs=500 +learn=0.003   \nneural network m02 two layers (v06)      mse +norm +epochs=50 +learn=0.003 +endloss=578...   \nlinear regression (ridge) (v06)          {'model__alpha': 1e-05, 'model__copy_X': False...   \n\n                                                                             silver params  \\\nxg boost (tree) (v06)                    {'model__booster': 'dart', 'model__colsample_b...   \nknn (v06)                                {'model__algorithm': 'brute', 'model__leaf_siz...   \ncatboost (v06)                           {'depth': 15, 'l2_leaf_reg': 1, 'learning_rate...   \nlight gradient boosting (v06)            {'model__boosting_type': 'dart', 'model__colsa...   \nxg boost (v06)                                                                         NaN   \ndecision tree (v06)                      {'model__ccp_alpha': 0.1, 'model__criterion': ...   \nneural network m11 mega (v06)                                mse +epochs=400 +learn=0.0003   \nneural network m12 mega (v06)                               mse +epochs=1000 +learn=0.0003   \nrandom forest (v06)                      {'model__bootstrap': True, 'model__ccp_alpha':...   \nneural network m05 rec deep (v06)                            mse +epochs=500 +learn=0.0003   \nneural network (v06)                                                         not available   \nneural network m03 2 layers+wider (v06)  mse +norm +epochs=500 +learn=0.003 +stop=154 +...   \nneural network m01 simple (v06)          recommended simple model/mse +norm +epochs=50 ...   \nneural network simplified (v06)          recommended simple model/mse +norm +epochs=300...   \nneural network m04 3 layers+wider (v06)                       mse +epochs=500 +learn=0.003   \nneural network m02 two layers (v06)      mse +norm +epochs=500 +learn=0.003 +stop=32 +e...   \nlinear regression (ridge) (v06)          {'model__alpha': 0.0001, 'model__copy_X': Fals...   \n\n                                        best is shared  \nxg boost (tree) (v06)                            False  \nknn (v06)                                        False  \ncatboost (v06)                                   False  \nlight gradient boosting (v06)                     True  \nxg boost (v06)                                     NaN  \ndecision tree (v06)                              False  \nneural network m11 mega (v06)                    False  \nneural network m12 mega (v06)                    False  \nrandom forest (v06)                              False  \nneural network m05 rec deep (v06)                False  \nneural network (v06)                               NaN  \nneural network m03 2 layers+wider (v06)          False  \nneural network m01 simple (v06)                  False  \nneural network simplified (v06)                  False  \nneural network m04 3 layers+wider (v06)          False  \nneural network m02 two layers (v06)              False  \nlinear regression (ridge) (v06)                  False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best score</th>\n      <th>best time</th>\n      <th>silver score</th>\n      <th>silver time</th>\n      <th>best params</th>\n      <th>silver params</th>\n      <th>best is shared</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>xg boost (tree) (v06)</th>\n      <td>0.727132</td>\n      <td>134.174901</td>\n      <td>0.725989</td>\n      <td>217.285686</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>knn (v06)</th>\n      <td>0.719049</td>\n      <td>0.017916</td>\n      <td>0.719049</td>\n      <td>0.018388</td>\n      <td>{'model__algorithm': 'brute', 'model__leaf_siz...</td>\n      <td>{'model__algorithm': 'brute', 'model__leaf_siz...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>catboost (v06)</th>\n      <td>0.715606</td>\n      <td>12.256545</td>\n      <td>0.619227</td>\n      <td>999</td>\n      <td>{'model__depth': 8, 'model__l2_leaf_reg': 1, '...</td>\n      <td>{'depth': 15, 'l2_leaf_reg': 1, 'learning_rate...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>light gradient boosting (v06)</th>\n      <td>0.706735</td>\n      <td>15.043873</td>\n      <td>0.706735</td>\n      <td>111.222566</td>\n      <td>{'model__boosting_type': 'dart', 'model__colsa...</td>\n      <td>{'model__boosting_type': 'dart', 'model__colsa...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>xg boost (v06)</th>\n      <td>0.687611</td>\n      <td>11.474795</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'model__booster': 'dart', 'model__early_stopp...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>decision tree (v06)</th>\n      <td>0.616727</td>\n      <td>0.133738</td>\n      <td>0.579448</td>\n      <td>0.101299</td>\n      <td>{'model__ccp_alpha': 0.0, 'model__criterion': ...</td>\n      <td>{'model__ccp_alpha': 0.1, 'model__criterion': ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m11 mega (v06)</th>\n      <td>0.612318</td>\n      <td>2569.45</td>\n      <td>0.563583</td>\n      <td>619.04</td>\n      <td>mse +epochs=1000 +learn=3e-05</td>\n      <td>mse +epochs=400 +learn=0.0003</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m12 mega (v06)</th>\n      <td>0.594032</td>\n      <td>813.27</td>\n      <td>0.59056</td>\n      <td>1714.15</td>\n      <td>mse +epochs=400 +learn=0.0003</td>\n      <td>mse +epochs=1000 +learn=0.0003</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>random forest (v06)</th>\n      <td>0.585876</td>\n      <td>1.769856</td>\n      <td>0.584706</td>\n      <td>286.298005</td>\n      <td>{'model__bootstrap': True, 'model__ccp_alpha':...</td>\n      <td>{'model__bootstrap': True, 'model__ccp_alpha':...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m05 rec deep (v06)</th>\n      <td>0.580348</td>\n      <td>604.9</td>\n      <td>0.564694</td>\n      <td>524.81</td>\n      <td>mse +epochs=500 +learn=0.0003</td>\n      <td>mse +epochs=500 +learn=0.0003</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network (v06)</th>\n      <td>0.556696</td>\n      <td>312.991321</td>\n      <td>0.471666</td>\n      <td>999</td>\n      <td>{'model__batch_size': 100, 'model__epochs': 50...</td>\n      <td>not available</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>neural network m03 2 layers+wider (v06)</th>\n      <td>0.549647</td>\n      <td>275.71</td>\n      <td>0.540557</td>\n      <td>343.65</td>\n      <td>mse +epochs=500 +learn=0.003 +loss=5229.047851...</td>\n      <td>mse +norm +epochs=500 +learn=0.003 +stop=154 +...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m01 simple (v06)</th>\n      <td>0.541221</td>\n      <td>36.2</td>\n      <td>0.53227</td>\n      <td>104.31</td>\n      <td>recommended simple model/mse +norm +epochs=50 ...</td>\n      <td>recommended simple model/mse +norm +epochs=50 ...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network simplified (v06)</th>\n      <td>0.540642</td>\n      <td>999</td>\n      <td>0.51033</td>\n      <td>999</td>\n      <td>recommended simple model + normalise, mse</td>\n      <td>recommended simple model/mse +norm +epochs=300...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m04 3 layers+wider (v06)</th>\n      <td>0.520933</td>\n      <td>395.14</td>\n      <td>0.445274</td>\n      <td>221.2</td>\n      <td>mse +epochs=500 +learn=0.003</td>\n      <td>mse +epochs=500 +learn=0.003</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>neural network m02 two layers (v06)</th>\n      <td>0.516773</td>\n      <td>112.54</td>\n      <td>0.505803</td>\n      <td>71.81</td>\n      <td>mse +norm +epochs=50 +learn=0.003 +endloss=578...</td>\n      <td>mse +norm +epochs=500 +learn=0.003 +stop=32 +e...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v06)</th>\n      <td>0.4569</td>\n      <td>0.28695</td>\n      <td>0.4569</td>\n      <td>0.244021</td>\n      <td>{'model__alpha': 1e-05, 'model__copy_X': False...</td>\n      <td>{'model__alpha': 0.0001, 'model__copy_X': Fals...</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_vs_2b = dataset_versions_df[\n",
    "    ['best score', 'best time', 'silver score', 'silver time', 'best params', 'silver params', 'best is shared']]\n",
    "df_1_vs_2b\n",
    "#{'model__booster': 'gbtree', 'model__early_stopping_rounds': None, 'model__gamma': 100, 'model__learning_rate': None, 'model__max_delta_step': 0, 'model__max_depth': 6, 'model__min_child_weight': ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
