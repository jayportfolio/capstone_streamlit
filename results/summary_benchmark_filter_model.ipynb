{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "models = ['xg boost', 'linear regression', 'knn', 'decision tree', 'random forest', 'catboost','light gradient boosting', 'neural network']\n",
    "model = None  #'xg boost'\n",
    "original_model = model\n",
    "h = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T00:00:52.632296Z",
     "iopub.status.busy": "2022-12-14T00:00:52.631912Z",
     "iopub.status.idle": "2022-12-14T00:00:53.255004Z",
     "shell.execute_reply": "2022-12-14T00:00:53.254157Z",
     "shell.execute_reply.started": "2022-12-14T00:00:52.632223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/8: linear regression\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                best score best time  \\\nlinear regression (ridge) (v11)                   0.484311    0.2412   \nlinear regression (ridge) (v10)                   0.470806  0.239057   \nlinear regression (ridge) (v09)                   0.459955  0.100284   \nlinear regression (ridge) (v06)                     0.4569   0.28695   \nlinear regression (ridge) - random search (v02)        NaN       NaN   \nlinear regression (ridge) - random search (v03)        NaN       NaN   \nlinear regression (ridge) - random search (v04)        NaN       NaN   \nlinear regression (ridge) - random search (v05)        NaN       NaN   \nlinear regression - basic (v01)                        NaN       NaN   \n\n                                                Mean Absolute Error Accuracy  \\\nlinear regression (ridge) (v11)                                 61567.465046   \nlinear regression (ridge) (v10)                                 62604.882559   \nlinear regression (ridge) (v09)                                 75320.739699   \nlinear regression (ridge) (v06)                                 63603.059705   \nlinear regression (ridge) - random search (v02)                  71267.87544   \nlinear regression (ridge) - random search (v03)                 70746.660452   \nlinear regression (ridge) - random search (v04)                 71834.403182   \nlinear regression (ridge) - random search (v05)                 63770.695868   \nlinear regression - basic (v01)                                 72921.558095   \n\n                                                Mean Squared Error Accuracy  \\\nlinear regression (ridge) (v11)                           5825535717.872867   \nlinear regression (ridge) (v10)                           5978439935.576468   \nlinear regression (ridge) (v09)                           8376872406.903015   \nlinear regression (ridge) (v06)                            6135206763.74439   \nlinear regression (ridge) - random search (v02)           7702385505.171303   \nlinear regression (ridge) - random search (v03)           7492527878.209663   \nlinear regression (ridge) - random search (v04)           7712522953.793764   \nlinear regression (ridge) - random search (v05)           6191276570.283344   \nlinear regression - basic (v01)                            8297985798.70861   \n\n                                                R square Accuracy  \\\nlinear regression (ridge) (v11)                          0.484302   \nlinear regression (ridge) (v10)                          0.470766   \nlinear regression (ridge) (v09)                          0.258448   \nlinear regression (ridge) (v06)                          0.456889   \nlinear regression (ridge) - random search (v02)          0.326879   \nlinear regression (ridge) - random search (v03)          0.326511   \nlinear regression (ridge) - random search (v04)          0.321224   \nlinear regression (ridge) - random search (v05)          0.443478   \nlinear regression - basic (v01)                           0.29667   \n\n                                                Root Mean Squared Error  \\\nlinear regression (ridge) (v11)                            76325.197136   \nlinear regression (ridge) (v10)                            77320.372061   \nlinear regression (ridge) (v09)                            91525.255569   \nlinear regression (ridge) (v06)                            78327.560691   \nlinear regression (ridge) - random search (v02)            87763.235499   \nlinear regression (ridge) - random search (v03)            86559.389313   \nlinear regression (ridge) - random search (v04)            87820.971036   \nlinear regression (ridge) - random search (v05)            78684.665407   \nlinear regression - basic (v01)                            91093.280755   \n\n                                                              best run date  \\\nlinear regression (ridge) (v11)                  2023-01-01 10:07:22.564855   \nlinear regression (ridge) (v10)                  2022-12-01 19:50:08.050622   \nlinear regression (ridge) (v09)                  2023-01-01 09:49:20.349186   \nlinear regression (ridge) (v06)                  2022-12-03 19:20:52.874336   \nlinear regression (ridge) - random search (v02)                         NaN   \nlinear regression (ridge) - random search (v03)                         NaN   \nlinear regression (ridge) - random search (v04)                         NaN   \nlinear regression (ridge) - random search (v05)                         NaN   \nlinear regression - basic (v01)                                         NaN   \n\n                                                                    best method  \\\nlinear regression (ridge) (v11)                  random search(pca,1.0% retain)   \nlinear regression (ridge) (v10)                                   random search   \nlinear regression (ridge) (v09)                              random search(pca)   \nlinear regression (ridge) (v06)                                   random search   \nlinear regression (ridge) - random search (v02)                             NaN   \nlinear regression (ridge) - random search (v03)                             NaN   \nlinear regression (ridge) - random search (v04)                             NaN   \nlinear regression (ridge) - random search (v05)                             NaN   \nlinear regression - basic (v01)                                             NaN   \n\n                                                best is shared  suboptimal  \nlinear regression (ridge) (v11)                          False  suboptimal  \nlinear regression (ridge) (v10)                          False  suboptimal  \nlinear regression (ridge) (v09)                          False  suboptimal  \nlinear regression (ridge) (v06)                          False  suboptimal  \nlinear regression (ridge) - random search (v02)            NaN         NaN  \nlinear regression (ridge) - random search (v03)            NaN         NaN  \nlinear regression (ridge) - random search (v04)            NaN         NaN  \nlinear regression (ridge) - random search (v05)            NaN         NaN  \nlinear regression - basic (v01)                            NaN         NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best score</th>\n      <th>best time</th>\n      <th>Mean Absolute Error Accuracy</th>\n      <th>Mean Squared Error Accuracy</th>\n      <th>R square Accuracy</th>\n      <th>Root Mean Squared Error</th>\n      <th>best run date</th>\n      <th>best method</th>\n      <th>best is shared</th>\n      <th>suboptimal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>linear regression (ridge) (v11)</th>\n      <td>0.484311</td>\n      <td>0.2412</td>\n      <td>61567.465046</td>\n      <td>5825535717.872867</td>\n      <td>0.484302</td>\n      <td>76325.197136</td>\n      <td>2023-01-01 10:07:22.564855</td>\n      <td>random search(pca,1.0% retain)</td>\n      <td>False</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v10)</th>\n      <td>0.470806</td>\n      <td>0.239057</td>\n      <td>62604.882559</td>\n      <td>5978439935.576468</td>\n      <td>0.470766</td>\n      <td>77320.372061</td>\n      <td>2022-12-01 19:50:08.050622</td>\n      <td>random search</td>\n      <td>False</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v09)</th>\n      <td>0.459955</td>\n      <td>0.100284</td>\n      <td>75320.739699</td>\n      <td>8376872406.903015</td>\n      <td>0.258448</td>\n      <td>91525.255569</td>\n      <td>2023-01-01 09:49:20.349186</td>\n      <td>random search(pca)</td>\n      <td>False</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v06)</th>\n      <td>0.4569</td>\n      <td>0.28695</td>\n      <td>63603.059705</td>\n      <td>6135206763.74439</td>\n      <td>0.456889</td>\n      <td>78327.560691</td>\n      <td>2022-12-03 19:20:52.874336</td>\n      <td>random search</td>\n      <td>False</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v02)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>71267.87544</td>\n      <td>7702385505.171303</td>\n      <td>0.326879</td>\n      <td>87763.235499</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v03)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>70746.660452</td>\n      <td>7492527878.209663</td>\n      <td>0.326511</td>\n      <td>86559.389313</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v04)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>71834.403182</td>\n      <td>7712522953.793764</td>\n      <td>0.321224</td>\n      <td>87820.971036</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v05)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>63770.695868</td>\n      <td>6191276570.283344</td>\n      <td>0.443478</td>\n      <td>78684.665407</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression - basic (v01)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>72921.558095</td>\n      <td>8297985798.70861</td>\n      <td>0.29667</td>\n      <td>91093.280755</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if not original_model:\n",
    "    h = (h + 1) % len(models)\n",
    "    model = models[h]\n",
    "print(f'{h + 1}/{len(models)}: {model}')\n",
    "\n",
    "dff = pd.read_json('results.json')\n",
    "\n",
    "#version = 'v11'\n",
    "#version = 'v09'\n",
    "version = 'all'\n",
    "\n",
    "vNN_columns = dff.columns if version == 'all' else [c for c in dff.columns if version in c]\n",
    "if model != 'all': vNN_columns = [c for c in dff.columns if model in c]\n",
    "\n",
    "dataset_versions_df = dff[vNN_columns].T.sort_values(\"best score\", ascending=False)\n",
    "dataset_versions_df_summary = dataset_versions_df[\n",
    "    ['best score', 'best time', 'Mean Absolute Error Accuracy', 'Mean Squared Error Accuracy', 'R square Accuracy',\n",
    "     'Root Mean Squared Error', 'best run date', 'best method', 'best is shared', \"suboptimal\"]]\n",
    "dataset_versions_df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-11T17:58:27.432682Z",
     "iopub.status.busy": "2022-12-11T17:58:27.432324Z",
     "iopub.status.idle": "2022-12-11T17:58:27.457488Z",
     "shell.execute_reply": "2022-12-11T17:58:27.455698Z",
     "shell.execute_reply.started": "2022-12-11T17:58:27.432654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                Mean Absolute Error Accuracy  \\\nlinear regression (ridge) (v11)                                 61567.465046   \nlinear regression (ridge) (v10)                                 62604.882559   \nlinear regression (ridge) (v09)                                 75320.739699   \nlinear regression (ridge) (v06)                                 63603.059705   \nlinear regression (ridge) - random search (v02)                  71267.87544   \nlinear regression (ridge) - random search (v03)                 70746.660452   \nlinear regression (ridge) - random search (v04)                 71834.403182   \nlinear regression (ridge) - random search (v05)                 63770.695868   \nlinear regression - basic (v01)                                 72921.558095   \n\n                                                Mean Squared Error Accuracy  \\\nlinear regression (ridge) (v11)                           5825535717.872867   \nlinear regression (ridge) (v10)                           5978439935.576468   \nlinear regression (ridge) (v09)                           8376872406.903015   \nlinear regression (ridge) (v06)                            6135206763.74439   \nlinear regression (ridge) - random search (v02)           7702385505.171303   \nlinear regression (ridge) - random search (v03)           7492527878.209663   \nlinear regression (ridge) - random search (v04)           7712522953.793764   \nlinear regression (ridge) - random search (v05)           6191276570.283344   \nlinear regression - basic (v01)                            8297985798.70861   \n\n                                                R square Accuracy  \\\nlinear regression (ridge) (v11)                          0.484302   \nlinear regression (ridge) (v10)                          0.470766   \nlinear regression (ridge) (v09)                          0.258448   \nlinear regression (ridge) (v06)                          0.456889   \nlinear regression (ridge) - random search (v02)          0.326879   \nlinear regression (ridge) - random search (v03)          0.326511   \nlinear regression (ridge) - random search (v04)          0.321224   \nlinear regression (ridge) - random search (v05)          0.443478   \nlinear regression - basic (v01)                           0.29667   \n\n                                                Root Mean Squared Error  \\\nlinear regression (ridge) (v11)                            76325.197136   \nlinear regression (ridge) (v10)                            77320.372061   \nlinear regression (ridge) (v09)                            91525.255569   \nlinear regression (ridge) (v06)                            78327.560691   \nlinear regression (ridge) - random search (v02)            87763.235499   \nlinear regression (ridge) - random search (v03)            86559.389313   \nlinear regression (ridge) - random search (v04)            87820.971036   \nlinear regression (ridge) - random search (v05)            78684.665407   \nlinear regression - basic (v01)                            91093.280755   \n\n                                                                        _method  \\\nlinear regression (ridge) (v11)                                   random search   \nlinear regression (ridge) (v10)                                   random search   \nlinear regression (ridge) (v09)                  random search(pca,0.5% retain)   \nlinear regression (ridge) (v06)                                   random search   \nlinear regression (ridge) - random search (v02)                             NaN   \nlinear regression (ridge) - random search (v03)                             NaN   \nlinear regression (ridge) - random search (v04)                             NaN   \nlinear regression (ridge) - random search (v05)                             NaN   \nlinear regression - basic (v01)                                             NaN   \n\n                                                                                           _params  \\\nlinear regression (ridge) (v11)                  {'model__alpha': 100, 'model__copy_X': False, ...   \nlinear regression (ridge) (v10)                  {'model__alpha': 100, 'model__copy_X': False, ...   \nlinear regression (ridge) (v09)                  {'model__alpha': 1e-05, 'model__copy_X': False...   \nlinear regression (ridge) (v06)                  {'model__alpha': 0.001, 'model__copy_X': False...   \nlinear regression (ridge) - random search (v02)  {'model__alpha': 1, 'model__fit_intercept': Tr...   \nlinear regression (ridge) - random search (v03)  {'model__alpha': 0.01, 'model__fit_intercept':...   \nlinear regression (ridge) - random search (v04)  {'model__alpha': 10, 'model__fit_intercept': T...   \nlinear regression (ridge) - random search (v05)  {'model__alpha': 0.001, 'model__fit_intercept'...   \nlinear regression - basic (v01)                                                                NaN   \n\n                                                   _score _train time  \\\nlinear regression (ridge) (v11)                  0.484302    0.079312   \nlinear regression (ridge) (v10)                  0.470766    0.183098   \nlinear regression (ridge) (v09)                  0.258448    0.087033   \nlinear regression (ridge) (v06)                  0.456889    0.019823   \nlinear regression (ridge) - random search (v02)  0.326879    0.286901   \nlinear regression (ridge) - random search (v03)  0.326511    0.091898   \nlinear regression (ridge) - random search (v04)  0.321224     0.02886   \nlinear regression (ridge) - random search (v05)  0.443478    0.141413   \nlinear regression - basic (v01)                   0.29667    0.099876   \n\n                                                best is shared  \\\nlinear regression (ridge) (v11)                          False   \nlinear regression (ridge) (v10)                          False   \nlinear regression (ridge) (v09)                          False   \nlinear regression (ridge) (v06)                          False   \nlinear regression (ridge) - random search (v02)            NaN   \nlinear regression (ridge) - random search (v03)            NaN   \nlinear regression (ridge) - random search (v04)            NaN   \nlinear regression (ridge) - random search (v05)            NaN   \nlinear regression - basic (v01)                            NaN   \n\n                                                                    best method  \\\nlinear regression (ridge) (v11)                  random search(pca,1.0% retain)   \nlinear regression (ridge) (v10)                                   random search   \nlinear regression (ridge) (v09)                              random search(pca)   \nlinear regression (ridge) (v06)                                   random search   \nlinear regression (ridge) - random search (v02)                             NaN   \nlinear regression (ridge) - random search (v03)                             NaN   \nlinear regression (ridge) - random search (v04)                             NaN   \nlinear regression (ridge) - random search (v05)                             NaN   \nlinear regression - basic (v01)                                             NaN   \n\n                                                 ...  \\\nlinear regression (ridge) (v11)                  ...   \nlinear regression (ridge) (v10)                  ...   \nlinear regression (ridge) (v09)                  ...   \nlinear regression (ridge) (v06)                  ...   \nlinear regression (ridge) - random search (v02)  ...   \nlinear regression (ridge) - random search (v03)  ...   \nlinear regression (ridge) - random search (v04)  ...   \nlinear regression (ridge) - random search (v05)  ...   \nlinear regression - basic (v01)                  ...   \n\n                                                                       date  \\\nlinear regression (ridge) (v11)                  2023-01-01 10:12:41.799663   \nlinear regression (ridge) (v10)                  2023-01-01 18:36:34.197826   \nlinear regression (ridge) (v09)                  2023-01-01 09:59:18.171520   \nlinear regression (ridge) (v06)                  2022-12-07 08:12:32.333127   \nlinear regression (ridge) - random search (v02)  2022-10-18 23:48:02.696625   \nlinear regression (ridge) - random search (v03)  2022-10-18 23:49:36.437220   \nlinear regression (ridge) - random search (v04)  2022-10-18 23:56:43.784546   \nlinear regression (ridge) - random search (v05)  2022-10-19 11:11:49.868418   \nlinear regression - basic (v01)                  2022-10-12 12:13:28.904470   \n\n                                                                  first run  \\\nlinear regression (ridge) (v11)                  2023-01-01 10:03:18.981364   \nlinear regression (ridge) (v10)                  2022-12-01 14:21:36.707990   \nlinear regression (ridge) (v09)                  2022-11-29 15:13:33.267574   \nlinear regression (ridge) (v06)                  2022-11-15 21:02:22.079702   \nlinear regression (ridge) - random search (v02)  2022-10-18 23:44:19.835809   \nlinear regression (ridge) - random search (v03)  2022-10-18 23:48:41.539572   \nlinear regression (ridge) - random search (v04)  2022-10-18 23:56:19.993042   \nlinear regression (ridge) - random search (v05)  2022-10-19 00:13:33.773722   \nlinear regression - basic (v01)                  2022-10-11 00:00:00.000000   \n\n                                                random_state   run_env  \\\nlinear regression (ridge) (v11)                          101  gradient   \nlinear regression (ridge) (v10)                          101  gradient   \nlinear regression (ridge) (v09)                          101  gradient   \nlinear regression (ridge) (v06)                          101  gradient   \nlinear regression (ridge) - random search (v02)          101       NaN   \nlinear regression (ridge) - random search (v03)          101       NaN   \nlinear regression (ridge) - random search (v04)          101       NaN   \nlinear regression (ridge) - random search (v05)          101       NaN   \nlinear regression - basic (v01)                          101       NaN   \n\n                                                                  silver method  \\\nlinear regression (ridge) (v11)                                   random search   \nlinear regression (ridge) (v10)                                   random search   \nlinear regression (ridge) (v09)                  random search(pca,1.0% retain)   \nlinear regression (ridge) (v06)                                   random search   \nlinear regression (ridge) - random search (v02)                             NaN   \nlinear regression (ridge) - random search (v03)                             NaN   \nlinear regression (ridge) - random search (v04)                             NaN   \nlinear regression (ridge) - random search (v05)                             NaN   \nlinear regression - basic (v01)                                             NaN   \n\n                                                                                     silver params  \\\nlinear regression (ridge) (v11)                  {'model__alpha': 100, 'model__copy_X': False, ...   \nlinear regression (ridge) (v10)                  {'model__alpha': 0.0001, 'model__copy_X': Fals...   \nlinear regression (ridge) (v09)                  {'model__alpha': 0.0001, 'model__copy_X': True...   \nlinear regression (ridge) (v06)                  {'model__alpha': 0.0001, 'model__copy_X': Fals...   \nlinear regression (ridge) - random search (v02)                                                NaN   \nlinear regression (ridge) - random search (v03)                                                NaN   \nlinear regression (ridge) - random search (v04)                                                NaN   \nlinear regression (ridge) - random search (v05)                                                NaN   \nlinear regression - basic (v01)                                                                NaN   \n\n                                                            silver run date  \\\nlinear regression (ridge) (v11)                  2023-01-01 10:12:41.799663   \nlinear regression (ridge) (v10)                  2022-12-01 15:02:10.080074   \nlinear regression (ridge) (v09)                  2023-01-01 09:53:55.211064   \nlinear regression (ridge) (v06)                  2022-12-03 19:28:37.848562   \nlinear regression (ridge) - random search (v02)                         NaN   \nlinear regression (ridge) - random search (v03)                         NaN   \nlinear regression (ridge) - random search (v04)                         NaN   \nlinear regression (ridge) - random search (v05)                         NaN   \nlinear regression - basic (v01)                                         NaN   \n\n                                                silver score silver time  \\\nlinear regression (ridge) (v11)                     0.484302    0.079312   \nlinear regression (ridge) (v10)                     0.470806    0.089642   \nlinear regression (ridge) (v09)                     0.459955    0.109841   \nlinear regression (ridge) (v06)                       0.4569    0.244021   \nlinear regression (ridge) - random search (v02)          NaN         NaN   \nlinear regression (ridge) - random search (v03)          NaN         NaN   \nlinear regression (ridge) - random search (v04)          NaN         NaN   \nlinear regression (ridge) - random search (v05)          NaN         NaN   \nlinear regression - basic (v01)                          NaN         NaN   \n\n                                                 suboptimal  \nlinear regression (ridge) (v11)                  suboptimal  \nlinear regression (ridge) (v10)                  suboptimal  \nlinear regression (ridge) (v09)                  suboptimal  \nlinear regression (ridge) (v06)                  suboptimal  \nlinear regression (ridge) - random search (v02)         NaN  \nlinear regression (ridge) - random search (v03)         NaN  \nlinear regression (ridge) - random search (v04)         NaN  \nlinear regression (ridge) - random search (v05)         NaN  \nlinear regression - basic (v01)                         NaN  \n\n[9 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean Absolute Error Accuracy</th>\n      <th>Mean Squared Error Accuracy</th>\n      <th>R square Accuracy</th>\n      <th>Root Mean Squared Error</th>\n      <th>_method</th>\n      <th>_params</th>\n      <th>_score</th>\n      <th>_train time</th>\n      <th>best is shared</th>\n      <th>best method</th>\n      <th>...</th>\n      <th>date</th>\n      <th>first run</th>\n      <th>random_state</th>\n      <th>run_env</th>\n      <th>silver method</th>\n      <th>silver params</th>\n      <th>silver run date</th>\n      <th>silver score</th>\n      <th>silver time</th>\n      <th>suboptimal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>linear regression (ridge) (v11)</th>\n      <td>61567.465046</td>\n      <td>5825535717.872867</td>\n      <td>0.484302</td>\n      <td>76325.197136</td>\n      <td>random search</td>\n      <td>{'model__alpha': 100, 'model__copy_X': False, ...</td>\n      <td>0.484302</td>\n      <td>0.079312</td>\n      <td>False</td>\n      <td>random search(pca,1.0% retain)</td>\n      <td>...</td>\n      <td>2023-01-01 10:12:41.799663</td>\n      <td>2023-01-01 10:03:18.981364</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search</td>\n      <td>{'model__alpha': 100, 'model__copy_X': False, ...</td>\n      <td>2023-01-01 10:12:41.799663</td>\n      <td>0.484302</td>\n      <td>0.079312</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v10)</th>\n      <td>62604.882559</td>\n      <td>5978439935.576468</td>\n      <td>0.470766</td>\n      <td>77320.372061</td>\n      <td>random search</td>\n      <td>{'model__alpha': 100, 'model__copy_X': False, ...</td>\n      <td>0.470766</td>\n      <td>0.183098</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2023-01-01 18:36:34.197826</td>\n      <td>2022-12-01 14:21:36.707990</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search</td>\n      <td>{'model__alpha': 0.0001, 'model__copy_X': Fals...</td>\n      <td>2022-12-01 15:02:10.080074</td>\n      <td>0.470806</td>\n      <td>0.089642</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v09)</th>\n      <td>75320.739699</td>\n      <td>8376872406.903015</td>\n      <td>0.258448</td>\n      <td>91525.255569</td>\n      <td>random search(pca,0.5% retain)</td>\n      <td>{'model__alpha': 1e-05, 'model__copy_X': False...</td>\n      <td>0.258448</td>\n      <td>0.087033</td>\n      <td>False</td>\n      <td>random search(pca)</td>\n      <td>...</td>\n      <td>2023-01-01 09:59:18.171520</td>\n      <td>2022-11-29 15:13:33.267574</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search(pca,1.0% retain)</td>\n      <td>{'model__alpha': 0.0001, 'model__copy_X': True...</td>\n      <td>2023-01-01 09:53:55.211064</td>\n      <td>0.459955</td>\n      <td>0.109841</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v06)</th>\n      <td>63603.059705</td>\n      <td>6135206763.74439</td>\n      <td>0.456889</td>\n      <td>78327.560691</td>\n      <td>random search</td>\n      <td>{'model__alpha': 0.001, 'model__copy_X': False...</td>\n      <td>0.456889</td>\n      <td>0.019823</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2022-12-07 08:12:32.333127</td>\n      <td>2022-11-15 21:02:22.079702</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>random search</td>\n      <td>{'model__alpha': 0.0001, 'model__copy_X': Fals...</td>\n      <td>2022-12-03 19:28:37.848562</td>\n      <td>0.4569</td>\n      <td>0.244021</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v02)</th>\n      <td>71267.87544</td>\n      <td>7702385505.171303</td>\n      <td>0.326879</td>\n      <td>87763.235499</td>\n      <td>NaN</td>\n      <td>{'model__alpha': 1, 'model__fit_intercept': Tr...</td>\n      <td>0.326879</td>\n      <td>0.286901</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2022-10-18 23:48:02.696625</td>\n      <td>2022-10-18 23:44:19.835809</td>\n      <td>101</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v03)</th>\n      <td>70746.660452</td>\n      <td>7492527878.209663</td>\n      <td>0.326511</td>\n      <td>86559.389313</td>\n      <td>NaN</td>\n      <td>{'model__alpha': 0.01, 'model__fit_intercept':...</td>\n      <td>0.326511</td>\n      <td>0.091898</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2022-10-18 23:49:36.437220</td>\n      <td>2022-10-18 23:48:41.539572</td>\n      <td>101</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v04)</th>\n      <td>71834.403182</td>\n      <td>7712522953.793764</td>\n      <td>0.321224</td>\n      <td>87820.971036</td>\n      <td>NaN</td>\n      <td>{'model__alpha': 10, 'model__fit_intercept': T...</td>\n      <td>0.321224</td>\n      <td>0.02886</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2022-10-18 23:56:43.784546</td>\n      <td>2022-10-18 23:56:19.993042</td>\n      <td>101</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v05)</th>\n      <td>63770.695868</td>\n      <td>6191276570.283344</td>\n      <td>0.443478</td>\n      <td>78684.665407</td>\n      <td>NaN</td>\n      <td>{'model__alpha': 0.001, 'model__fit_intercept'...</td>\n      <td>0.443478</td>\n      <td>0.141413</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2022-10-19 11:11:49.868418</td>\n      <td>2022-10-19 00:13:33.773722</td>\n      <td>101</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression - basic (v01)</th>\n      <td>72921.558095</td>\n      <td>8297985798.70861</td>\n      <td>0.29667</td>\n      <td>91093.280755</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.29667</td>\n      <td>0.099876</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2022-10-12 12:13:28.904470</td>\n      <td>2022-10-11 00:00:00.000000</td>\n      <td>101</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>9 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_versions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-11T17:58:27.459481Z",
     "iopub.status.busy": "2022-12-11T17:58:27.459230Z",
     "iopub.status.idle": "2022-12-11T17:58:27.472176Z",
     "shell.execute_reply": "2022-12-11T17:58:27.471352Z",
     "shell.execute_reply.started": "2022-12-11T17:58:27.459459Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                best score best time  \\\nlinear regression (ridge) (v11)                   0.484311    0.2412   \nlinear regression (ridge) (v10)                   0.470806  0.239057   \nlinear regression (ridge) (v09)                   0.459955  0.100284   \nlinear regression (ridge) (v06)                     0.4569   0.28695   \nlinear regression (ridge) - random search (v02)        NaN       NaN   \nlinear regression (ridge) - random search (v03)        NaN       NaN   \nlinear regression (ridge) - random search (v04)        NaN       NaN   \nlinear regression (ridge) - random search (v05)        NaN       NaN   \nlinear regression - basic (v01)                        NaN       NaN   \n\n                                                silver score silver time  \\\nlinear regression (ridge) (v11)                     0.484302    0.079312   \nlinear regression (ridge) (v10)                     0.470806    0.089642   \nlinear regression (ridge) (v09)                     0.459955    0.109841   \nlinear regression (ridge) (v06)                       0.4569    0.244021   \nlinear regression (ridge) - random search (v02)          NaN         NaN   \nlinear regression (ridge) - random search (v03)          NaN         NaN   \nlinear regression (ridge) - random search (v04)          NaN         NaN   \nlinear regression (ridge) - random search (v05)          NaN         NaN   \nlinear regression - basic (v01)                          NaN         NaN   \n\n                                                                    best method  \\\nlinear regression (ridge) (v11)                  random search(pca,1.0% retain)   \nlinear regression (ridge) (v10)                                   random search   \nlinear regression (ridge) (v09)                              random search(pca)   \nlinear regression (ridge) (v06)                                   random search   \nlinear regression (ridge) - random search (v02)                             NaN   \nlinear regression (ridge) - random search (v03)                             NaN   \nlinear regression (ridge) - random search (v04)                             NaN   \nlinear regression (ridge) - random search (v05)                             NaN   \nlinear regression - basic (v01)                                             NaN   \n\n                                                                  silver method  \\\nlinear regression (ridge) (v11)                                   random search   \nlinear regression (ridge) (v10)                                   random search   \nlinear regression (ridge) (v09)                  random search(pca,1.0% retain)   \nlinear regression (ridge) (v06)                                   random search   \nlinear regression (ridge) - random search (v02)                             NaN   \nlinear regression (ridge) - random search (v03)                             NaN   \nlinear regression (ridge) - random search (v04)                             NaN   \nlinear regression (ridge) - random search (v05)                             NaN   \nlinear regression - basic (v01)                                             NaN   \n\n                                                best is shared  \nlinear regression (ridge) (v11)                          False  \nlinear regression (ridge) (v10)                          False  \nlinear regression (ridge) (v09)                          False  \nlinear regression (ridge) (v06)                          False  \nlinear regression (ridge) - random search (v02)            NaN  \nlinear regression (ridge) - random search (v03)            NaN  \nlinear regression (ridge) - random search (v04)            NaN  \nlinear regression (ridge) - random search (v05)            NaN  \nlinear regression - basic (v01)                            NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best score</th>\n      <th>best time</th>\n      <th>silver score</th>\n      <th>silver time</th>\n      <th>best method</th>\n      <th>silver method</th>\n      <th>best is shared</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>linear regression (ridge) (v11)</th>\n      <td>0.484311</td>\n      <td>0.2412</td>\n      <td>0.484302</td>\n      <td>0.079312</td>\n      <td>random search(pca,1.0% retain)</td>\n      <td>random search</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v10)</th>\n      <td>0.470806</td>\n      <td>0.239057</td>\n      <td>0.470806</td>\n      <td>0.089642</td>\n      <td>random search</td>\n      <td>random search</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v09)</th>\n      <td>0.459955</td>\n      <td>0.100284</td>\n      <td>0.459955</td>\n      <td>0.109841</td>\n      <td>random search(pca)</td>\n      <td>random search(pca,1.0% retain)</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v06)</th>\n      <td>0.4569</td>\n      <td>0.28695</td>\n      <td>0.4569</td>\n      <td>0.244021</td>\n      <td>random search</td>\n      <td>random search</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v02)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v03)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v04)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v05)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression - basic (v01)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_1_vs_2 = dataset_versions_df[\n",
    "    ['best score', 'best time', 'silver score', 'silver time', 'best method', 'silver method', 'best is shared']]\n",
    "df_summary_1_vs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-11T17:58:27.473783Z",
     "iopub.status.busy": "2022-12-11T17:58:27.473530Z",
     "iopub.status.idle": "2022-12-11T17:58:27.490023Z",
     "shell.execute_reply": "2022-12-11T17:58:27.489187Z",
     "shell.execute_reply.started": "2022-12-11T17:58:27.473760Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                best score best time  \\\nlinear regression (ridge) (v11)                   0.484311    0.2412   \nlinear regression (ridge) (v10)                   0.470806  0.239057   \nlinear regression (ridge) (v09)                   0.459955  0.100284   \nlinear regression (ridge) (v06)                     0.4569   0.28695   \nlinear regression (ridge) - random search (v02)        NaN       NaN   \nlinear regression (ridge) - random search (v03)        NaN       NaN   \nlinear regression (ridge) - random search (v04)        NaN       NaN   \nlinear regression (ridge) - random search (v05)        NaN       NaN   \nlinear regression - basic (v01)                        NaN       NaN   \n\n                                                silver score silver time  \\\nlinear regression (ridge) (v11)                     0.484302    0.079312   \nlinear regression (ridge) (v10)                     0.470806    0.089642   \nlinear regression (ridge) (v09)                     0.459955    0.109841   \nlinear regression (ridge) (v06)                       0.4569    0.244021   \nlinear regression (ridge) - random search (v02)          NaN         NaN   \nlinear regression (ridge) - random search (v03)          NaN         NaN   \nlinear regression (ridge) - random search (v04)          NaN         NaN   \nlinear regression (ridge) - random search (v05)          NaN         NaN   \nlinear regression - basic (v01)                          NaN         NaN   \n\n                                                                                       best params  \\\nlinear regression (ridge) (v11)                  {'model__alpha': 100, 'model__copy_X': True, '...   \nlinear regression (ridge) (v10)                  {'model__alpha': 1e-05, 'model__copy_X': True,...   \nlinear regression (ridge) (v09)                  {'model__alpha': 1e-05, 'model__copy_X': True,...   \nlinear regression (ridge) (v06)                  {'model__alpha': 1e-05, 'model__copy_X': False...   \nlinear regression (ridge) - random search (v02)                             MULTIPLE PARAM OPTIONS   \nlinear regression (ridge) - random search (v03)                             MULTIPLE PARAM OPTIONS   \nlinear regression (ridge) - random search (v04)                             MULTIPLE PARAM OPTIONS   \nlinear regression (ridge) - random search (v05)                             MULTIPLE PARAM OPTIONS   \nlinear regression - basic (v01)                                                                NaN   \n\n                                                                                     silver params  \\\nlinear regression (ridge) (v11)                  {'model__alpha': 100, 'model__copy_X': False, ...   \nlinear regression (ridge) (v10)                  {'model__alpha': 0.0001, 'model__copy_X': Fals...   \nlinear regression (ridge) (v09)                  {'model__alpha': 0.0001, 'model__copy_X': True...   \nlinear regression (ridge) (v06)                  {'model__alpha': 0.0001, 'model__copy_X': Fals...   \nlinear regression (ridge) - random search (v02)                                                NaN   \nlinear regression (ridge) - random search (v03)                                                NaN   \nlinear regression (ridge) - random search (v04)                                                NaN   \nlinear regression (ridge) - random search (v05)                                                NaN   \nlinear regression - basic (v01)                                                                NaN   \n\n                                                best is shared  \\\nlinear regression (ridge) (v11)                          False   \nlinear regression (ridge) (v10)                          False   \nlinear regression (ridge) (v09)                          False   \nlinear regression (ridge) (v06)                          False   \nlinear regression (ridge) - random search (v02)            NaN   \nlinear regression (ridge) - random search (v03)            NaN   \nlinear regression (ridge) - random search (v04)            NaN   \nlinear regression (ridge) - random search (v05)            NaN   \nlinear regression - basic (v01)                            NaN   \n\n                                                                    best method  \\\nlinear regression (ridge) (v11)                  random search(pca,1.0% retain)   \nlinear regression (ridge) (v10)                                   random search   \nlinear regression (ridge) (v09)                              random search(pca)   \nlinear regression (ridge) (v06)                                   random search   \nlinear regression (ridge) - random search (v02)                             NaN   \nlinear regression (ridge) - random search (v03)                             NaN   \nlinear regression (ridge) - random search (v04)                             NaN   \nlinear regression (ridge) - random search (v05)                             NaN   \nlinear regression - basic (v01)                                             NaN   \n\n                                                                  silver method  \nlinear regression (ridge) (v11)                                   random search  \nlinear regression (ridge) (v10)                                   random search  \nlinear regression (ridge) (v09)                  random search(pca,1.0% retain)  \nlinear regression (ridge) (v06)                                   random search  \nlinear regression (ridge) - random search (v02)                             NaN  \nlinear regression (ridge) - random search (v03)                             NaN  \nlinear regression (ridge) - random search (v04)                             NaN  \nlinear regression (ridge) - random search (v05)                             NaN  \nlinear regression - basic (v01)                                             NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best score</th>\n      <th>best time</th>\n      <th>silver score</th>\n      <th>silver time</th>\n      <th>best params</th>\n      <th>silver params</th>\n      <th>best is shared</th>\n      <th>best method</th>\n      <th>silver method</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>linear regression (ridge) (v11)</th>\n      <td>0.484311</td>\n      <td>0.2412</td>\n      <td>0.484302</td>\n      <td>0.079312</td>\n      <td>{'model__alpha': 100, 'model__copy_X': True, '...</td>\n      <td>{'model__alpha': 100, 'model__copy_X': False, ...</td>\n      <td>False</td>\n      <td>random search(pca,1.0% retain)</td>\n      <td>random search</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v10)</th>\n      <td>0.470806</td>\n      <td>0.239057</td>\n      <td>0.470806</td>\n      <td>0.089642</td>\n      <td>{'model__alpha': 1e-05, 'model__copy_X': True,...</td>\n      <td>{'model__alpha': 0.0001, 'model__copy_X': Fals...</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>random search</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v09)</th>\n      <td>0.459955</td>\n      <td>0.100284</td>\n      <td>0.459955</td>\n      <td>0.109841</td>\n      <td>{'model__alpha': 1e-05, 'model__copy_X': True,...</td>\n      <td>{'model__alpha': 0.0001, 'model__copy_X': True...</td>\n      <td>False</td>\n      <td>random search(pca)</td>\n      <td>random search(pca,1.0% retain)</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) (v06)</th>\n      <td>0.4569</td>\n      <td>0.28695</td>\n      <td>0.4569</td>\n      <td>0.244021</td>\n      <td>{'model__alpha': 1e-05, 'model__copy_X': False...</td>\n      <td>{'model__alpha': 0.0001, 'model__copy_X': Fals...</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>random search</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v02)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>MULTIPLE PARAM OPTIONS</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v03)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>MULTIPLE PARAM OPTIONS</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v04)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>MULTIPLE PARAM OPTIONS</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v05)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>MULTIPLE PARAM OPTIONS</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression - basic (v01)</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_vs_2b = dataset_versions_df[\n",
    "    ['best score', 'best time', 'silver score', 'silver time', 'best params', 'silver params', 'best is shared','best method','silver method']]\n",
    "df_1_vs_2b\n",
    "#{'model__booster': 'gbtree', 'model__early_stopping_rounds': None, 'model__gamma': 100, 'model__learning_rate': None, 'model__max_delta_step': 0, 'model__max_depth': 6, 'model__min_child_weight': ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysing the hyperparameters for the best performing version (for linear regression)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                      best model             runner-up model  \\\nmodel__alpha                                 100                         100   \nmodel__copy_X                               True                       False   \nmodel__fit_intercept                        True                        True   \nmodel__max_iter                            10000                     1000000   \nmodel__positive                            False                       False   \nmodel__random_state                          101                         101   \nmodel__solver                                svd                        auto   \nmodel__tol                                 0.001                        0.01   \nscore                                   0.484311                    0.484302   \ntime                                      0.2412                    0.079312   \ndate run              2023-01-01 10:07:22.564855  2023-01-01 10:12:41.799663   \n\n                               most recent model  \nmodel__alpha                                 100  \nmodel__copy_X                              False  \nmodel__fit_intercept                        True  \nmodel__max_iter                          1000000  \nmodel__positive                            False  \nmodel__random_state                          101  \nmodel__solver                               auto  \nmodel__tol                                  0.01  \nscore                                   0.484302  \ntime                                    0.079312  \ndate run              2023-01-01 10:12:41.799663  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best model</th>\n      <th>runner-up model</th>\n      <th>most recent model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>model__alpha</th>\n      <td>100</td>\n      <td>100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>model__copy_X</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>model__fit_intercept</th>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>model__max_iter</th>\n      <td>10000</td>\n      <td>1000000</td>\n      <td>1000000</td>\n    </tr>\n    <tr>\n      <th>model__positive</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>model__random_state</th>\n      <td>101</td>\n      <td>101</td>\n      <td>101</td>\n    </tr>\n    <tr>\n      <th>model__solver</th>\n      <td>svd</td>\n      <td>auto</td>\n      <td>auto</td>\n    </tr>\n    <tr>\n      <th>model__tol</th>\n      <td>0.001</td>\n      <td>0.01</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>score</th>\n      <td>0.484311</td>\n      <td>0.484302</td>\n      <td>0.484302</td>\n    </tr>\n    <tr>\n      <th>time</th>\n      <td>0.2412</td>\n      <td>0.079312</td>\n      <td>0.079312</td>\n    </tr>\n    <tr>\n      <th>date run</th>\n      <td>2023-01-01 10:07:22.564855</td>\n      <td>2023-01-01 10:12:41.799663</td>\n      <td>2023-01-01 10:12:41.799663</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_1_vs_2b.iloc[0]['best params']\n",
    "#df_1_vs_2b.iloc[0]['silver params']\n",
    "d1 = dataset_versions_df.iloc[0]['best params']\n",
    "d2 = dataset_versions_df.iloc[0]['silver params']\n",
    "d99 = dataset_versions_df.iloc[0]['_params']\n",
    "d1['score'] = dataset_versions_df.iloc[0]['best score']\n",
    "d2['score'] = dataset_versions_df.iloc[0]['silver score']\n",
    "d99['score'] = dataset_versions_df.iloc[0]['_score']\n",
    "d1['time'] = dataset_versions_df.iloc[0]['best time']\n",
    "d2['time'] = dataset_versions_df.iloc[0]['silver time']\n",
    "d99['time'] = dataset_versions_df.iloc[0]['_train time']\n",
    "d1['date run'] = dataset_versions_df.iloc[0]['best run date']\n",
    "d2['date run'] = dataset_versions_df.iloc[0]['silver run date']\n",
    "d99['date run'] = dataset_versions_df.iloc[0]['date']\n",
    "\n",
    "res = {}\n",
    "for each in d1:\n",
    "    res[each] = [d1[each]]\n",
    "    if each in d2:\n",
    "        if each not in res:\n",
    "            d2[each]\n",
    "            res[each]\n",
    "        res[each].extend([d2[each]])\n",
    "    else:\n",
    "        d1[each] = d2[each]\n",
    "\n",
    "including_most_recent = True\n",
    "if including_most_recent == True:\n",
    "    for each in d1:\n",
    "        if each in d99:\n",
    "            if each not in res:\n",
    "                d2[each]\n",
    "                res[each]\n",
    "            res[each].extend([d99[each]])\n",
    "        else:\n",
    "            #d1[each] = d99[each]\n",
    "            pass\n",
    "\n",
    "run_comparison = pd.DataFrame.from_dict(res).T\n",
    "if including_most_recent:\n",
    "    run_comparison.columns = ['best model','runner-up model','most recent model']\n",
    "else:\n",
    "    run_comparison.columns = ['best model','runner-up model']\n",
    "print(f\"Analysing the hyperparameters for the best performing version (for {model})\")\n",
    "run_comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
