{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM = 'Linear Regression'\n",
    "ALGORITHM_DETAIL = 'random search'\n",
    "VERSION = '01'\n",
    "\n",
    "RANDOM_STATE = 101\n",
    "TRAINING_SIZE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "pipe = Pipeline([\n",
    "    #('mms', MinMaxScaler()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('model', LinearRegression())\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "from termcolor import colored\n",
    "\n",
    "confirm_colab = False\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = confirm_colab\n",
    "\n",
    "if not IN_COLAB:\n",
    "    import functions_20221011a\n",
    "    from functions_20221011a import set_csv_directory\n",
    "\n",
    "    set_csv_directory('final_split')\n",
    "\n",
    "debug_mode = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mfeatures\u001B[0m ->  ['location.latitude', 'location.longitude', 'bedrooms', 'bathrooms', 'nearestStation', 'tenure.tenureType']\n",
      "\u001B[1m\u001B[32mlabel\u001B[0m ->  Price\n"
     ]
    }
   ],
   "source": [
    "#cutdown_rows = 1000\n",
    "cutdown_rows = 0\n",
    "\n",
    "LABEL = 'Price'\n",
    "\n",
    "booleans = []\n",
    "floats = ['location.latitude', 'location.longitude', 'bedrooms', 'bathrooms', 'nearestStation']\n",
    "categories = ['tenure.tenureType']\n",
    "\n",
    "columns = []\n",
    "columns.extend(booleans)\n",
    "columns.extend(floats)\n",
    "columns.extend(categories)\n",
    "\n",
    "print(colored(f\"features\", \"blue\"), \"-> \", columns)\n",
    "columns.insert(0, LABEL)\n",
    "print(colored(f\"label\", \"green\", None, ['bold']), \"-> \", LABEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "filename = f'df_listings_v{VERSION}.csv'\n",
    "#remote_pathname = 'https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/df_listings.csv'\n",
    "remote_pathname = f'https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/{filename}'\n",
    "df_pathname_raw = f'../../data/source/{filename}'\n",
    "df_pathname_tidy = f'../../data/final/{filename}'\n",
    "\n",
    "\n",
    "def get_source_dataframe(rows=cutdown_rows, folder_prefix='../'):\n",
    "    if IN_COLAB:\n",
    "        inDF = pd.read_csv(remote_pathname, on_bad_lines='error', index_col=0)\n",
    "    else:\n",
    "        try:\n",
    "            inDF = pd.read_csv(df_pathname_tidy, on_bad_lines='error', index_col=0)\n",
    "        except:\n",
    "            print(f\"WARNING: Failed to retrieved stored data for version {VERSION}, creating new source data.\")\n",
    "            inDF = functions_20221011a.get_combined_dataset(HOW='inner', early_duplicates=True,\n",
    "                                                            folder_prefix=folder_prefix)\n",
    "            inDF.to_csv(df_pathname_raw)\n",
    "\n",
    "    if rows and rows > 0:\n",
    "        inDF = inDF[:rows]\n",
    "    return inDF\n",
    "\n",
    "\n",
    "def create_train_test_data(df_orig, return_index=False, drop_nulls=True):\n",
    "    df = df_orig.copy()\n",
    "\n",
    "    if drop_nulls:\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "    if return_index:\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "    for column in categories:\n",
    "        df = pd.concat([df, pd.get_dummies(df[column], prefix=column)], axis=1)\n",
    "        df.drop([column], axis=1, inplace=True)  # now drop the original column (you don't need it anymore),\n",
    "\n",
    "    ins = df.pop('index')\n",
    "    df.insert(1, 'index2', ins)\n",
    "    df.insert(0, 'index', ins)\n",
    "\n",
    "    #features = df[df.columns[1:]].values\n",
    "    features = df[df.columns[2:]].values\n",
    "    #labels = df[LABEL].values\n",
    "    labels = df.iloc[:, 0:2].values\n",
    "\n",
    "    if not return_index:\n",
    "        return train_test_split(features, labels, train_size=TRAINING_SIZE, random_state=RANDOM_STATE)\n",
    "    else:\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(features, labels, train_size=TRAINING_SIZE, random_state=RANDOM_STATE)\n",
    "        X_train_index = X_train1[:, 0].reshape(-1, 1)\n",
    "        y_train_index = y_train1[:, 0].reshape(-1, 1)\n",
    "        X_test_index = X_test1[:, 0].reshape(-1, 1)\n",
    "        y_test_index = y_test1[:, 0].reshape(-1, 1)\n",
    "        X_train1 = X_train1[:, 1:]\n",
    "        y_train1 = y_train1[:, 1].reshape(-1, 1)\n",
    "        X_test1 = X_test1[:, 1:]\n",
    "        y_test1 = y_test1[:, 1].reshape(-1, 1)\n",
    "\n",
    "        return X_train1, X_test1, y_train1, y_test1, X_train_index, X_test_index, y_train_index, y_test_index\n",
    "\n",
    "#X_train, X_test, y_train, y_test, X_train_index, X_test_index, y_train_index, y_test_index = create_train_test_data(get_source_dataframe(), return_index=True, drop_nulls=False)\n",
    "#X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_train_index.shape, X_test_index.shape, y_train_index.shape, y_test_index.shape,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54067, 7)\n",
      "Index(['14520525', '27953107', '33593487', '35271294', '35429088', '44749111',\n",
      "       '46204665', '49020666', '49036279', '49303873',\n",
      "       ...\n",
      "       '126173423', '126173600', '126175973', '126178769', '126179018',\n",
      "       '126179672', '126180107', '126180704', '126180962', '126181118'],\n",
      "      dtype='object', length=54067)\n"
     ]
    }
   ],
   "source": [
    "df = get_source_dataframe(folder_prefix='../../')\n",
    "df_orig = df.copy()\n",
    "\n",
    "df = df[columns]\n",
    "\n",
    "if not IN_COLAB:\n",
    "    df = functions_20221011a.pre_tidy_dataset(df)\n",
    "    df.to_csv(df_pathname_tidy)\n",
    "\n",
    "print(df.shape)\n",
    "df[:5]\n",
    "\n",
    "df_orig.merge(df, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "print(df.index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "            Price location.latitude  location.longitude  bedrooms  bathrooms  \\\n14520525   550000          51.52995           -0.207020       3.0        1.0   \n27953107   400000          51.54939           -0.482600       2.0        2.0   \n33593487   579950          51.44718           -0.338770       2.0        1.0   \n35271294   370000         51.449568           -0.140154       2.0        1.0   \n35429088   599950          51.57703           -0.141230       2.0        1.0   \n...           ...               ...                 ...       ...        ...   \n126179672  600000          51.35717           -0.074740       3.0        2.0   \n126180107  419999         51.531415           -0.052964       2.0        1.0   \n126180704  475000         51.543141            0.011498       2.0        1.0   \n126180962  450000         51.592105           -0.008233       NaN        1.0   \n126181118  525000         51.424589           -0.206790       2.0        1.0   \n\n           nearestStation  tenure.tenureType  \n14520525         0.274316          LEASEHOLD  \n27953107         0.305845          LEASEHOLD  \n33593487         0.438045           FREEHOLD  \n35271294         0.399307          LEASEHOLD  \n35429088         0.238187                NaN  \n...                   ...                ...  \n126179672        0.545665          LEASEHOLD  \n126180107        0.191407          LEASEHOLD  \n126180704        0.308609          LEASEHOLD  \n126180962        0.476935           FREEHOLD  \n126181118        0.238489  SHARE_OF_FREEHOLD  \n\n[54067 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>location.latitude</th>\n      <th>location.longitude</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n      <th>tenure.tenureType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14520525</th>\n      <td>550000</td>\n      <td>51.52995</td>\n      <td>-0.207020</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.274316</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>27953107</th>\n      <td>400000</td>\n      <td>51.54939</td>\n      <td>-0.482600</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.305845</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>33593487</th>\n      <td>579950</td>\n      <td>51.44718</td>\n      <td>-0.338770</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.438045</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>35271294</th>\n      <td>370000</td>\n      <td>51.449568</td>\n      <td>-0.140154</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.399307</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>35429088</th>\n      <td>599950</td>\n      <td>51.57703</td>\n      <td>-0.141230</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.238187</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>126179672</th>\n      <td>600000</td>\n      <td>51.35717</td>\n      <td>-0.074740</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.545665</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>126180107</th>\n      <td>419999</td>\n      <td>51.531415</td>\n      <td>-0.052964</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.191407</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>126180704</th>\n      <td>475000</td>\n      <td>51.543141</td>\n      <td>0.011498</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.308609</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>126180962</th>\n      <td>450000</td>\n      <td>51.592105</td>\n      <td>-0.008233</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.476935</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>126181118</th>\n      <td>525000</td>\n      <td>51.424589</td>\n      <td>-0.206790</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.238489</td>\n      <td>SHARE_OF_FREEHOLD</td>\n    </tr>\n  </tbody>\n</table>\n<p>54067 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Price                    0\nlocation.latitude        0\nlocation.longitude       0\nbedrooms              1802\nbathrooms             3498\nnearestStation           0\ntenure.tenureType     3654\ndtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 54067 entries, 14520525 to 126181118\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Price               54067 non-null  int64  \n",
      " 1   location.latitude   54067 non-null  object \n",
      " 2   location.longitude  54067 non-null  float64\n",
      " 3   bedrooms            52265 non-null  float64\n",
      " 4   bathrooms           50569 non-null  float64\n",
      " 5   nearestStation      54067 non-null  float64\n",
      " 6   tenure.tenureType   50413 non-null  object \n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 5.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "               Price  location.longitude       bedrooms     bathrooms  \\\ncount   54067.000000        54067.000000   52265.000000  50569.000000   \nmean   416448.380528           -0.106239      11.360145      1.181534   \nstd    113505.624206            0.718769    2143.329175      0.413244   \nmin    100000.000000           -0.498315       1.000000      1.000000   \n25%    325000.000000           -0.212965       1.000000      1.000000   \n50%    425000.000000           -0.105220       2.000000      1.000000   \n75%    500000.000000           -0.012998       2.000000      1.000000   \nmax    600000.000000           51.558746  490000.000000     12.000000   \n\n       nearestStation  \ncount    54067.000000  \nmean         0.442075  \nstd          1.049040  \nmin          0.000000  \n25%          0.221778  \n50%          0.361208  \n75%          0.553963  \nmax        192.431869  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>location.longitude</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>54067.000000</td>\n      <td>54067.000000</td>\n      <td>52265.000000</td>\n      <td>50569.000000</td>\n      <td>54067.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>416448.380528</td>\n      <td>-0.106239</td>\n      <td>11.360145</td>\n      <td>1.181534</td>\n      <td>0.442075</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>113505.624206</td>\n      <td>0.718769</td>\n      <td>2143.329175</td>\n      <td>0.413244</td>\n      <td>1.049040</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>100000.000000</td>\n      <td>-0.498315</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>325000.000000</td>\n      <td>-0.212965</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.221778</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>425000.000000</td>\n      <td>-0.105220</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.361208</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>500000.000000</td>\n      <td>-0.012998</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.553963</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>600000.000000</td>\n      <td>51.558746</td>\n      <td>490000.000000</td>\n      <td>12.000000</td>\n      <td>192.431869</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe contract due to cleaning: 54067 ==> 49016\n"
     ]
    },
    {
     "data": {
      "text/plain": "                      count           mean            std            min  \\\nPrice               49016.0  421205.709136  110831.099938  100000.000000   \nlocation.latitude   49016.0      51.496432       0.077345      51.298317   \nlocation.longitude  49016.0      -0.114267       0.156269      -0.498315   \nbedrooms            49016.0       1.981394       0.824532       1.000000   \nbathrooms           49016.0       1.186674       0.413086       1.000000   \nnearestStation      49016.0       0.437429       0.353326       0.000000   \n\n                              25%            50%            75%            max  \nPrice               339950.000000  425000.000000  500000.000000  600000.000000  \nlocation.latitude       51.438138      51.499720      51.555650      51.683185  \nlocation.longitude      -0.211373      -0.103357      -0.011796       0.279726  \nbedrooms                 1.000000       2.000000       2.000000       7.000000  \nbathrooms                1.000000       1.000000       1.000000       5.000000  \nnearestStation           0.224506       0.365045       0.556585      16.168861  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Price</th>\n      <td>49016.0</td>\n      <td>421205.709136</td>\n      <td>110831.099938</td>\n      <td>100000.000000</td>\n      <td>339950.000000</td>\n      <td>425000.000000</td>\n      <td>500000.000000</td>\n      <td>600000.000000</td>\n    </tr>\n    <tr>\n      <th>location.latitude</th>\n      <td>49016.0</td>\n      <td>51.496432</td>\n      <td>0.077345</td>\n      <td>51.298317</td>\n      <td>51.438138</td>\n      <td>51.499720</td>\n      <td>51.555650</td>\n      <td>51.683185</td>\n    </tr>\n    <tr>\n      <th>location.longitude</th>\n      <td>49016.0</td>\n      <td>-0.114267</td>\n      <td>0.156269</td>\n      <td>-0.498315</td>\n      <td>-0.211373</td>\n      <td>-0.103357</td>\n      <td>-0.011796</td>\n      <td>0.279726</td>\n    </tr>\n    <tr>\n      <th>bedrooms</th>\n      <td>49016.0</td>\n      <td>1.981394</td>\n      <td>0.824532</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>bathrooms</th>\n      <td>49016.0</td>\n      <td>1.186674</td>\n      <td>0.413086</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>nearestStation</th>\n      <td>49016.0</td>\n      <td>0.437429</td>\n      <td>0.353326</td>\n      <td>0.000000</td>\n      <td>0.224506</td>\n      <td>0.365045</td>\n      <td>0.556585</td>\n      <td>16.168861</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_length = len(df)\n",
    "df['location.latitude'] = pd.to_numeric(df['location.latitude'], 'coerce').dropna().astype(float)\n",
    "df = df[(df['location.longitude'] <= 10)]\n",
    "df = df[(df['bedrooms'] <= 10)]\n",
    "df = df[df['bathrooms'] <= 5]\n",
    "df = df[(df['nearestStation'] <= 20)]\n",
    "\n",
    "print(f\"dataframe contract due to cleaning: {old_length} ==> {len(df)}\")\n",
    "old_length = len(df)\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Price                    0\nlocation.latitude        0\nlocation.longitude       0\nbedrooms                 0\nbathrooms                0\nnearestStation           0\ntenure.tenureType     2874\ndtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49016 ==> 46142\n"
     ]
    },
    {
     "data": {
      "text/plain": "               Price  location.latitude  location.longitude      bedrooms  \\\ncount   46142.000000       46142.000000        46142.000000  46142.000000   \nmean   421282.384335          51.496075           -0.114033      1.979953   \nstd    110858.107656           0.077508            0.155650      0.823314   \nmin    100000.000000          51.298317           -0.498315      1.000000   \n25%    339950.000000          51.437568           -0.211290      1.000000   \n50%    425000.000000          51.498427           -0.103070      2.000000   \n75%    500000.000000          51.555687           -0.012061      2.000000   \nmax    600000.000000          51.683185            0.279726      7.000000   \n\n          bathrooms  nearestStation  \ncount  46142.000000    46142.000000  \nmean       1.185753        0.437174  \nstd        0.411915        0.352397  \nmin        1.000000        0.000000  \n25%        1.000000        0.225159  \n50%        1.000000        0.365437  \n75%        1.000000        0.556509  \nmax        5.000000       16.168861  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>location.latitude</th>\n      <th>location.longitude</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>46142.000000</td>\n      <td>46142.000000</td>\n      <td>46142.000000</td>\n      <td>46142.000000</td>\n      <td>46142.000000</td>\n      <td>46142.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>421282.384335</td>\n      <td>51.496075</td>\n      <td>-0.114033</td>\n      <td>1.979953</td>\n      <td>1.185753</td>\n      <td>0.437174</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>110858.107656</td>\n      <td>0.077508</td>\n      <td>0.155650</td>\n      <td>0.823314</td>\n      <td>0.411915</td>\n      <td>0.352397</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>100000.000000</td>\n      <td>51.298317</td>\n      <td>-0.498315</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>339950.000000</td>\n      <td>51.437568</td>\n      <td>-0.211290</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.225159</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>425000.000000</td>\n      <td>51.498427</td>\n      <td>-0.103070</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.365437</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>500000.000000</td>\n      <td>51.555687</td>\n      <td>-0.012061</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.556509</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>600000.000000</td>\n      <td>51.683185</td>\n      <td>0.279726</td>\n      <td>7.000000</td>\n      <td>5.000000</td>\n      <td>16.168861</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(f\"{old_length} ==> {len(df)}\")\n",
    "old_length = len(df)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41527, 9) (4615, 9) (41527, 1) (4615, 1) (41527, 1) (4615, 1) (41527, 1) (4615, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_train_index, X_test_index, y_train_index, y_test_index = create_train_test_data(df,\n",
    "                                                                                                                    return_index=True,\n",
    "                                                                                                                    drop_nulls=True)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_train_index.shape, X_test_index.shape,\n",
    "      y_train_index.shape, y_test_index.shape)\n",
    "#print(type(X_train))\n",
    "#X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputer = SimpleImputer(strategy='mean')\n",
    "#imputer.fit(X_train[6])\n",
    "#X_train[6] = imputer.transform(X_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.243e+13, tolerance: 5.126e+10\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'alpha': 1.0,\n 'copy_X': True,\n 'fit_intercept': True,\n 'max_iter': 1000,\n 'normalize': 'deprecated',\n 'positive': False,\n 'precompute': False,\n 'random_state': None,\n 'selection': 'cyclic',\n 'tol': 0.0001,\n 'warm_start': False}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from time import time\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = Lasso()\n",
    "model.fit(X_train, y_train)\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "(RandomizedSearchCV(cv=3,\n                    estimator=Pipeline(steps=[('std_scaler', StandardScaler()),\n                                              ('model', LinearRegression())]),\n                    n_jobs=1,\n                    param_distributions={'alpha': [1, 10, 100],\n                                         'fit_intercept': [True, False],\n                                         'max_iter': [100, 1000, 10000],\n                                         'positive': [True, False],\n                                         'selection': ['random', 'cyclic'],\n                                         'tol': [0.0001, 0.001, 0.01],\n                                         'warm_start': [True, False]},\n                    return_train_score=True, scoring='neg_mean_squared_error',\n                    verbose=False),)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Best Score:  0.30582573121661794\n",
    "# Best Score:  {'alpha': 10, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'selection': 'cyclic', 'tol': 0.001, 'warm_start': True}\n",
    "# Best Score:  Lasso(alpha=10, tol=0.001, warm_start=True)\n",
    "# Best Score:  138\n",
    "\n",
    "# find optimal alpha with grid search\n",
    "alpha = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "alpha = [1, 10, 100]\n",
    "fit_intercept = [True, False]\n",
    "max_iter = [100,1000,10000]\n",
    "positive = [True, False]\n",
    "selection = ['random','cyclic']\n",
    "tol = [0.0001, 0.001, 0.01]\n",
    "warm_start = [True, False]\n",
    "# ['alpha', 'copy_X', 'fit_intercept', 'max_iter', 'normalize', 'positive', 'precompute', 'random_state', 'selection', 'tol', 'warm_start'].\n",
    "\n",
    "param_grid = dict(alpha=alpha, fit_intercept=fit_intercept, max_iter=max_iter, positive=positive, selection=selection, tol=tol, warm_start=warm_start)\n",
    "#param_grid = dict()\n",
    "\n",
    "cv = 3\n",
    "n_jobs = 1\n",
    "verbose = False\n",
    "scoring='neg_mean_squared_error'\n",
    "refit=True\n",
    "\n",
    "#grid = RandomizedSearchCV(estimator=model, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "\n",
    "gs = RandomizedSearchCV(pipe, param_grid, cv=cv, n_jobs=n_jobs,\n",
    "                  verbose=verbose, scoring=scoring, refit=refit,\n",
    "                  return_train_score=True),\n",
    "gs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'warm_start' for estimator Pipeline(steps=[('std_scaler', StandardScaler()),\n                ('model', LinearRegression())]). Valid parameters are: ['memory', 'steps', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [28], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m grid_result \u001B[38;5;241m=\u001B[39m gs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[1;32m      3\u001B[0m timings \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      5\u001B[0m t0 \u001B[38;5;241m=\u001B[39m time()\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    869\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    870\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    871\u001B[0m     )\n\u001B[1;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 875\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    878\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    879\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1753\u001B[0m, in \u001B[0;36mRandomizedSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1751\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1752\u001B[0m     \u001B[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1753\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1754\u001B[0m \u001B[43m        \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1755\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[1;32m   1756\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1757\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:822\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    817\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    818\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    819\u001B[0m         )\n\u001B[1;32m    820\u001B[0m     )\n\u001B[0;32m--> 822\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    823\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    832\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    835\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    837\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    843\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    844\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/joblib/parallel.py:1085\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1077\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n\u001B[1;32m   1078\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1082\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n\u001B[1;32m   1083\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n\u001B[1;32m   1084\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 1085\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1086\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1088\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/joblib/parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 901\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/joblib/parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[1;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[1;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/joblib/_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/sklearn/utils/fixes.py:117\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig):\n\u001B[0;32m--> 117\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:674\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    671\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m parameters\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    672\u001B[0m         cloned_parameters[k] \u001B[38;5;241m=\u001B[39m clone(v, safe\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m--> 674\u001B[0m     estimator \u001B[38;5;241m=\u001B[39m \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_params\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcloned_parameters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    676\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    678\u001B[0m X_train, y_train \u001B[38;5;241m=\u001B[39m _safe_split(estimator, X, y, train)\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/sklearn/pipeline.py:188\u001B[0m, in \u001B[0;36mPipeline.set_params\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_params\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    170\u001B[0m     \u001B[38;5;124;03m\"\"\"Set the parameters of this estimator.\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \n\u001B[1;32m    172\u001B[0m \u001B[38;5;124;03m    Valid parameter keys can be listed with ``get_params()``. Note that\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;124;03m        Pipeline class instance.\u001B[39;00m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 188\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_params\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msteps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/sklearn/utils/metaestimators.py:72\u001B[0m, in \u001B[0;36m_BaseComposition._set_params\u001B[0;34m(self, attr, **params)\u001B[0m\n\u001B[1;32m     69\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_replace_estimator(attr, name, params\u001B[38;5;241m.\u001B[39mpop(name))\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m# 3. Step parameters and other initialisation arguments\u001B[39;00m\n\u001B[0;32m---> 72\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_params\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/sklearn/base.py:246\u001B[0m, in \u001B[0;36mBaseEstimator.set_params\u001B[0;34m(self, **params)\u001B[0m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m valid_params:\n\u001B[1;32m    245\u001B[0m     local_valid_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_param_names()\n\u001B[0;32m--> 246\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    247\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid parameter \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m for estimator \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    248\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValid parameters are: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlocal_valid_params\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    249\u001B[0m     )\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m delim:\n\u001B[1;32m    252\u001B[0m     nested_params[key][sub_key] \u001B[38;5;241m=\u001B[39m value\n",
      "\u001B[0;31mValueError\u001B[0m: Invalid parameter 'warm_start' for estimator Pipeline(steps=[('std_scaler', StandardScaler()),\n                ('model', LinearRegression())]). Valid parameters are: ['memory', 'steps', 'verbose']."
     ]
    }
   ],
   "source": [
    "\n",
    "grid_result = gs[0].fit(X_train, y_train)\n",
    "\n",
    "timings = []\n",
    "\n",
    "t0 = time()\n",
    "pipe.fit(X_train, y_train)\n",
    "timings.append(time() - t0)\n",
    "\n",
    "\n",
    "print(timings)\n",
    "average_time = sum(timings) / len(timings)\n",
    "print(average_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {}\n",
      "-8569594561.56 (+/-295233331.442) for {}\n",
      "Best Index:  0\n",
      "Best Score:  -8569594561.559986\n",
      "Best Params:  {}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [25], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBest Score: \u001B[39m\u001B[38;5;124m'\u001B[39m, grid_result\u001B[38;5;241m.\u001B[39mbest_score_)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBest Params: \u001B[39m\u001B[38;5;124m'\u001B[39m, grid_result\u001B[38;5;241m.\u001B[39mbest_params_)\n\u001B[0;32m---> 13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBest Model: \u001B[39m\u001B[38;5;124m'\u001B[39m, grid_result\u001B[38;5;241m.\u001B[39mbest_estimator_)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "def print_results(results):\n",
    "    print(f'BEST PARAMS: {results.best_params_}')\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print(f'{round(mean, 3)} (+/-{round(std*2,3)}) for {params}')\n",
    "\n",
    "print_results(grid_result)\n",
    "print('Best Index: ', grid_result.best_index_)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)\n",
    "print('Best Model: ', grid_result.)\n",
    "#print('Best Params: ', grid_result.best_params_)[out]\n",
    "### Best Score:  0.4883436188936269\n",
    "### Best Params:  {'alpha': 0.01}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "y_pred = y_pred.reshape((-1, 1))\n",
    "\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = math.sqrt(MSE)\n",
    "print('-' * 10 + ALGORITHM + '-' * 10)\n",
    "print('R square Accuracy', R2)\n",
    "print('Mean Absolute Error Accuracy', MAE)\n",
    "print('Mean Squared Error Accuracy', MSE)\n",
    "print('Root Mean Squared Error', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    print(y_test_index.reshape((-1, 1)).shape);\n",
    "    print(y_pred.reshape((-1, 1)).shape);\n",
    "    print(y_test.shape);\n",
    "    print(y_test_index.shape);\n",
    "    print(y_pred.shape);\n",
    "    print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = np.hstack((y_test_index, y_test, y_pred))\n",
    "compare_df = DataFrame(compare, columns=['reference', 'actual', 'predicted'])\n",
    "compare_df['difference'] = abs(compare_df['actual'] - compare_df['predicted'])\n",
    "compare_df['diff 1 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['actual'] * 100)\n",
    "compare_df['diff 2 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['predicted']) * 100\n",
    "compare_df['reference'] = compare_df['reference'].astype(str)\n",
    "compare_df.set_index('reference', inplace=True)\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df.merge(df[columns], how='inner', left_index=True, right_index=True).sort_values(['diff 1 %'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pipe.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, pipe.predict(X_test), edgecolors=(0, 0, 1))\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_xlabel('Actual')\n",
    "#ax.title.set_text(f'CV Chosen best option ({calculated_best_pipe[1]})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "results = {\n",
    "    'Score': score,\n",
    "    'R square Accuracy': R2,\n",
    "    'Mean Absolute Error Accuracy': MAE,\n",
    "    'Mean Squared Error Accuracy': MSE,\n",
    "    'Root Mean Squared Error': RMSE,\n",
    "    'Training Time': average_time,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'date': str(datetime.now())\n",
    "}\n",
    "import json\n",
    "\n",
    "def update_results():\n",
    "    results_filename = '../../results/results.json'\n",
    "\n",
    "    with open(results_filename) as f:\n",
    "        raw_audit = f.read()\n",
    "    results_json = json.loads(raw_audit)\n",
    "\n",
    "    results_json[f'{ALGORITHM} - {ALGORITHM_DETAIL} (v{VERSION})'.lower()] = results\n",
    "\n",
    "    with open(results_filename, 'w') as file:\n",
    "        file.write(json.dumps(results_json, indent=4))\n",
    "\n",
    "if not IN_COLAB:\n",
    "    update_results()\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
