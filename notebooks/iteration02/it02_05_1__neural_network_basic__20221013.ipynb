{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM = 'Neural Network'\n",
    "ALGORITHM_DETAIL = 'basic'\n",
    "VERSION = '02'\n",
    "\n",
    "RANDOM_STATE = 101\n",
    "TRAINING_SIZE = 0.9\n",
    "\n",
    "CROSS_VALIDATION_SCORING = 'r2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "def build_and_compile_model(norm):\n",
    "    model = keras.Sequential([\n",
    "        norm,\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        #layers.Dense(132, activation='relu'),\n",
    "        #layers.Dense(132, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    return model\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "\n",
    "dnn_model = build_and_compile_model(normalizer)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    #('mms', MinMaxScaler()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('model', dnn_model)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "from termcolor import colored\n",
    "\n",
    "confirm_colab = False\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = confirm_colab\n",
    "\n",
    "if not IN_COLAB:\n",
    "    import functions_20221012\n",
    "    from functions_20221012 import set_csv_directory\n",
    "\n",
    "    set_csv_directory('final_split')\n",
    "\n",
    "debug_mode = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mfeatures\u001B[0m ->  ['location.latitude', 'location.longitude', 'bedrooms', 'bathrooms', 'nearestStation', 'tenure.tenureType']\n",
      "\u001B[1m\u001B[32mlabel\u001B[0m ->  Price\n"
     ]
    }
   ],
   "source": [
    "#cutdown_rows = 1000\n",
    "cutdown_rows = 0\n",
    "\n",
    "LABEL = 'Price'\n",
    "\n",
    "booleans = []\n",
    "floats = ['location.latitude', 'location.longitude', 'bedrooms', 'bathrooms', 'nearestStation']\n",
    "categories = ['tenure.tenureType']\n",
    "\n",
    "columns = []\n",
    "columns.extend(booleans)\n",
    "columns.extend(floats)\n",
    "columns.extend(categories)\n",
    "\n",
    "print(colored(f\"features\", \"blue\"), \"-> \", columns)\n",
    "columns.insert(0, LABEL)\n",
    "print(colored(f\"label\", \"green\", None, ['bold']), \"-> \", LABEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "filename = f'df_listings_v{VERSION}.csv'\n",
    "remote_pathname = f'https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/{filename}'\n",
    "df_pathname_raw = f'../../data/source/{filename}'\n",
    "df_pathname_tidy = f'../../data/final/{filename}'\n",
    "\n",
    "\n",
    "def get_source_dataframe(rows=cutdown_rows, folder_prefix='../'):\n",
    "    retrieval_type = None\n",
    "\n",
    "    if IN_COLAB:\n",
    "        inDF = pd.read_csv(remote_pathname, on_bad_lines='error', index_col=0)\n",
    "        retrieval_type = 'tidy'\n",
    "        print('loaded data from', remote_pathname)\n",
    "    else:\n",
    "        try:\n",
    "            inDF = pd.read_csv(df_pathname_tidy, on_bad_lines='error', index_col=0)\n",
    "            retrieval_type = 'tidy'\n",
    "            print('loaded data from', df_pathname_tidy)\n",
    "        except:\n",
    "            print(f\"WARNING: Failed to retrieved stored data for version {VERSION}, creating new source data.\")\n",
    "            inDF = functions_20221012.get_combined_dataset(HOW='inner', early_duplicates=True,\n",
    "                                                           folder_prefix=folder_prefix)\n",
    "            inDF.to_csv(df_pathname_raw)\n",
    "            retrieval_type = 'raw'\n",
    "\n",
    "    if rows and rows > 0:\n",
    "        inDF = inDF[:rows]\n",
    "    return inDF, retrieval_type\n",
    "\n",
    "\n",
    "def create_train_test_data(df_orig, return_index=False, drop_nulls=True):\n",
    "    df = df_orig.copy()\n",
    "\n",
    "    if drop_nulls:\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "    if return_index:\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "    for column in categories:\n",
    "        df = pd.concat([df, pd.get_dummies(df[column], prefix=column)], axis=1)\n",
    "        df.drop([column], axis=1, inplace=True)  # now drop the original column (you don't need it anymore),\n",
    "\n",
    "    ins = df.pop('index')\n",
    "    df.insert(1, 'index2', ins)\n",
    "    df.insert(0, 'index', ins)\n",
    "\n",
    "    #features = df[df.columns[1:]].values\n",
    "    features = df[df.columns[2:]].values\n",
    "    #labels = df[LABEL].values\n",
    "    labels = df.iloc[:, 0:2].values\n",
    "\n",
    "    if not return_index:\n",
    "        return train_test_split(features, labels, train_size=0.9, random_state=RANDOM_STATE)\n",
    "    else:\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(features, labels, train_size=0.9,\n",
    "                                                                random_state=RANDOM_STATE)\n",
    "        X_train_index = X_train1[:, 0].reshape(-1, 1)\n",
    "        y_train_index = y_train1[:, 0].reshape(-1, 1)\n",
    "        X_test_index = X_test1[:, 0].reshape(-1, 1)\n",
    "        y_test_index = y_test1[:, 0].reshape(-1, 1)\n",
    "        X_train1 = X_train1[:, 1:]\n",
    "        y_train1 = y_train1[:, 1].reshape(-1, 1)\n",
    "        X_test1 = X_test1[:, 1:]\n",
    "        y_test1 = y_test1[:, 1].reshape(-1, 1)\n",
    "\n",
    "        return X_train1, X_test1, y_train1, y_test1, X_train_index, X_test_index, y_train_index, y_test_index\n",
    "\n",
    "#X_train, X_test, y_train, y_test, X_train_index, X_test_index, y_train_index, y_test_index = create_train_test_data(get_source_dataframe(), return_index=True, drop_nulls=False)\n",
    "#X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_train_index.shape, X_test_index.shape, y_train_index.shape, y_test_index.shape,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data from ../../data/final/df_listings_v02.csv\n",
      "(52117, 7)\n",
      "Int64Index([ 14520525,  27953107,  33593487,  35271294,  35429088,  44749111,\n",
      "             46204665,  49020666,  49036279,  49303873,\n",
      "            ...\n",
      "            126173423, 126173600, 126175973, 126178769, 126179018, 126179672,\n",
      "            126180107, 126180704, 126180962, 126181118],\n",
      "           dtype='int64', length=52117)\n"
     ]
    }
   ],
   "source": [
    "df, retrieval_type = get_source_dataframe(folder_prefix='../../')\n",
    "df_orig = df.copy()\n",
    "\n",
    "if retrieval_type != 'tidy':\n",
    "    df = functions_20221012.add_supplements(df)\n",
    "    df.to_csv(df_pathname_raw)\n",
    "    df = functions_20221012.tidy_dataset(df, version=int(VERSION))\n",
    "\n",
    "    df = df[columns]\n",
    "\n",
    "    df.to_csv(df_pathname_tidy)\n",
    "\n",
    "print(df.shape)\n",
    "df[:5]\n",
    "\n",
    "df_orig.merge(df, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "print(df.index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "              Price location.latitude  location.longitude  bedrooms  \\\n14520525   550000.0          51.52995           -0.207020       3.0   \n27953107   400000.0          51.54939           -0.482600       2.0   \n33593487   579950.0          51.44718           -0.338770       2.0   \n35271294   370000.0         51.449568           -0.140154       2.0   \n35429088   599950.0          51.57703           -0.141230       2.0   \n...             ...               ...                 ...       ...   \n126179672  600000.0          51.35717           -0.074740       3.0   \n126180107  419999.0         51.531415           -0.052964       2.0   \n126180704  475000.0         51.543141            0.011498       2.0   \n126180962  450000.0         51.592105           -0.008233       NaN   \n126181118  525000.0         51.424589           -0.206790       2.0   \n\n           bathrooms  nearestStation  tenure.tenureType  \n14520525         1.0        0.274316          LEASEHOLD  \n27953107         2.0        0.305845          LEASEHOLD  \n33593487         1.0        0.438045           FREEHOLD  \n35271294         1.0        0.399307          LEASEHOLD  \n35429088         1.0        0.238187                NaN  \n...              ...             ...                ...  \n126179672        2.0        0.545665          LEASEHOLD  \n126180107        1.0        0.191407          LEASEHOLD  \n126180704        1.0        0.308609          LEASEHOLD  \n126180962        1.0        0.476935           FREEHOLD  \n126181118        1.0        0.238489  SHARE_OF_FREEHOLD  \n\n[52117 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>location.latitude</th>\n      <th>location.longitude</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n      <th>tenure.tenureType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14520525</th>\n      <td>550000.0</td>\n      <td>51.52995</td>\n      <td>-0.207020</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.274316</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>27953107</th>\n      <td>400000.0</td>\n      <td>51.54939</td>\n      <td>-0.482600</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.305845</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>33593487</th>\n      <td>579950.0</td>\n      <td>51.44718</td>\n      <td>-0.338770</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.438045</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>35271294</th>\n      <td>370000.0</td>\n      <td>51.449568</td>\n      <td>-0.140154</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.399307</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>35429088</th>\n      <td>599950.0</td>\n      <td>51.57703</td>\n      <td>-0.141230</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.238187</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>126179672</th>\n      <td>600000.0</td>\n      <td>51.35717</td>\n      <td>-0.074740</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.545665</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>126180107</th>\n      <td>419999.0</td>\n      <td>51.531415</td>\n      <td>-0.052964</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.191407</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>126180704</th>\n      <td>475000.0</td>\n      <td>51.543141</td>\n      <td>0.011498</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.308609</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>126180962</th>\n      <td>450000.0</td>\n      <td>51.592105</td>\n      <td>-0.008233</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.476935</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>126181118</th>\n      <td>525000.0</td>\n      <td>51.424589</td>\n      <td>-0.206790</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.238489</td>\n      <td>SHARE_OF_FREEHOLD</td>\n    </tr>\n  </tbody>\n</table>\n<p>52117 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "Price                    0\nlocation.latitude        0\nlocation.longitude       0\nbedrooms              1742\nbathrooms             3173\nnearestStation           0\ntenure.tenureType     3402\ndtype: int64"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 52117 entries, 14520525 to 126181118\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Price               52117 non-null  float64\n",
      " 1   location.latitude   52117 non-null  object \n",
      " 2   location.longitude  52117 non-null  float64\n",
      " 3   bedrooms            50375 non-null  float64\n",
      " 4   bathrooms           48944 non-null  float64\n",
      " 5   nearestStation      52117 non-null  float64\n",
      " 6   tenure.tenureType   48715 non-null  object \n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 5.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "               Price  location.longitude       bedrooms     bathrooms  \\\ncount   52117.000000        52117.000000   50375.000000  48944.000000   \nmean   419854.956790           -0.104810      11.721787      1.177182   \nstd    110342.806124            0.731478    2183.166275      0.410552   \nmin    100000.000000           -0.498315       1.000000      1.000000   \n25%    330000.000000           -0.211852       1.000000      1.000000   \n50%    425000.000000           -0.104440       2.000000      1.000000   \n75%    500000.000000           -0.011509       3.000000      1.000000   \nmax    600000.000000           51.558746  490000.000000     12.000000   \n\n       nearestStation  \ncount    52117.000000  \nmean         0.445245  \nstd          1.066809  \nmin          0.000000  \n25%          0.224233  \n50%          0.363994  \n75%          0.557263  \nmax        192.431869  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>location.longitude</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>52117.000000</td>\n      <td>52117.000000</td>\n      <td>50375.000000</td>\n      <td>48944.000000</td>\n      <td>52117.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>419854.956790</td>\n      <td>-0.104810</td>\n      <td>11.721787</td>\n      <td>1.177182</td>\n      <td>0.445245</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>110342.806124</td>\n      <td>0.731478</td>\n      <td>2183.166275</td>\n      <td>0.410552</td>\n      <td>1.066809</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>100000.000000</td>\n      <td>-0.498315</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>330000.000000</td>\n      <td>-0.211852</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.224233</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>425000.000000</td>\n      <td>-0.104440</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.363994</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>500000.000000</td>\n      <td>-0.011509</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>0.557263</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>600000.000000</td>\n      <td>51.558746</td>\n      <td>490000.000000</td>\n      <td>12.000000</td>\n      <td>192.431869</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe contract due to cleaning: 52117 ==> 47444\n"
     ]
    },
    {
     "data": {
      "text/plain": "                      count           mean            std            min  \\\nPrice               47444.0  424032.547382  108060.063745  100000.000000   \nlocation.latitude   47444.0      51.496962       0.077034      51.298317   \nlocation.longitude  47444.0      -0.113297       0.156316      -0.498315   \nbedrooms            47444.0       1.990557       0.828428       1.000000   \nbathrooms           47444.0       1.182173       0.410188       1.000000   \nnearestStation      47444.0       0.439824       0.354467       0.000000   \n\n                              25%            50%            75%            max  \nPrice               345000.000000  425000.000000  511500.000000  600000.000000  \nlocation.latitude       51.438814      51.499890      51.555916      51.683185  \nlocation.longitude      -0.210785      -0.102333      -0.010485       0.279726  \nbedrooms                 1.000000       2.000000       3.000000       7.000000  \nbathrooms                1.000000       1.000000       1.000000       5.000000  \nnearestStation           0.226450       0.367506       0.558826      16.168861  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Price</th>\n      <td>47444.0</td>\n      <td>424032.547382</td>\n      <td>108060.063745</td>\n      <td>100000.000000</td>\n      <td>345000.000000</td>\n      <td>425000.000000</td>\n      <td>511500.000000</td>\n      <td>600000.000000</td>\n    </tr>\n    <tr>\n      <th>location.latitude</th>\n      <td>47444.0</td>\n      <td>51.496962</td>\n      <td>0.077034</td>\n      <td>51.298317</td>\n      <td>51.438814</td>\n      <td>51.499890</td>\n      <td>51.555916</td>\n      <td>51.683185</td>\n    </tr>\n    <tr>\n      <th>location.longitude</th>\n      <td>47444.0</td>\n      <td>-0.113297</td>\n      <td>0.156316</td>\n      <td>-0.498315</td>\n      <td>-0.210785</td>\n      <td>-0.102333</td>\n      <td>-0.010485</td>\n      <td>0.279726</td>\n    </tr>\n    <tr>\n      <th>bedrooms</th>\n      <td>47444.0</td>\n      <td>1.990557</td>\n      <td>0.828428</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>bathrooms</th>\n      <td>47444.0</td>\n      <td>1.182173</td>\n      <td>0.410188</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>nearestStation</th>\n      <td>47444.0</td>\n      <td>0.439824</td>\n      <td>0.354467</td>\n      <td>0.000000</td>\n      <td>0.226450</td>\n      <td>0.367506</td>\n      <td>0.558826</td>\n      <td>16.168861</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_length = len(df)\n",
    "df['location.latitude'] = pd.to_numeric(df['location.latitude'], 'coerce').dropna().astype(float)\n",
    "df = df[(df['location.longitude'] <= 10)]\n",
    "df = df[(df['bedrooms'] <= 10)]\n",
    "df = df[df['bathrooms'] <= 5]\n",
    "df = df[(df['nearestStation'] <= 20)]\n",
    "\n",
    "print(f\"dataframe contract due to cleaning: {old_length} ==> {len(df)}\")\n",
    "old_length = len(df)\n",
    "\n",
    "df.describe().T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "Price                    0\nlocation.latitude        0\nlocation.longitude       0\nbedrooms                 0\nbathrooms                0\nnearestStation           0\ntenure.tenureType     2780\ndtype: int64"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47444 ==> 44664\n"
     ]
    },
    {
     "data": {
      "text/plain": "               Price  location.latitude  location.longitude      bedrooms  \\\ncount   44664.000000       44664.000000        44664.000000  44664.000000   \nmean   424197.633598          51.496602           -0.113125      1.989208   \nstd    107989.580699           0.077221            0.155684      0.827142   \nmin    100000.000000          51.298317           -0.498315      1.000000   \n25%    345000.000000          51.438246           -0.210584      1.000000   \n50%    425000.000000          51.498681           -0.101934      2.000000   \n75%    515000.000000          51.555979           -0.010933      3.000000   \nmax    600000.000000          51.683185            0.279726      7.000000   \n\n          bathrooms  nearestStation  \ncount  44664.000000    44664.000000  \nmean       1.181332        0.439504  \nstd        0.409031        0.353470  \nmin        1.000000        0.000000  \n25%        1.000000        0.226771  \n50%        1.000000        0.367875  \n75%        1.000000        0.558693  \nmax        5.000000       16.168861  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>location.latitude</th>\n      <th>location.longitude</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>44664.000000</td>\n      <td>44664.000000</td>\n      <td>44664.000000</td>\n      <td>44664.000000</td>\n      <td>44664.000000</td>\n      <td>44664.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>424197.633598</td>\n      <td>51.496602</td>\n      <td>-0.113125</td>\n      <td>1.989208</td>\n      <td>1.181332</td>\n      <td>0.439504</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>107989.580699</td>\n      <td>0.077221</td>\n      <td>0.155684</td>\n      <td>0.827142</td>\n      <td>0.409031</td>\n      <td>0.353470</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>100000.000000</td>\n      <td>51.298317</td>\n      <td>-0.498315</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>345000.000000</td>\n      <td>51.438246</td>\n      <td>-0.210584</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.226771</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>425000.000000</td>\n      <td>51.498681</td>\n      <td>-0.101934</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.367875</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>515000.000000</td>\n      <td>51.555979</td>\n      <td>-0.010933</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>0.558693</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>600000.000000</td>\n      <td>51.683185</td>\n      <td>0.279726</td>\n      <td>7.000000</td>\n      <td>5.000000</td>\n      <td>16.168861</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(f\"{old_length} ==> {len(df)}\")\n",
    "old_length = len(df)\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40197, 9) (4467, 9) (40197, 1) (4467, 1) (40197, 1) (4467, 1) (40197, 1) (4467, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_train_index, X_test_index, y_train_index, y_test_index = create_train_test_data(df,\n",
    "                                                                                                                    return_index=True,\n",
    "                                                                                                                    drop_nulls=True)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_train_index.shape, X_test_index.shape,\n",
    "      y_train_index.shape, y_test_index.shape)\n",
    "#print(type(X_train))\n",
    "#X_train[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "#imputer = SimpleImputer(strategy='mean')\n",
    "#imputer.fit(X_train[6])\n",
    "#X_train[6] = imputer.transform(X_train[6])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "#pipe.fit(X_train, y_train)\n",
    "\n",
    "model = dnn_model\n",
    "#model.fit(X_train, y_train)\n",
    "if False:\n",
    "    model.get_params()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "{}"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Best Score:  0.30582573121661794\n",
    "# Best Score:  {'alpha': 10, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'selection': 'cyclic', 'tol': 0.001, 'warm_start': True}\n",
    "# Best Score:  Lasso(alpha=10, tol=0.001, warm_start=True)\n",
    "# Best Score:  138\n",
    "\n",
    "options_block = {}\n",
    "\n",
    "# find optimal alpha with grid search\n",
    "ccp_alpha = [0, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "criterion = ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']\n",
    "max_depth = [None, 1, 2, 3, 5, 10, 20]\n",
    "max_features = [1, 2, 3, 5, 10, 20, len(columns)]\n",
    "max_leaf_nodes = [2, 3, 5, 10, 20]\n",
    "min_impurity_decrease = [None, 0, 1, 2, 3, 5]\n",
    "min_samples_leaf = [1, 2, 3, 5]\n",
    "min_samples_split = [2, 3, 5, 10]\n",
    "min_weight_fraction_leaf = [0.1, 0.2, 0.3, 0.5]\n",
    "splitter = ['best', 'random']\n",
    "\n",
    "max_iter = [100, 1000, 10000]\n",
    "\n",
    "options__n_neighbours = [3, 5, 7, 9, 15, 31]\n",
    "options__leafsize = [2, 3, 4, 57, 9, 13, 21]\n",
    "\n",
    "param_grid = dict(model__ccp_alpha=ccp_alpha, model__criterion=criterion, model__max_depth=max_depth,\n",
    "                  model__max_features=max_features, model__max_leaf_nodes=max_leaf_nodes,\n",
    "                  model__min_impurity_decrease=min_impurity_decrease,\n",
    "                  model__min_samples_leaf=min_samples_leaf, model__min_samples_split=min_samples_split,\n",
    "                  model__min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                  model__splitter=splitter\n",
    "                  )\n",
    "param_grid = {}\n",
    "for each in options_block:\n",
    "    if type (options_block[each]) == list:\n",
    "        param_grid['model__' + each] = options_block[each]\n",
    "    else:\n",
    "        param_grid['model__' + each] = [options_block[each]]\n",
    "param_grid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 2/10\n",
      "Epoch 3/10\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n",
      "Epoch 7/10\n",
      "Epoch 8/10\n",
      "Epoch 9/10\n",
      "Epoch 10/10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = 3\n",
    "n_jobs = 1\n",
    "verbose = 1\n",
    "refit = True\n",
    "\n",
    "#grid = RandomizedSearchCV(estimator=model, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "\n",
    "# gs = RandomizedSearchCV(pipe, param_grid, cv=cv, n_jobs=n_jobs,\n",
    "#                         verbose=verbose, scoring=CROSS_VALIDATION_SCORING,\n",
    "#                         #refit=refit,\n",
    "#                         return_train_score=True, n_iter=300),\n",
    "# gs\n",
    "#\n",
    "# grid_result = gs[0].fit(X_train, y_train)\n",
    "\n",
    "history = dnn_model.fit(\n",
    "X_train,  # train_features,\n",
    "y_train,  # train_labels,\n",
    "validation_split=0.2,\n",
    "verbose=10, epochs=10)\n",
    "\n",
    "    #print(dnn_model.evaluate(X_test, y_test, verbose=0))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "pipe = grid_result.best_estimator_\n",
    "timings = []\n",
    "\n",
    "if False:\n",
    "    t0 = time()\n",
    "    pipe.fit(X_train, y_train)\n",
    "    timings.append(time() - t0)\n",
    "\n",
    "    print(timings)\n",
    "    average_time = sum(timings) / len(timings)\n",
    "    print(average_time)\n",
    "else:\n",
    "    timings = [999]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {}\n",
      "-16.123 (+/-8.329) for {}\n",
      "Best Index:  0\n",
      "Best Score:  -16.123132752269367\n",
      "Best Params:  {}\n"
     ]
    }
   ],
   "source": [
    "def print_results(results):\n",
    "    print(f'BEST PARAMS: {results.best_params_}')\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print(f'{round(mean, 3)} (+/-{round(std * 2, 3)}) for {params}')\n",
    "\n",
    "\n",
    "print_results(grid_result)\n",
    "print('Best Index: ', grid_result.best_index_)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)\n",
    "#print('Best Model: ', grid_result.)\n",
    "#print('Best Params: ', grid_result.best_params_)[out]\n",
    "### Best Score:  0.4883436188936269\n",
    "### Best Params:  {'alpha': 0.01}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "<keras.engine.sequential.Sequential at 0x7ffafc839070>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"/home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 8), found shape=(None, 9)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [96], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#y_pred = pipe.predict(X_test)\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m pipe[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mevaluate(X_test, y_test, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/tmp/__autograph_generated_filepg5qbdtz.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"/home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 8), found shape=(None, 9)\n"
     ]
    }
   ],
   "source": [
    "#y_pred = pipe.predict(X_test)\n",
    "y_pred = pipe[1].evaluate(X_test, y_test, verbose=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "y_pred = y_pred.reshape((-1, 1))\n",
    "\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = math.sqrt(MSE)\n",
    "print('-' * 10 + ALGORITHM + '-' * 10)\n",
    "print('R square Accuracy', R2)\n",
    "print('Mean Absolute Error Accuracy', MAE)\n",
    "print('Mean Squared Error Accuracy', MSE)\n",
    "print('Root Mean Squared Error', RMSE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    print(y_test_index.reshape((-1, 1)).shape);\n",
    "    print(y_pred.reshape((-1, 1)).shape);\n",
    "    print(y_test.shape);\n",
    "    print(y_test_index.shape);\n",
    "    print(y_pred.shape);\n",
    "    print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compare = np.hstack((y_test_index, y_test, y_pred))\n",
    "compare_df = DataFrame(compare, columns=['reference', 'actual', 'predicted'])\n",
    "compare_df['difference'] = abs(compare_df['actual'] - compare_df['predicted'])\n",
    "compare_df['diff 1 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['actual'] * 100)\n",
    "compare_df['diff 2 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['predicted']) * 100\n",
    "compare_df['reference'] = compare_df['reference'].astype(str)\n",
    "compare_df.set_index('reference', inplace=True)\n",
    "compare_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compare_df.merge(df[columns], how='inner', left_index=True, right_index=True).sort_values(['diff 1 %'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = pipe.score(X_test, y_test)\n",
    "score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, pipe.predict(X_test), edgecolors=(0, 0, 1))\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_xlabel('Actual')\n",
    "#ax.title.set_text(f'CV Chosen best option ({calculated_best_pipe[1]})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "results = {\n",
    "    'Score': score,\n",
    "    'R square Accuracy': R2,\n",
    "    'Mean Absolute Error Accuracy': MAE,\n",
    "    'Mean Squared Error Accuracy': MSE,\n",
    "    'Root Mean Squared Error': RMSE,\n",
    "    'Training Time': average_time,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'date': str(datetime.now()),\n",
    "}\n",
    "import json\n",
    "\n",
    "\n",
    "def get_results():\n",
    "    results_filename = '../../results/results.json'\n",
    "\n",
    "    with open(results_filename) as f:\n",
    "        raw_audit = f.read()\n",
    "    results_json = json.loads(raw_audit)\n",
    "    return results_json\n",
    "\n",
    "def update_results(results_json, new_results):\n",
    "\n",
    "    key = f'{ALGORITHM} - {ALGORITHM_DETAIL} (v{VERSION})'.lower()\n",
    "    try:\n",
    "        first_run_date = str(datetime.now())\n",
    "        first_run_date = results_json[key]['date']\n",
    "        first_run_date = results_json[key]['first run']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    results['first run'] = first_run_date\n",
    "\n",
    "    results_json[key] = new_results\n",
    "\n",
    "    results_filename = '../../results/results.json'\n",
    "    with open(results_filename, 'w') as file:\n",
    "        file.write(json.dumps(results_json, indent=4))\n",
    "\n",
    "\n",
    "if not IN_COLAB:\n",
    "    results_json = get_results()\n",
    "    update_results(results_json, results)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
