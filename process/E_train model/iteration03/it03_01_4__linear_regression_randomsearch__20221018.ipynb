{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM = 'Linear Regression'\n",
    "ALGORITHM_DETAIL = 'random search'\n",
    "VERSION = '03'\n",
    "\n",
    "RANDOM_STATE = 101\n",
    "TRAINING_SIZE = 0.9\n",
    "\n",
    "CROSS_VALIDATION_SCORING = 'r2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "pipe = Pipeline([\n",
    "    #('mms', MinMaxScaler()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('model', Ridge())\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "from termcolor import colored\n",
    "\n",
    "confirm_colab = False\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = confirm_colab\n",
    "\n",
    "if not IN_COLAB:\n",
    "    from functions_20221018 import set_csv_directory, get_combined_dataset, add_supplements, tidy_dataset, feature_engineer\n",
    "\n",
    "set_csv_directory('final_split')\n",
    "\n",
    "debug_mode = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mfeatures\u001B[0m ->  ['bedrooms', 'bathrooms', 'nearestStation', 'latitude_deviation2', 'longitude_deviation2', 'tenure.tenureType']\n",
      "\u001B[1m\u001B[32mlabel\u001B[0m ->  Price\n"
     ]
    }
   ],
   "source": [
    "#cutdown_rows = 1000\n",
    "cutdown_rows = 0\n",
    "\n",
    "LABEL = 'Price'\n",
    "\n",
    "booleans = []\n",
    "floats = ['location.latitude', 'location.longitude', 'bedrooms', 'bathrooms', 'nearestStation', 'latitude_deviation',\n",
    "          'latitude_deviation2', 'longitude_deviation', 'longitude_deviation2']\n",
    "floats = ['bedrooms', 'bathrooms', 'nearestStation', 'latitude_deviation2', 'longitude_deviation2']\n",
    "categories = ['tenure.tenureType']\n",
    "\n",
    "columns = []\n",
    "columns.extend(booleans)\n",
    "columns.extend(floats)\n",
    "columns.extend(categories)\n",
    "\n",
    "print(colored(f\"features\", \"blue\"), \"-> \", columns)\n",
    "columns.insert(0, LABEL)\n",
    "print(colored(f\"label\", \"green\", None, ['bold']), \"-> \", LABEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "filename = f'df_listings_v{VERSION}.csv'\n",
    "remote_pathname = f'https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/{filename}'\n",
    "df_pathname_raw = f'../../data/source/{filename}'\n",
    "df_pathname_tidy = f'../../data/final/{filename}'\n",
    "\n",
    "\n",
    "def get_source_dataframe(rows=cutdown_rows, folder_prefix='../'):\n",
    "    retrieval_type = None\n",
    "\n",
    "    if IN_COLAB:\n",
    "        inDF = pd.read_csv(remote_pathname, on_bad_lines='error', index_col=0)\n",
    "        retrieval_type = 'tidy'\n",
    "        print('loaded data from', remote_pathname)\n",
    "    else:\n",
    "        try:\n",
    "            inDF = pd.read_csv(df_pathname_tidy, on_bad_lines='error', index_col=0)\n",
    "            retrieval_type = 'tidy'\n",
    "            print('loaded data from', df_pathname_tidy)\n",
    "        except:\n",
    "            try:\n",
    "                inDF = pd.read_csv(df_pathname_raw, on_bad_lines='error', index_col=0)\n",
    "                retrieval_type = 'raw'\n",
    "                print(f'starting to get {retrieval_type} data...')\n",
    "                print('loaded data from', df_pathname_raw)\n",
    "                print(f'finished getting {retrieval_type} data!')\n",
    "            except:\n",
    "                print(f\"WARNING: Failed to retrieved stored data for version {VERSION}, creating new source data.\")\n",
    "                retrieval_type = 'scratch'\n",
    "                print(f'starting to get {retrieval_type} data...')\n",
    "                inDF = get_combined_dataset(HOW='inner', early_duplicates=True, folder_prefix=folder_prefix)\n",
    "                print(f'finished getting {retrieval_type} data!')\n",
    "\n",
    "                print(f'starting to save {retrieval_type} data...')\n",
    "                inDF.to_csv(df_pathname_raw)\n",
    "                print(f'finished saving {retrieval_type} data!')\n",
    "\n",
    "    if rows and rows > 0:\n",
    "        inDF = inDF[:rows]\n",
    "    return inDF, retrieval_type\n",
    "\n",
    "\n",
    "def create_train_test_data(df_orig, return_index=False, drop_nulls=True):\n",
    "    df = df_orig.copy()\n",
    "\n",
    "    if drop_nulls:\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "    if return_index:\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "    for column in categories:\n",
    "        df = pd.concat([df, pd.get_dummies(df[column], prefix=column)], axis=1)\n",
    "        df.drop([column], axis=1, inplace=True)  # now drop the original column (you don't need it anymore),\n",
    "\n",
    "    ins = df.pop('index')\n",
    "    df.insert(1, 'index2', ins)\n",
    "    df.insert(0, 'index', ins)\n",
    "\n",
    "    #features = df[df.columns[1:]].values\n",
    "    features = df[df.columns[2:]].values\n",
    "    #labels = df[LABEL].values\n",
    "    labels = df.iloc[:, 0:2].values\n",
    "\n",
    "    if not return_index:\n",
    "        return train_test_split(features, labels, train_size=0.9, random_state=RANDOM_STATE)\n",
    "    else:\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(features, labels, train_size=0.9,\n",
    "                                                                random_state=RANDOM_STATE)\n",
    "        X_train_index = X_train1[:, 0].reshape(-1, 1)\n",
    "        y_train_index = y_train1[:, 0].reshape(-1, 1)\n",
    "        X_test_index = X_test1[:, 0].reshape(-1, 1)\n",
    "        y_test_index = y_test1[:, 0].reshape(-1, 1)\n",
    "        X_train1 = X_train1[:, 1:]\n",
    "        y_train1 = y_train1[:, 1].reshape(-1, 1)\n",
    "        X_test1 = X_test1[:, 1:]\n",
    "        y_test1 = y_test1[:, 1].reshape(-1, 1)\n",
    "\n",
    "        return X_train1, X_test1, y_train1, y_test1, X_train_index, X_test_index, y_train_index, y_test_index\n",
    "\n",
    "#X_train, X_test, y_train, y_test, X_train_index, X_test_index, y_train_index, y_test_index = create_train_test_data(get_source_dataframe(), return_index=True, drop_nulls=False)\n",
    "#X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_train_index.shape, X_test_index.shape, y_train_index.shape, y_test_index.shape,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data from ../../data/final/df_listings_v03.csv\n",
      "(51501, 7)\n",
      "Int64Index([ 14520525,  27953107,  33593487,  35271294,  35429088,  44749111,\n",
      "             46204665,  49020666,  49036279,  49303873,\n",
      "            ...\n",
      "            126173423, 126173600, 126175973, 126178769, 126179018, 126179672,\n",
      "            126180107, 126180704, 126180962, 126181118],\n",
      "           dtype='int64', length=51501)\n"
     ]
    }
   ],
   "source": [
    "df, retrieval_type = get_source_dataframe(folder_prefix='../../')\n",
    "df_orig = df.copy()\n",
    "\n",
    "if retrieval_type != 'tidy':\n",
    "    if retrieval_type != 'raw':\n",
    "        df = add_supplements(df)\n",
    "        print(f'starting to save {retrieval_type} data...')\n",
    "        df.to_csv(df_pathname_raw)\n",
    "        print(f'finished saving {retrieval_type} data!')\n",
    "    df = tidy_dataset(df, version=int(VERSION))\n",
    "    df = feature_engineer(df, version=int(VERSION))\n",
    "\n",
    "    df = df[columns]\n",
    "\n",
    "    print(f'starting to save {retrieval_type} data...')\n",
    "    df.to_csv(df_pathname_tidy)\n",
    "    print(f'finished saving {retrieval_type} data!')\n",
    "\n",
    "print(df.shape)\n",
    "df[:5]\n",
    "\n",
    "df_orig.merge(df, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "print(df.index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "              Price  bedrooms  bathrooms  nearestStation  latitude_deviation  \\\n14520525   550000.0       3.0        1.0        0.274316            0.067288   \n27953107   400000.0       2.0        2.0        0.305845            0.086728   \n33593487   579950.0       2.0        1.0        0.438045            0.015482   \n35271294   370000.0       2.0        1.0        0.399307            0.013094   \n35429088   599950.0       2.0        1.0        0.238187            0.114368   \n...             ...       ...        ...             ...                 ...   \n126179672  600000.0       3.0        2.0        0.545665            0.105492   \n126180107  419999.0       2.0        1.0        0.191407            0.068753   \n126180704  475000.0       2.0        1.0        0.308609            0.080479   \n126180962  450000.0       NaN        1.0        0.476935            0.129443   \n126181118  525000.0       2.0        1.0        0.238489            0.038073   \n\n           longitude_deviation  tenure.tenureType  \n14520525              0.141915          LEASEHOLD  \n27953107              0.417495          LEASEHOLD  \n33593487              0.273665           FREEHOLD  \n35271294              0.075049          LEASEHOLD  \n35429088              0.076125                NaN  \n...                        ...                ...  \n126179672             0.009635          LEASEHOLD  \n126180107             0.012141          LEASEHOLD  \n126180704             0.076603          LEASEHOLD  \n126180962             0.056872           FREEHOLD  \n126181118             0.141685  SHARE_OF_FREEHOLD  \n\n[51501 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n      <th>latitude_deviation</th>\n      <th>longitude_deviation</th>\n      <th>tenure.tenureType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14520525</th>\n      <td>550000.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.274316</td>\n      <td>0.067288</td>\n      <td>0.141915</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>27953107</th>\n      <td>400000.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.305845</td>\n      <td>0.086728</td>\n      <td>0.417495</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>33593487</th>\n      <td>579950.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.438045</td>\n      <td>0.015482</td>\n      <td>0.273665</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>35271294</th>\n      <td>370000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.399307</td>\n      <td>0.013094</td>\n      <td>0.075049</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>35429088</th>\n      <td>599950.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.238187</td>\n      <td>0.114368</td>\n      <td>0.076125</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>126179672</th>\n      <td>600000.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.545665</td>\n      <td>0.105492</td>\n      <td>0.009635</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>126180107</th>\n      <td>419999.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.191407</td>\n      <td>0.068753</td>\n      <td>0.012141</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>126180704</th>\n      <td>475000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.308609</td>\n      <td>0.080479</td>\n      <td>0.076603</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>126180962</th>\n      <td>450000.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.476935</td>\n      <td>0.129443</td>\n      <td>0.056872</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>126181118</th>\n      <td>525000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.238489</td>\n      <td>0.038073</td>\n      <td>0.141685</td>\n      <td>SHARE_OF_FREEHOLD</td>\n    </tr>\n  </tbody>\n</table>\n<p>51501 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Price                     0\nbedrooms               1714\nbathrooms              3149\nnearestStation            0\nlatitude_deviation       10\nlongitude_deviation       0\ntenure.tenureType      3352\ndtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 51501 entries, 14520525 to 126181118\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Price                51501 non-null  float64\n",
      " 1   bedrooms             49787 non-null  float64\n",
      " 2   bathrooms            48352 non-null  float64\n",
      " 3   nearestStation       51501 non-null  float64\n",
      " 4   latitude_deviation   51491 non-null  float64\n",
      " 5   longitude_deviation  51501 non-null  float64\n",
      " 6   tenure.tenureType    48149 non-null  object \n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 5.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "               Price       bedrooms     bathrooms  nearestStation  \\\ncount   51501.000000   49787.000000  48352.000000    51501.000000   \nmean   420845.464438      11.838693      1.177159        0.445829   \nstd    109595.522981    2196.020360      0.410369        1.071443   \nmin    100000.000000       1.000000      1.000000        0.000000   \n25%    335000.000000       1.000000      1.000000        0.224756   \n50%    425000.000000       2.000000      1.000000        0.364523   \n75%    500000.000000       3.000000      1.000000        0.558390   \nmax    600000.000000  490000.000000     12.000000      192.431869   \n\n       latitude_deviation  longitude_deviation  \ncount        5.149100e+04         5.150100e+04  \nmean         6.952685e-02         1.391510e-01  \nstd          4.656998e-02         7.234829e-01  \nmin          4.000000e-07         2.000000e-07  \n25%          3.113350e-02         4.650480e-02  \n50%          6.375360e-02         1.033192e-01  \n75%          1.010514e-01         1.976652e-01  \nmax          2.205226e-01         5.162385e+01  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n      <th>latitude_deviation</th>\n      <th>longitude_deviation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>51501.000000</td>\n      <td>49787.000000</td>\n      <td>48352.000000</td>\n      <td>51501.000000</td>\n      <td>5.149100e+04</td>\n      <td>5.150100e+04</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>420845.464438</td>\n      <td>11.838693</td>\n      <td>1.177159</td>\n      <td>0.445829</td>\n      <td>6.952685e-02</td>\n      <td>1.391510e-01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>109595.522981</td>\n      <td>2196.020360</td>\n      <td>0.410369</td>\n      <td>1.071443</td>\n      <td>4.656998e-02</td>\n      <td>7.234829e-01</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>100000.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>4.000000e-07</td>\n      <td>2.000000e-07</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>335000.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.224756</td>\n      <td>3.113350e-02</td>\n      <td>4.650480e-02</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>425000.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.364523</td>\n      <td>6.375360e-02</td>\n      <td>1.033192e-01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>500000.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>0.558390</td>\n      <td>1.010514e-01</td>\n      <td>1.976652e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>600000.000000</td>\n      <td>490000.000000</td>\n      <td>12.000000</td>\n      <td>192.431869</td>\n      <td>2.205226e-01</td>\n      <td>5.162385e+01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'location.latitude'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3800\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3799\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3800\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'location.latitude'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [10], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m old_length \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(df)\n\u001B[0;32m----> 2\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocation.latitude\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_numeric(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocation.latitude\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcoerce\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mdropna()\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mfloat\u001B[39m)\n\u001B[1;32m      3\u001B[0m df \u001B[38;5;241m=\u001B[39m df[(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocation.longitude\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m)]\n\u001B[1;32m      4\u001B[0m df \u001B[38;5;241m=\u001B[39m df[(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlongitude_deviation\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m)]\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/pandas/core/frame.py:3805\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3804\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3805\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3807\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3800\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3804\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3805\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'location.latitude'"
     ]
    }
   ],
   "source": [
    "old_length = len(df)\n",
    "df['location.latitude'] = pd.to_numeric(df['location.latitude'], 'coerce').dropna().astype(float)\n",
    "df = df[(df['location.longitude'] <= 10)]\n",
    "df = df[(df['longitude_deviation'] <= 1)]\n",
    "df = df[(df['longitude_deviation2'] <= 1)]\n",
    "df = df[(df['bedrooms'] <= 10)]\n",
    "df = df[df['bathrooms'] <= 5]\n",
    "df = df[(df['nearestStation'] <= 20)]\n",
    "\n",
    "print(f\"dataframe contract due to cleaning: {old_length} ==> {len(df)}\")\n",
    "old_length = len(df)\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "print(f\"{old_length} ==> {len(df)}\")\n",
    "old_length = len(df)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_train_index, X_test_index, y_train_index, y_test_index = create_train_test_data(df,\n",
    "                                                                                                                    return_index=True,\n",
    "                                                                                                                    drop_nulls=True)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_train_index.shape, X_test_index.shape,\n",
    "      y_train_index.shape, y_test_index.shape)\n",
    "#print(type(X_train))\n",
    "#X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputer = SimpleImputer(strategy='mean')\n",
    "#imputer.fit(X_train[6])\n",
    "#X_train[6] = imputer.transform(X_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "model = Ridge()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Best Score:  0.30582573121661794\n",
    "# Best Score:  {'alpha': 10, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'selection': 'cyclic', 'tol': 0.001, 'warm_start': True}\n",
    "# Best Score:  Lasso(alpha=10, tol=0.001, warm_start=True)\n",
    "# Best Score:  138\n",
    "\n",
    "# find optimal alpha with grid search\n",
    "alpha = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "#alpha = [1, 10, 100]\n",
    "fit_intercept = [True, False]\n",
    "max_iter = [100, 1000, 10000]\n",
    "positive = [True, False]\n",
    "solver = ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']\n",
    "tol = [0.00001, 0.0001, 0.001, 0.01]\n",
    "warm_start = [True, False]\n",
    "# ['alpha', 'copy_X', 'fit_intercept', 'max_iter', 'normalize', 'positive', 'precompute', 'random_state', 'selection', 'tol', 'warm_start'].\n",
    "\n",
    "options__n_neighbours = [3, 5, 7, 9, 15, 31]\n",
    "options__leafsize = [2, 3, 4, 57, 9, 13, 21]\n",
    "\n",
    "param_grid = dict(model__alpha=alpha, model__fit_intercept=fit_intercept, model__max_iter=max_iter,\n",
    "                  model__positive=positive,\n",
    "                  model__tol=tol, model__solver=solver)\n",
    "#param_grid = dict(estimator__n_neighbors=options__n_neighbours, estimator__leaf_size= options__leafsize)\n",
    "\n",
    "#param_grid = {'model__n_neighbors': options__n_neighbours,'model__leaf_size': options__leafsize},\n",
    "#param_grid = {'n_neighbors': options__n_neighbours,                   'leaf_size': options__leafsize},\n",
    "cv = 2\n",
    "n_jobs = 1\n",
    "verbose = 1\n",
    "refit = True\n",
    "\n",
    "#grid = RandomizedSearchCV(estimator=model, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "\n",
    "gs = RandomizedSearchCV(pipe, param_grid, cv=cv, n_jobs=n_jobs,\n",
    "                        verbose=verbose, scoring=CROSS_VALIDATION_SCORING, refit=refit,\n",
    "                        return_train_score=True),\n",
    "gs\n",
    "\n",
    "grid_result = gs[0].fit(X_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe = grid_result.best_estimator_\n",
    "timings = []\n",
    "\n",
    "t0 = time()\n",
    "pipe.fit(X_train, y_train)\n",
    "timings.append(time() - t0)\n",
    "\n",
    "print(timings)\n",
    "average_time = sum(timings) / len(timings)\n",
    "print(average_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print(f'BEST PARAMS: {results.best_params_}')\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print(f'{round(mean, 3)} (+/-{round(std * 2, 3)}) for {params}')\n",
    "\n",
    "\n",
    "print_results(grid_result)\n",
    "print('Best Index: ', grid_result.best_index_)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)\n",
    "#print('Best Model: ', grid_result.)\n",
    "#print('Best Params: ', grid_result.best_params_)[out]\n",
    "### Best Score:  0.4883436188936269\n",
    "### Best Params:  {'alpha': 0.01}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "y_pred = y_pred.reshape((-1, 1))\n",
    "\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = math.sqrt(MSE)\n",
    "print('-' * 10 + ALGORITHM + '-' * 10)\n",
    "print('R square Accuracy', R2)\n",
    "print('Mean Absolute Error Accuracy', MAE)\n",
    "print('Mean Squared Error Accuracy', MSE)\n",
    "print('Root Mean Squared Error', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    print(y_test_index.reshape((-1, 1)).shape);\n",
    "    print(y_pred.reshape((-1, 1)).shape);\n",
    "    print(y_test.shape);\n",
    "    print(y_test_index.shape);\n",
    "    print(y_pred.shape);\n",
    "    print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = np.hstack((y_test_index, y_test, y_pred))\n",
    "compare_df = DataFrame(compare, columns=['reference', 'actual', 'predicted'])\n",
    "compare_df['difference'] = abs(compare_df['actual'] - compare_df['predicted'])\n",
    "compare_df['diff 1 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['actual'] * 100)\n",
    "compare_df['diff 2 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['predicted']) * 100\n",
    "compare_df['reference'] = compare_df['reference'].astype(str)\n",
    "compare_df.set_index('reference', inplace=True)\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df.merge(df[columns], how='inner', left_index=True, right_index=True).sort_values(['diff 1 %'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes:\n",
    "* 96587218 has been removed from sale\n",
    "* 117356900 is a hotel room\n",
    "* 125520530"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pipe.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, pipe.predict(X_test), edgecolors=(0, 0, 1))\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_xlabel('Actual')\n",
    "#ax.title.set_text(f'CV Chosen best option ({calculated_best_pipe[1]})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "results = {\n",
    "    'Score': score,\n",
    "    'R square Accuracy': R2,\n",
    "    'Mean Absolute Error Accuracy': MAE,\n",
    "    'Mean Squared Error Accuracy': MSE,\n",
    "    'Root Mean Squared Error': RMSE,\n",
    "    'Training Time': average_time,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'date': str(datetime.now()),\n",
    "    'params': grid_result.best_params_\n",
    "}\n",
    "import json\n",
    "\n",
    "\n",
    "def get_results():\n",
    "    results_filename = '../../results/results.json'\n",
    "\n",
    "    with open(results_filename) as f:\n",
    "        raw_audit = f.read()\n",
    "    results_json = json.loads(raw_audit)\n",
    "    return results_json\n",
    "\n",
    "\n",
    "def update_results(saved_results_json, new_results):\n",
    "    key = f'{ALGORITHM} - {ALGORITHM_DETAIL} (v{VERSION})'.lower()\n",
    "    try:\n",
    "        first_run_date = str(datetime.now())\n",
    "        first_run_date = saved_results_json[key]['date']\n",
    "        first_run_date = saved_results_json[key]['first run']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        max_score = -1000\n",
    "        max_params = 'NOT APPLICABLE'\n",
    "        max_score = saved_results_json[key]['Score']\n",
    "        max_params = saved_results_json[key]['params']\n",
    "        max_score = saved_results_json[key]['max score']\n",
    "        max_params = saved_results_json[key]['max params']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    results['first run'] = first_run_date\n",
    "    if key not in saved_results_json:\n",
    "        new_results['max params'] = new_results['params']\n",
    "        new_results['max score'] = new_results['Score']\n",
    "        new_results['suboptimal'] = 'pending'\n",
    "    elif max_score > saved_results_json[key]['Score']:\n",
    "        new_results['suboptimal'] = 'suboptimal'\n",
    "    elif max_score == saved_results_json[key]['Score']:\n",
    "        if saved_results_json[key]['params'] != new_results['params']:\n",
    "            new_results['max params'] = 'MULTIPLE PARAM OPTIONS'\n",
    "        else:\n",
    "            new_results['max params'] = saved_results_json[key]['params']\n",
    "            new_results['max score'] = saved_results_json[key]['Score']\n",
    "            new_results['suboptimal'] = 'pending'\n",
    "    else:\n",
    "        new_results['max params'] = saved_results_json[key]['params']\n",
    "        new_results['max score'] = saved_results_json[key]['Score']\n",
    "        new_results['suboptimal'] = 'pending'\n",
    "\n",
    "    saved_results_json[key] = new_results\n",
    "\n",
    "    results_filename = '../../results/results.json'\n",
    "    with open(results_filename, 'w') as file:\n",
    "        file.write(json.dumps(saved_results_json, indent=4))\n",
    "\n",
    "\n",
    "if not IN_COLAB:\n",
    "    results_json = get_results()\n",
    "    update_results(results_json, results)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "deep_dive_csv = pd.read_csv(df_pathname_raw, index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "deep_dive_csv.loc[125520530, ['Price', 'keyFeatures', 'sharedOwnership']]\n",
    "deep_dive_csv.loc[85795281, ['Price', 'keyFeatures', 'sharedOwnership']]\n",
    "\n",
    "deep_dive_csv.loc[85795281, 'text.description']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "deep_dive_csv.loc[85795281]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "property_dataset = deep_dive_csv.loc[[125520530, 96587218], :]\n",
    "property_dataset\n",
    "\n",
    "(\n",
    "        (property_dataset['sharedOwnership.sharedOwnership'] == True) |\n",
    "        (property_dataset['analyticsProperty.priceQualifier'] == 'Shared ownership') |\n",
    "        (property_dataset['keyFeatures'].str.contains('shared ownership'))\n",
    ")\n",
    "\n",
    "(property_dataset['keyFeatures'].str.contains('%'))\n",
    "\n",
    "#(property_dataset['sharedOwnership'])\n",
    "#'share' isin (property_dataset['keyFeatures'].str.lower())\n",
    "\n",
    "#df[df.beer_style.str.contains('IPA')]\n",
    "property_dataset[property_dataset.keyFeatures.str.contains('IPA')]\n",
    "\n",
    "#(property_dataset['keyFeatures'].str.contains('%')))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
