{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGORITHM = 'Random Forest'\n",
    "ALGORITHM_DETAIL = 'random search'\n",
    "VERSION = '06'\n",
    "\n",
    "RANDOM_STATE = 101\n",
    "TRAINING_SIZE = 0.9\n",
    "\n",
    "CROSS_VALIDATION_SCORING = 'r2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "pipe = Pipeline([\n",
    "    #('mms', MinMaxScaler()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor())\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "from termcolor import colored\n",
    "\n",
    "confirm_colab = False\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = confirm_colab\n",
    "\n",
    "if not IN_COLAB:\n",
    "    from functions_20221106 import set_csv_directory, get_combined_dataset, get_columns\n",
    "    from functions_20221106 import add_supplements, tidy_dataset, preprocess, feature_engineer\n",
    "\n",
    "    set_csv_directory('final_split')\n",
    "\n",
    "debug_mode = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mfeatures\u001B[0m ->  ['bedrooms', 'bathrooms', 'nearestStation', 'location.latitude', 'location.longitude', 'latitude_deviation', 'longitude_deviation', 'tenure.tenureType']\n",
      "\u001B[1m\u001B[32mlabel\u001B[0m ->  Price\n"
     ]
    }
   ],
   "source": [
    "#cutdown_rows = 1000\n",
    "cutdown_rows = 0\n",
    "\n",
    "LABEL = 'Price'\n",
    "\n",
    "columns, booleans, floats, categories, custom, wildcard = get_columns(version=VERSION)\n",
    "\n",
    "print(colored(f\"features\", \"blue\"), \"-> \", columns)\n",
    "columns.insert(0, LABEL)\n",
    "print(colored(f\"label\", \"green\", None, ['bold']), \"-> \", LABEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_source_dataframe(rows=cutdown_rows, folder_prefix='../../../'):\n",
    "    retrieval_type = None\n",
    "\n",
    "    filename = f'df_listings_v{VERSION}.csv'\n",
    "    remote_pathname = f'https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/{filename}'\n",
    "    df_pathname_raw = folder_prefix + f'data/source/{filename}'\n",
    "    df_pathname_tidy = folder_prefix + f'data/final/{filename}'\n",
    "\n",
    "    if IN_COLAB:\n",
    "        inDF = pd.read_csv(remote_pathname, on_bad_lines='error', index_col=0)\n",
    "        retrieval_type = 'tidy'\n",
    "        print('loaded data from', folder_prefix + remote_pathname)\n",
    "    else:\n",
    "        inDF = pd.read_csv(df_pathname_tidy, on_bad_lines='error', index_col=0)\n",
    "        retrieval_type = 'tidy'\n",
    "        print('loaded data from', df_pathname_tidy)\n",
    "\n",
    "    if rows and rows > 0:\n",
    "        inDF = inDF[:rows]\n",
    "    return inDF, retrieval_type\n",
    "\n",
    "\n",
    "def create_train_test_data(df_orig, return_index=False, drop_nulls=True):\n",
    "    df = df_orig.copy()\n",
    "\n",
    "    if drop_nulls:\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "    if return_index:\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "    for column in categories:\n",
    "        df = pd.concat([df, pd.get_dummies(df[column], prefix=column)], axis=1)\n",
    "        df.drop([column], axis=1, inplace=True)  # now drop the original column (you don't need it anymore),\n",
    "\n",
    "    ins = df.pop('index')\n",
    "    df.insert(1, 'index2', ins)\n",
    "    df.insert(0, 'index', ins)\n",
    "\n",
    "\n",
    "    df_features = df[df.columns[2:]]\n",
    "    df_labels = df.iloc[:, 0:2]\n",
    "\n",
    "    features = df[df.columns[2:]].values\n",
    "    labels = df.iloc[:, 0:2].values\n",
    "\n",
    "    if not return_index:\n",
    "        return train_test_split(features, labels, train_size=0.9, random_state=RANDOM_STATE)\n",
    "    else:\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(features, labels, train_size=0.9,\n",
    "                                                                random_state=RANDOM_STATE)\n",
    "        X_train_index = X_train1[:, 0].reshape(-1, 1)\n",
    "        y_train_index = y_train1[:, 0].reshape(-1, 1)\n",
    "        X_test_index = X_test1[:, 0].reshape(-1, 1)\n",
    "        y_test_index = y_test1[:, 0].reshape(-1, 1)\n",
    "        X_train1 = X_train1[:, 1:]\n",
    "        y_train1 = y_train1[:, 1].reshape(-1, 1)\n",
    "        X_test1 = X_test1[:, 1:]\n",
    "        y_test1 = y_test1[:, 1].reshape(-1, 1)\n",
    "\n",
    "        return X_train1, X_test1, y_train1, y_test1, X_train_index, X_test_index, y_train_index, y_test_index, df_features, df_labels\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data from ../../../data/final/df_listings_v06.csv\n",
      "(46871, 9)\n"
     ]
    }
   ],
   "source": [
    "df, retrieval_type = get_source_dataframe(folder_prefix='../../../')\n",
    "df_orig = df.copy()\n",
    "\n",
    "if retrieval_type != 'tidy':\n",
    "    df = tidy_dataset(df, version=int(VERSION))\n",
    "    df = feature_engineer(df, version=int(VERSION))\n",
    "\n",
    "    df = df[columns]\n",
    "\n",
    "print(df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "              Price  bedrooms  bathrooms  nearestStation  location.latitude  \\\n14520525   550000.0       3.0        1.0        0.274316          51.529950   \n27953107   400000.0       2.0        2.0        0.305845          51.549390   \n33593487   579950.0       2.0        1.0        0.438045          51.447180   \n35271294   370000.0       2.0        1.0        0.399307          51.449568   \n35429088   599950.0       2.0        1.0        0.238187          51.577030   \n...             ...       ...        ...             ...                ...   \n126179018  575000.0       2.0        1.0        0.682879          51.370651   \n126179672  600000.0       3.0        2.0        0.545665          51.357170   \n126180107  419999.0       2.0        1.0        0.191407          51.531415   \n126180704  475000.0       2.0        1.0        0.308609          51.543141   \n126181118  525000.0       2.0        1.0        0.238489          51.424589   \n\n           location.longitude  latitude_deviation  longitude_deviation  \\\n14520525            -0.207020            0.030230             0.102600   \n27953107            -0.482600            0.049670             0.378180   \n33593487            -0.338770            0.052540             0.234350   \n35271294            -0.140154            0.050152             0.035734   \n35429088            -0.141230            0.077310             0.036810   \n...                       ...                 ...                  ...   \n126179018           -0.238346            0.129069             0.133926   \n126179672           -0.074740            0.142550             0.029680   \n126180107           -0.052964            0.031695             0.051456   \n126180704            0.011498            0.043421             0.115918   \n126181118           -0.206790            0.075131             0.102370   \n\n           tenure.tenureType  \n14520525           LEASEHOLD  \n27953107           LEASEHOLD  \n33593487            FREEHOLD  \n35271294           LEASEHOLD  \n35429088                 NaN  \n...                      ...  \n126179018           FREEHOLD  \n126179672          LEASEHOLD  \n126180107          LEASEHOLD  \n126180704          LEASEHOLD  \n126181118  SHARE_OF_FREEHOLD  \n\n[46871 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n      <th>location.latitude</th>\n      <th>location.longitude</th>\n      <th>latitude_deviation</th>\n      <th>longitude_deviation</th>\n      <th>tenure.tenureType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14520525</th>\n      <td>550000.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.274316</td>\n      <td>51.529950</td>\n      <td>-0.207020</td>\n      <td>0.030230</td>\n      <td>0.102600</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>27953107</th>\n      <td>400000.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.305845</td>\n      <td>51.549390</td>\n      <td>-0.482600</td>\n      <td>0.049670</td>\n      <td>0.378180</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>33593487</th>\n      <td>579950.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.438045</td>\n      <td>51.447180</td>\n      <td>-0.338770</td>\n      <td>0.052540</td>\n      <td>0.234350</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>35271294</th>\n      <td>370000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.399307</td>\n      <td>51.449568</td>\n      <td>-0.140154</td>\n      <td>0.050152</td>\n      <td>0.035734</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>35429088</th>\n      <td>599950.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.238187</td>\n      <td>51.577030</td>\n      <td>-0.141230</td>\n      <td>0.077310</td>\n      <td>0.036810</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>126179018</th>\n      <td>575000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.682879</td>\n      <td>51.370651</td>\n      <td>-0.238346</td>\n      <td>0.129069</td>\n      <td>0.133926</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>126179672</th>\n      <td>600000.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.545665</td>\n      <td>51.357170</td>\n      <td>-0.074740</td>\n      <td>0.142550</td>\n      <td>0.029680</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>126180107</th>\n      <td>419999.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.191407</td>\n      <td>51.531415</td>\n      <td>-0.052964</td>\n      <td>0.031695</td>\n      <td>0.051456</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>126180704</th>\n      <td>475000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.308609</td>\n      <td>51.543141</td>\n      <td>0.011498</td>\n      <td>0.043421</td>\n      <td>0.115918</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>126181118</th>\n      <td>525000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.238489</td>\n      <td>51.424589</td>\n      <td>-0.206790</td>\n      <td>0.075131</td>\n      <td>0.102370</td>\n      <td>SHARE_OF_FREEHOLD</td>\n    </tr>\n  </tbody>\n</table>\n<p>46871 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Price                     0\nbedrooms                  0\nbathrooms                 0\nnearestStation            0\nlocation.latitude         0\nlocation.longitude        0\nlatitude_deviation        0\nlongitude_deviation       0\ntenure.tenureType      2744\ndtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46871 entries, 14520525 to 126181118\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Price                46871 non-null  float64\n",
      " 1   bedrooms             46871 non-null  float64\n",
      " 2   bathrooms            46871 non-null  float64\n",
      " 3   nearestStation       46871 non-null  float64\n",
      " 4   location.latitude    46871 non-null  float64\n",
      " 5   location.longitude   46871 non-null  float64\n",
      " 6   latitude_deviation   46871 non-null  float64\n",
      " 7   longitude_deviation  46871 non-null  float64\n",
      " 8   tenure.tenureType    44127 non-null  object \n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "                       count           mean            std            min  \\\nPrice                46871.0  425069.390775  107227.324906  100000.000000   \nbedrooms             46871.0       1.992469       0.828837       1.000000   \nbathrooms            46871.0       1.182074       0.409879       1.000000   \nnearestStation       46871.0       0.438847       0.325942       0.000000   \nlocation.latitude    46871.0      51.497049       0.077085      51.298317   \nlocation.longitude   46871.0      -0.113269       0.156489      -0.498315   \nlatitude_deviation   46871.0       0.064317       0.042573       0.000000   \nlongitude_deviation  46871.0       0.124202       0.095607       0.000000   \n\n                               25%            50%            75%  \\\nPrice                349950.000000  425000.000000  515000.000000   \nbedrooms                  1.000000       2.000000       3.000000   \nbathrooms                 1.000000       1.000000       1.000000   \nnearestStation            0.227169       0.367971       0.559620   \nlocation.latitude        51.438861      51.499977      51.556183   \nlocation.longitude       -0.210796      -0.102230      -0.010343   \nlatitude_deviation        0.028876       0.058595       0.094362   \nlongitude_deviation       0.043560       0.098984       0.192684   \n\n                               max  \nPrice                600000.000000  \nbedrooms                  7.000000  \nbathrooms                 5.000000  \nnearestStation            7.197700  \nlocation.latitude        51.683185  \nlocation.longitude        0.279726  \nlatitude_deviation        0.201403  \nlongitude_deviation       0.393895  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Price</th>\n      <td>46871.0</td>\n      <td>425069.390775</td>\n      <td>107227.324906</td>\n      <td>100000.000000</td>\n      <td>349950.000000</td>\n      <td>425000.000000</td>\n      <td>515000.000000</td>\n      <td>600000.000000</td>\n    </tr>\n    <tr>\n      <th>bedrooms</th>\n      <td>46871.0</td>\n      <td>1.992469</td>\n      <td>0.828837</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>bathrooms</th>\n      <td>46871.0</td>\n      <td>1.182074</td>\n      <td>0.409879</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>nearestStation</th>\n      <td>46871.0</td>\n      <td>0.438847</td>\n      <td>0.325942</td>\n      <td>0.000000</td>\n      <td>0.227169</td>\n      <td>0.367971</td>\n      <td>0.559620</td>\n      <td>7.197700</td>\n    </tr>\n    <tr>\n      <th>location.latitude</th>\n      <td>46871.0</td>\n      <td>51.497049</td>\n      <td>0.077085</td>\n      <td>51.298317</td>\n      <td>51.438861</td>\n      <td>51.499977</td>\n      <td>51.556183</td>\n      <td>51.683185</td>\n    </tr>\n    <tr>\n      <th>location.longitude</th>\n      <td>46871.0</td>\n      <td>-0.113269</td>\n      <td>0.156489</td>\n      <td>-0.498315</td>\n      <td>-0.210796</td>\n      <td>-0.102230</td>\n      <td>-0.010343</td>\n      <td>0.279726</td>\n    </tr>\n    <tr>\n      <th>latitude_deviation</th>\n      <td>46871.0</td>\n      <td>0.064317</td>\n      <td>0.042573</td>\n      <td>0.000000</td>\n      <td>0.028876</td>\n      <td>0.058595</td>\n      <td>0.094362</td>\n      <td>0.201403</td>\n    </tr>\n    <tr>\n      <th>longitude_deviation</th>\n      <td>46871.0</td>\n      <td>0.124202</td>\n      <td>0.095607</td>\n      <td>0.000000</td>\n      <td>0.043560</td>\n      <td>0.098984</td>\n      <td>0.192684</td>\n      <td>0.393895</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe contract due to cleaning: 46871 ==> 46871\n"
     ]
    },
    {
     "data": {
      "text/plain": "                       count           mean            std            min  \\\nPrice                46871.0  425069.390775  107227.324906  100000.000000   \nbedrooms             46871.0       1.992469       0.828837       1.000000   \nbathrooms            46871.0       1.182074       0.409879       1.000000   \nnearestStation       46871.0       0.438847       0.325942       0.000000   \nlocation.latitude    46871.0      51.497049       0.077085      51.298317   \nlocation.longitude   46871.0      -0.113269       0.156489      -0.498315   \nlatitude_deviation   46871.0       0.064317       0.042573       0.000000   \nlongitude_deviation  46871.0       0.124202       0.095607       0.000000   \n\n                               25%            50%            75%  \\\nPrice                349950.000000  425000.000000  515000.000000   \nbedrooms                  1.000000       2.000000       3.000000   \nbathrooms                 1.000000       1.000000       1.000000   \nnearestStation            0.227169       0.367971       0.559620   \nlocation.latitude        51.438861      51.499977      51.556183   \nlocation.longitude       -0.210796      -0.102230      -0.010343   \nlatitude_deviation        0.028876       0.058595       0.094362   \nlongitude_deviation       0.043560       0.098984       0.192684   \n\n                               max  \nPrice                600000.000000  \nbedrooms                  7.000000  \nbathrooms                 5.000000  \nnearestStation            7.197700  \nlocation.latitude        51.683185  \nlocation.longitude        0.279726  \nlatitude_deviation        0.201403  \nlongitude_deviation       0.393895  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Price</th>\n      <td>46871.0</td>\n      <td>425069.390775</td>\n      <td>107227.324906</td>\n      <td>100000.000000</td>\n      <td>349950.000000</td>\n      <td>425000.000000</td>\n      <td>515000.000000</td>\n      <td>600000.000000</td>\n    </tr>\n    <tr>\n      <th>bedrooms</th>\n      <td>46871.0</td>\n      <td>1.992469</td>\n      <td>0.828837</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>bathrooms</th>\n      <td>46871.0</td>\n      <td>1.182074</td>\n      <td>0.409879</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>nearestStation</th>\n      <td>46871.0</td>\n      <td>0.438847</td>\n      <td>0.325942</td>\n      <td>0.000000</td>\n      <td>0.227169</td>\n      <td>0.367971</td>\n      <td>0.559620</td>\n      <td>7.197700</td>\n    </tr>\n    <tr>\n      <th>location.latitude</th>\n      <td>46871.0</td>\n      <td>51.497049</td>\n      <td>0.077085</td>\n      <td>51.298317</td>\n      <td>51.438861</td>\n      <td>51.499977</td>\n      <td>51.556183</td>\n      <td>51.683185</td>\n    </tr>\n    <tr>\n      <th>location.longitude</th>\n      <td>46871.0</td>\n      <td>-0.113269</td>\n      <td>0.156489</td>\n      <td>-0.498315</td>\n      <td>-0.210796</td>\n      <td>-0.102230</td>\n      <td>-0.010343</td>\n      <td>0.279726</td>\n    </tr>\n    <tr>\n      <th>latitude_deviation</th>\n      <td>46871.0</td>\n      <td>0.064317</td>\n      <td>0.042573</td>\n      <td>0.000000</td>\n      <td>0.028876</td>\n      <td>0.058595</td>\n      <td>0.094362</td>\n      <td>0.201403</td>\n    </tr>\n    <tr>\n      <th>longitude_deviation</th>\n      <td>46871.0</td>\n      <td>0.124202</td>\n      <td>0.095607</td>\n      <td>0.000000</td>\n      <td>0.043560</td>\n      <td>0.098984</td>\n      <td>0.192684</td>\n      <td>0.393895</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_length = len(df)\n",
    "#df['location.latitude'] = pd.to_numeric(df['location.latitude'], 'coerce').dropna().astype(float)\n",
    "#df = df[(df['location.longitude'] <= 10)]\n",
    "#df = df[(df['longitude_deviation'] <= 1)]\n",
    "\n",
    "df = preprocess(df, version=VERSION)\n",
    "\n",
    "print(f\"dataframe contract due to cleaning: {old_length} ==> {len(df)}\")\n",
    "old_length = len(df)\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Price                     0\nbedrooms                  0\nbathrooms                 0\nnearestStation            0\nlocation.latitude         0\nlocation.longitude        0\nlatitude_deviation        0\nlongitude_deviation       0\ntenure.tenureType      2744\ndtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46871 ==> 44127\n"
     ]
    },
    {
     "data": {
      "text/plain": "               Price      bedrooms    bathrooms  nearestStation  \\\ncount   44127.000000  44127.000000  44127.00000    44127.000000   \nmean   425224.642373      1.990981      1.18134        0.438522   \nstd    107203.332660      0.827621      0.40893        0.324152   \nmin    100000.000000      1.000000      1.00000        0.000000   \n25%    349950.000000      1.000000      1.00000        0.227551   \n50%    425000.000000      2.000000      1.00000        0.368351   \n75%    515000.000000      3.000000      1.00000        0.559486   \nmax    600000.000000      7.000000      5.00000        7.197700   \n\n       location.latitude  location.longitude  latitude_deviation  \\\ncount       44127.000000        44127.000000        44127.000000   \nmean           51.496711           -0.113106            0.064544   \nstd             0.077267            0.155863            0.042583   \nmin            51.298317           -0.498315            0.000000   \n25%            51.438303           -0.210633            0.029023   \n50%            51.498780           -0.101910            0.058904   \n75%            51.556343           -0.010854            0.094620   \nmax            51.683185            0.279726            0.201403   \n\n       longitude_deviation  \ncount         44127.000000  \nmean              0.123699  \nstd               0.095220  \nmin               0.000000  \n25%               0.043551  \n50%               0.098750  \n75%               0.191727  \nmax               0.393895  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n      <th>location.latitude</th>\n      <th>location.longitude</th>\n      <th>latitude_deviation</th>\n      <th>longitude_deviation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>44127.000000</td>\n      <td>44127.000000</td>\n      <td>44127.00000</td>\n      <td>44127.000000</td>\n      <td>44127.000000</td>\n      <td>44127.000000</td>\n      <td>44127.000000</td>\n      <td>44127.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>425224.642373</td>\n      <td>1.990981</td>\n      <td>1.18134</td>\n      <td>0.438522</td>\n      <td>51.496711</td>\n      <td>-0.113106</td>\n      <td>0.064544</td>\n      <td>0.123699</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>107203.332660</td>\n      <td>0.827621</td>\n      <td>0.40893</td>\n      <td>0.324152</td>\n      <td>0.077267</td>\n      <td>0.155863</td>\n      <td>0.042583</td>\n      <td>0.095220</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>100000.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>0.000000</td>\n      <td>51.298317</td>\n      <td>-0.498315</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>349950.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>0.227551</td>\n      <td>51.438303</td>\n      <td>-0.210633</td>\n      <td>0.029023</td>\n      <td>0.043551</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>425000.000000</td>\n      <td>2.000000</td>\n      <td>1.00000</td>\n      <td>0.368351</td>\n      <td>51.498780</td>\n      <td>-0.101910</td>\n      <td>0.058904</td>\n      <td>0.098750</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>515000.000000</td>\n      <td>3.000000</td>\n      <td>1.00000</td>\n      <td>0.559486</td>\n      <td>51.556343</td>\n      <td>-0.010854</td>\n      <td>0.094620</td>\n      <td>0.191727</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>600000.000000</td>\n      <td>7.000000</td>\n      <td>5.00000</td>\n      <td>7.197700</td>\n      <td>51.683185</td>\n      <td>0.279726</td>\n      <td>0.201403</td>\n      <td>0.393895</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(f\"{old_length} ==> {len(df)}\")\n",
    "old_length = len(df)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39714, 11) (4413, 11) (39714, 1) (4413, 1) (39714, 1) (4413, 1) (39714, 1) (4413, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_train_index, X_test_index, y_train_index, y_test_index, df_features, df_labels = create_train_test_data(df,\n",
    "                                                                                                                    return_index=True,\n",
    "                                                                                                                    drop_nulls=True)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_train_index.shape, X_test_index.shape,\n",
    "      y_train_index.shape, y_test_index.shape)\n",
    "#print(type(X_train))\n",
    "#X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[3.        , 3.        , 0.31661326, ..., 1.        , 0.        ,\n        0.        ],\n       [1.        , 1.        , 0.53093375, ..., 0.        , 1.        ,\n        0.        ],\n       [1.        , 1.        , 0.28550937, ..., 0.        , 0.        ,\n        1.        ],\n       ...,\n       [3.        , 1.        , 0.72181034, ..., 1.        , 0.        ,\n        0.        ],\n       [1.        , 1.        , 0.43589737, ..., 0.        , 1.        ,\n        0.        ],\n       [5.        , 3.        , 0.09716825, ..., 1.        , 0.        ,\n        0.        ]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imputer = SimpleImputer(strategy='mean')\n",
    "#imputer.fit(X_train[6])\n",
    "#X_train[6] = imputer.transform(X_train[6])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'bootstrap': True,\n 'ccp_alpha': 0.0,\n 'criterion': 'squared_error',\n 'max_depth': None,\n 'max_features': 1.0,\n 'max_leaf_nodes': None,\n 'max_samples': None,\n 'min_impurity_decrease': 0.0,\n 'min_samples_leaf': 1,\n 'min_samples_split': 2,\n 'min_weight_fraction_leaf': 0.0,\n 'n_estimators': 100,\n 'n_jobs': None,\n 'oob_score': False,\n 'random_state': None,\n 'verbose': 0,\n 'warm_start': False}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "model = pipe[1]\n",
    "model.get_params()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "{'bootstrap': True,\n",
    " 'ccp_alpha': 0.0,\n",
    " 'criterion': 'squared_error',\n",
    " 'max_depth': None,\n",
    " 'max_features': 1.0,\n",
    " 'max_leaf_nodes': None,\n",
    " 'max_samples': None,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 2,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'n_estimators': 100,\n",
    " 'n_jobs': None,\n",
    " 'oob_score': False,\n",
    " 'random_state': None,\n",
    " 'verbose': 0,\n",
    " 'warm_start': False}\n",
    "'''\n",
    "options_block = {'bootstrap': True,\n",
    " 'ccp_alpha': [0.0, 0.05, 0.1, 0.25, 1, 5],\n",
    " 'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    " 'max_depth': [None, 1, 2, 5, 10, 50],\n",
    " 'max_features': [None, 1.0, 'sqrt', 'log2', .5, .25, .1, 2],\n",
    " 'max_leaf_nodes': [None, 2, 5, 10, 50,100,200,500],\n",
    " 'max_samples': None,\n",
    " 'min_impurity_decrease': [0.0, 0.1, 0.25, 1, 5],\n",
    " 'min_samples_leaf': [1, 0.25, 0.5, 1.5, 2, 4, 8, 50],\n",
    " 'min_samples_split': [2, 4, 8, 50,100,200,500],\n",
    " 'min_weight_fraction_leaf': [0.0, 0.1, 0.25, 0.5],\n",
    " 'n_estimators': 100,\n",
    " 'n_jobs': None,\n",
    " 'oob_score': False,\n",
    " 'random_state': None,\n",
    " 'verbose': 0,\n",
    " 'warm_start': False}\n",
    "\n",
    "param_grid = {}\n",
    "for each in options_block:\n",
    "    if type(options_block[each]) == list:\n",
    "        param_grid['model__' + each] = options_block[each]\n",
    "    elif options_block[each] == None:\n",
    "        #print (f'skipping {each} because value is {options_block[each]}')\n",
    "        param_grid['model__' + each] = [options_block[each]]\n",
    "    else:\n",
    "        param_grid['model__' + each] = [options_block[each]]\n",
    "#param_grid\n",
    "\n",
    "cv = 3\n",
    "n_jobs = 1\n",
    "verbose = 1\n",
    "refit = True\n",
    "\n",
    "#grid = RandomizedSearchCV(estimator=model, param_grid=param_grid, scoring='r2', verbose=1, n_jobs=-1)\n",
    "\n",
    "# temp override\n",
    "# cv = 2\n",
    "# gs = RandomizedSearchCV(pipe, param_grid, cv=cv, n_jobs=n_jobs,\n",
    "#                         verbose=verbose, scoring=CROSS_VALIDATION_SCORING, refit=refit,\n",
    "#                         return_train_score=True, n_iter=30),\n",
    "\n",
    "cv = 3\n",
    "n_jobs = 3\n",
    "gs = RandomizedSearchCV(pipe, param_grid, cv=cv, n_jobs=n_jobs,\n",
    "                        verbose=verbose, scoring=CROSS_VALIDATION_SCORING, refit=refit,\n",
    "                        return_train_score=True, n_iter=10),\n",
    "gs\n",
    "\n",
    "grid_result = gs[0].fit(X_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe = grid_result.best_estimator_\n",
    "timings = []\n",
    "\n",
    "t0 = time()\n",
    "pipe.fit(X_train, y_train)\n",
    "timings.append(time() - t0)\n",
    "\n",
    "print(timings)\n",
    "average_time = sum(timings) / len(timings)\n",
    "print(average_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print(f'BEST PARAMS: {results.best_params_}')\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print(f'{round(mean, 3)} (+/-{round(std * 2, 3)}) for {params}')\n",
    "\n",
    "\n",
    "print_results(grid_result)\n",
    "print('Best Index: ', grid_result.best_index_)\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)\n",
    "#print('Best Model: ', grid_result.)\n",
    "#print('Best Params: ', grid_result.best_params_)[out]\n",
    "### Best Score:  0.4883436188936269\n",
    "### Best Params:  {'alpha': 0.01}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "y_pred = y_pred.reshape((-1, 1))\n",
    "\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = math.sqrt(MSE)\n",
    "print('-' * 10 + ALGORITHM + '-' * 10)\n",
    "print('R square Accuracy', R2)\n",
    "print('Mean Absolute Error Accuracy', MAE)\n",
    "print('Mean Squared Error Accuracy', MSE)\n",
    "print('Root Mean Squared Error', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    print(y_test_index.reshape((-1, 1)).shape);\n",
    "    print(y_pred.reshape((-1, 1)).shape);\n",
    "    print(y_test.shape);\n",
    "    print(y_test_index.shape);\n",
    "    print(y_pred.shape);\n",
    "    print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "compare = np.hstack((y_test_index, y_test, y_pred))\n",
    "compare_df = DataFrame(compare, columns=['reference', 'actual', 'predicted'])\n",
    "compare_df['difference'] = abs(compare_df['actual'] - compare_df['predicted'])\n",
    "compare_df['diff 1 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['actual'] * 100)\n",
    "compare_df['diff 2 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['predicted']) * 100\n",
    "compare_df['reference'] = compare_df['reference'].astype(str)\n",
    "compare_df.set_index('reference', inplace=True)\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "compare_df.merge(df[columns], how='inner', left_index=True, right_index=True).sort_values(['diff 1 %'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "score = pipe.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, pipe.predict(X_test), edgecolors=(0, 0, 1))\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_xlabel('Actual')\n",
    "#ax.title.set_text(f'CV Chosen best option ({calculated_best_pipe[1]})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if False:\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            #return pd.Series({**params, **d})\n",
    "            return pd.Series({**params, **d, **{'params_full': str(params)}})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]\n",
    "\n",
    "\n",
    "    import seaborn as sns\n",
    "\n",
    "    score_summary = score_summary(self=gs, sort_by='max_score')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "if False:\n",
    "    #sns.set(rc={\"figure.figsize\": (10, 10)})\n",
    "    sns.set_theme(font_scale=2, rc=None)\n",
    "    sns.set_theme(font_scale=1, rc=None)\n",
    "\n",
    "    #total_graphs = len(score_summary)\n",
    "    # max_horizontal = 4\n",
    "    # index2 = 0\n",
    "    # resultant_rows = math.ceil(total_graphs / max_horizontal)\n",
    "    # #subplots_adjust()\n",
    "    #\n",
    "    # #fig, axes = plt.subplots(nrows=resultant_rows, ncols=max_horizontal)\n",
    "    fig, axes = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "    best_estimator = score_summary.iloc[0]\n",
    "    worst_estimator = score_summary.iloc[-1]\n",
    "\n",
    "    name_best = best_estimator[\"estimator\"]\n",
    "    params_str = best_estimator[\"params_full\"]\n",
    "    params_best = ast.literal_eval(params_str)\n",
    "\n",
    "    name_worst = worst_estimator[\"estimator\"]\n",
    "    params_str = worst_estimator[\"params_full\"]\n",
    "    params_worst = ast.literal_eval(params_str)\n",
    "\n",
    "    KNeighborsRegressor().set_params()\n",
    "\n",
    "    best_pipe = make_pipe(name_best)\n",
    "    worst_pipe = make_pipe(name_worst)\n",
    "\n",
    "    coordinates = axes[0]\n",
    "    sns.lineplot(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], ax=axes[0], color='red')\n",
    "    sns.scatterplot(x=y_test, y=best_pipe.set_params(**params_best).fit(X_train, y_train).predict(X_test), ax=axes[0],\n",
    "                    s=100).set(\n",
    "        title=f'\"BEST\" model: {name_best} \\n{params_best}')\n",
    "\n",
    "    sns.lineplot(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], ax=axes[1], color='red')\n",
    "    sns.scatterplot(x=y_test, y=worst_pipe.set_params(**params_worst).fit(X_train, y_train).predict(X_test), ax=axes[1],\n",
    "                    s=100).set(\n",
    "        title=f'\"WORST\" model: {name_worst} \\n{params_worst}')\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=worst_pipe.set_params(**params_worst).fit(X_train, y_train).predict(X_test), ax=axes[2],\n",
    "                    s=100, color='orange')\n",
    "    sns.scatterplot(x=y_test, y=best_pipe.set_params(**params_best).fit(X_train, y_train).predict(X_test), ax=axes[2],\n",
    "                    s=100, alpha=0.6, color='black').set(\n",
    "        title='best (black) vs worst (orange)')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if False:\n",
    "    max_horizontal = 3\n",
    "\n",
    "    #sns.set()\n",
    "    #sns.set_theme(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=True, rc=None)\n",
    "    sns.set(rc={\"figure.figsize\": (20, 20)})\n",
    "    sns.set_theme(font_scale=2, rc=None)\n",
    "    sns.set_theme(font_scale=1, rc=None)\n",
    "\n",
    "    total_graphs = len(score_summary)\n",
    "    index2 = 0\n",
    "    resultant_rows = math.ceil(total_graphs / max_horizontal)\n",
    "    #subplots_adjust()\n",
    "\n",
    "    #fig, axes = plt.subplots(nrows=resultant_rows, ncols=max_horizontal)\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=max_horizontal, figsize=(15, 10))\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "    for (key, next_estimator), index in zip(score_summary.iterrows(), range(total_graphs)):\n",
    "        if index % (max_horizontal * 2) == 0 and index != 0:\n",
    "            index2 = 0\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "            #fig, axes = plt.subplots(nrows=resultant_rows, ncols=max_horizontal)\n",
    "            fig, axes = plt.subplots(nrows=2, ncols=max_horizontal, figsize=(15, 10))\n",
    "\n",
    "        name_next = next_estimator[\"estimator\"]\n",
    "        params_str = next_estimator[\"params_full\"]\n",
    "        params_next = ast.literal_eval(params_str)\n",
    "        #print(\"next\", params_next)\n",
    "\n",
    "        if 'noscale' in name_next:\n",
    "            pipe = Pipeline(steps=[\n",
    "                ('preprocessor', features_noscale_preprocessor),  # preprocess features\n",
    "                ('estimator', models_and_params[name_next][\"model\"]),\n",
    "            ])  # start the training\n",
    "        else:\n",
    "            pipe = Pipeline(steps=[\n",
    "                ('preprocessor', features_preprocessor),\n",
    "                ('estimator', models_and_params[name_next][\"model\"]),  # preprocess features\n",
    "            ])  # start the training\n",
    "\n",
    "        # 0 ==> 0,0\n",
    "        # 1 ==> 0,1\n",
    "        # 2 ==> 1,0\n",
    "        x_coor = index2 // max_horizontal\n",
    "        y_coor = index2 % max_horizontal\n",
    "\n",
    "        coordinates = axes[x_coor][y_coor]\n",
    "        #sns.lineplot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], hue='red', lw=3)\n",
    "        sns.lineplot(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], ax=coordinates, color='red')\n",
    "        sns.scatterplot(x=y_test, y=pipe.set_params(**params_next).fit(X_train, y_train).predict(X_test),\n",
    "                        ax=coordinates, s=100).set(\n",
    "            title=f'({index}) {\"BEST\" if index == 0 else \"next\"} model: {name_next} \\n{params_next}')\n",
    "        #if index == 11: break\n",
    "        index2 += 1\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "results = {\n",
    "    'Score': score,\n",
    "    'R square Accuracy': R2,\n",
    "    'Mean Absolute Error Accuracy': MAE,\n",
    "    'Mean Squared Error Accuracy': MSE,\n",
    "    'Root Mean Squared Error': RMSE,\n",
    "    'Training Time': average_time,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'date': str(datetime.now()),\n",
    "    'params': grid_result.best_params_\n",
    "}\n",
    "import json\n",
    "\n",
    "\n",
    "def get_results():\n",
    "    results_filename = '../../../results/results.json'\n",
    "\n",
    "    with open(results_filename) as f:\n",
    "        raw_audit = f.read()\n",
    "    results_json = json.loads(raw_audit)\n",
    "    return results_json\n",
    "\n",
    "\n",
    "def update_results(saved_results_json, new_results):\n",
    "    key = f'{ALGORITHM} - {ALGORITHM_DETAIL} (v{VERSION})'.lower()\n",
    "    try:\n",
    "        first_run_date = str(datetime.now())\n",
    "        first_run_date = saved_results_json[key]['date']\n",
    "        first_run_date = saved_results_json[key]['first run']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        max_score = -1000\n",
    "        max_params = 'NOT APPLICABLE'\n",
    "        max_score = saved_results_json[key]['Score']\n",
    "        max_params = saved_results_json[key]['params']\n",
    "        max_score = saved_results_json[key]['max score']\n",
    "        max_params = saved_results_json[key]['max params']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    results['first run'] = first_run_date\n",
    "    if key not in saved_results_json:\n",
    "        new_results['max params'] = new_results['params']\n",
    "        new_results['max score'] = new_results['Score']\n",
    "        new_results['suboptimal'] = 'pending'\n",
    "    elif max_score > saved_results_json[key]['Score']:\n",
    "        new_results['suboptimal'] = 'suboptimal'\n",
    "    elif max_score == saved_results_json[key]['Score']:\n",
    "        if saved_results_json[key]['params'] != new_results['params']:\n",
    "            new_results['max params'] = 'MULTIPLE PARAM OPTIONS'\n",
    "        else:\n",
    "            new_results['max params'] = saved_results_json[key]['params']\n",
    "            new_results['max score'] = saved_results_json[key]['Score']\n",
    "            new_results['suboptimal'] = 'pending'\n",
    "    else:\n",
    "        new_results['max params'] = saved_results_json[key]['params']\n",
    "        new_results['max score'] = saved_results_json[key]['Score']\n",
    "        new_results['suboptimal'] = 'pending'\n",
    "\n",
    "    saved_results_json[key] = new_results\n",
    "\n",
    "    results_filename = '../../../results/results.json'\n",
    "    with open(results_filename, 'w') as file:\n",
    "        file.write(json.dumps(saved_results_json, indent=4, sort_keys=True))\n",
    "\n",
    "\n",
    "if not IN_COLAB:\n",
    "    results_json = get_results()\n",
    "    update_results(results_json, results)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results\n",
    "import pickle\n",
    "\n",
    "# try:\n",
    "#     model = pickle.load(open(f'model_{ALGORITHM}.pkl', 'rb'))\n",
    "#     # raise ValueError\n",
    "# except:\n",
    "#     model = build_model(ALGORITHM, drop_nulls=~include_nulls)\n",
    "#     with open(f'models/model_{ALGORITHM}.pkl', 'wb') as f:\n",
    "#         pickle.dump(model, f)\n",
    "\n",
    "\n",
    "with open(f'../../../models/optimised_model_{ALGORITHM}_v{VERSION}.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_result.best_estimator_, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_result.best_estimator_[1].feature_names_in_\n",
    "#grid_result.best_estimator_[1].feature_importances_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = grid_result.best_estimator_[1]\n",
    "\n",
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis = 0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print('Feature Ranking:')\n",
    "\n",
    "#print(df_features.columns)\n",
    "#print(len(df_features.columns))\n",
    "for f in range(X_train.shape[1]):\n",
    "    print('%d. features %d (%f)'% (f+1, indices[f], importances[indices[f]]), df_features.columns[indices[f]+1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "importances = grid_result.best_estimator_[1].feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(range(len(importances)), importances[indices])\n",
    "ax.set_yticks(range(len(importances)))\n",
    "_ = ax.set_yticklabels(np.array(X_train.columns)[indices])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
