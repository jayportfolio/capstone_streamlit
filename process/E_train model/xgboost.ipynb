{
 "cells": [
  {
   "cell_type": "raw",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": ""
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['Price',\n 'location.latitude',\n 'location.longitude',\n 'bedrooms',\n 'bathrooms',\n 'nearestStation',\n 'nearestTram',\n 'nearestUnderground',\n 'nearestOverground',\n 'tenure.tenureType',\n 'analyticsProperty.soldSTC',\n 'analyticsProperty.preOwned',\n 'analyticsProperty.propertyType',\n 'borough',\n 'sharedOwnership.sharedOwnership',\n 'analyticsProperty.priceQualifier',\n 'keyFeatures']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cutdown_rows = 1000\n",
    "cutdown_rows = 0\n",
    "\n",
    "LABEL = 'Price'\n",
    "\n",
    "floats = ['location.latitude', 'location.longitude', 'bedrooms', 'bathrooms',\n",
    "          'nearestStation', 'nearestTram', 'nearestUnderground', 'nearestOverground',\n",
    "          ]\n",
    "\n",
    "categories = ['tenure.tenureType',\n",
    "              'analyticsProperty.soldSTC',\n",
    "              'analyticsProperty.preOwned',\n",
    "              #'sharedOwnership.sharedOwnership',\n",
    "              #\n",
    "              'analyticsProperty.propertyType',  # 'propertyType',\n",
    "              #'analyticsProperty.propertySubType',\n",
    "              'borough',\n",
    "              ]\n",
    "custom = [\n",
    "    'sharedOwnership.sharedOwnership',\n",
    "    'analyticsProperty.priceQualifier',\n",
    "    'keyFeatures'\n",
    "]\n",
    "#categories = []\n",
    "\n",
    "features = floats.copy()\n",
    "features.extend(categories)\n",
    "features.extend(custom)\n",
    "features.insert(0, LABEL)\n",
    "features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RANDOM_STATE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [3], line 59\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[38;5;66;03m# X_train_index = pd.to_numeric(X_train_index, 'coerce').astype(int)\u001B[39;00m\n\u001B[1;32m     52\u001B[0m         \u001B[38;5;66;03m# y_train_index = pd.to_numeric(y_train_index, 'coerce').astype(int)\u001B[39;00m\n\u001B[1;32m     53\u001B[0m         \u001B[38;5;66;03m# X_test_index = pd.to_numeric(X_test_index, 'coerce').astype(int)\u001B[39;00m\n\u001B[1;32m     54\u001B[0m         \u001B[38;5;66;03m# y_test_index = pd.to_numeric(y_test_index, 'coerce').astype(int)\u001B[39;00m\n\u001B[1;32m     56\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m X_train1, X_test1, y_train1, y_test1, X_train_index, X_test_index, y_train_index, y_test_index\n\u001B[0;32m---> 59\u001B[0m X_train, X_test, y_train, y_test, X_train_index, X_test_index, y_train_index, y_test_index \u001B[38;5;241m=\u001B[39m create_train_test_data(\n\u001B[1;32m     60\u001B[0m     get_source_dataframe(), return_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, drop_nulls\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     61\u001B[0m X_train\u001B[38;5;241m.\u001B[39mshape, X_test\u001B[38;5;241m.\u001B[39mshape, y_train\u001B[38;5;241m.\u001B[39mshape, y_test\u001B[38;5;241m.\u001B[39mshape, X_train_index\u001B[38;5;241m.\u001B[39mshape, X_test_index\u001B[38;5;241m.\u001B[39mshape, y_train_index\u001B[38;5;241m.\u001B[39mshape, y_test_index\u001B[38;5;241m.\u001B[39mshape,\n\u001B[1;32m     62\u001B[0m X_train[\u001B[38;5;241m0\u001B[39m]\n",
      "Cell \u001B[0;32mIn [3], line 39\u001B[0m, in \u001B[0;36mcreate_train_test_data\u001B[0;34m(df_orig, return_index, drop_nulls)\u001B[0m\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m train_test_split(features, labels, train_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.9\u001B[39m, random_state\u001B[38;5;241m=\u001B[39mRANDOM_STATE)\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 39\u001B[0m     X_train1, X_test1, y_train1, y_test1 \u001B[38;5;241m=\u001B[39m train_test_split(features, labels, train_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.9\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[43mRANDOM_STATE\u001B[49m)\n\u001B[1;32m     40\u001B[0m     X_train_index \u001B[38;5;241m=\u001B[39m X_train1[:, \u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     41\u001B[0m     y_train_index \u001B[38;5;241m=\u001B[39m y_train1[:, \u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'RANDOM_STATE' is not defined"
     ]
    }
   ],
   "source": [
    "def get_source_dataframe(rows=cutdown_rows):\n",
    "    try:\n",
    "        df = pd.read_csv('../data/source/df_listings.csv', on_bad_lines='skip', index_col=0)\n",
    "    except:\n",
    "        df = pd.read_csv('https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/df_listings.csv', on_bad_lines='skip', index_col=0)\n",
    "\n",
    "    df = df[features]\n",
    "\n",
    "    if rows and rows > 0:\n",
    "        df = df[:rows]\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_train_test_data(df_orig, return_index=False, drop_nulls=True):\n",
    "    df = df_orig.copy()\n",
    "\n",
    "    if drop_nulls:\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "    if return_index:\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "    for column in categories:\n",
    "        df = pd.concat([df, pd.get_dummies(df[column], prefix=column)], axis=1)\n",
    "        df.drop([column], axis=1, inplace=True)  # now drop the original column (you don't need it anymore),\n",
    "\n",
    "    ins = df.pop('index')\n",
    "    df.insert(1, 'index2', ins)\n",
    "    df.insert(0, 'index', ins)\n",
    "\n",
    "    #features = df[df.columns[1:]].values\n",
    "    features = df[df.columns[2:]].values\n",
    "    #labels = df[LABEL].values\n",
    "    labels = df.iloc[:, 0:2].values\n",
    "\n",
    "    if not return_index:\n",
    "        return train_test_split(features, labels, train_size=0.9, random_state=RANDOM_STATE)\n",
    "    else:\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(features, labels, train_size=0.9, random_state=RANDOM_STATE)\n",
    "        X_train_index = X_train1[:, 0].reshape(-1, 1)\n",
    "        y_train_index = y_train1[:, 0].reshape(-1, 1)\n",
    "        X_test_index = X_test1[:, 0].reshape(-1, 1)\n",
    "        y_test_index = y_test1[:, 0].reshape(-1, 1)\n",
    "        #X_train1 = X_train1[:,3:]\n",
    "        X_train1 = X_train1[:, 1:]\n",
    "        y_train1 = y_train1[:, 1].reshape(-1, 1)\n",
    "        #X_test1 = X_test1[:,3:]\n",
    "        X_test1 = X_test1[:, 1:]\n",
    "        y_test1 = y_test1[:, 1].reshape(-1, 1)\n",
    "\n",
    "        # X_train_index = pd.to_numeric(X_train_index, 'coerce').astype(int)\n",
    "        # y_train_index = pd.to_numeric(y_train_index, 'coerce').astype(int)\n",
    "        # X_test_index = pd.to_numeric(X_test_index, 'coerce').astype(int)\n",
    "        # y_test_index = pd.to_numeric(y_test_index, 'coerce').astype(int)\n",
    "\n",
    "        return X_train1, X_test1, y_train1, y_test1, X_train_index, X_test_index, y_train_index, y_test_index\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, X_train_index, X_test_index, y_train_index, y_test_index = create_train_test_data(\n",
    "    get_source_dataframe(), return_index=True, drop_nulls=False)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_train_index.shape, X_test_index.shape, y_train_index.shape, y_test_index.shape,\n",
    "X_train[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = get_source_dataframe()\n",
    "df_orig = df.copy()\n",
    "print(df.shape)\n",
    "df[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'nearestTram' in features:\n",
    "    df['nearestTram'] = df['nearestTram'].fillna(99)\n",
    "    df['nearestOverground'] = df['nearestOverground'].fillna(99)\n",
    "    df['nearestUnderground'] = df['nearestUnderground'].fillna(99)\n",
    "    df['nearestStation'] = df['nearestStation'].fillna(99)\n",
    "\n",
    "    imputer = SimpleImputer(strategy='constant', fill_value=99)\n",
    "    imputer.fit(df['nearestTram'].values.reshape(-1, 1))\n",
    "    df['nearestTram'] = imputer.transform(df['nearestTram'].values.reshape(-1, 1))\n",
    "    df['nearestUnderground'] = imputer.transform(df['nearestUnderground'].values.reshape(-1, 1))\n",
    "    df['nearestOverground'] = imputer.transform(df['nearestOverground'].values.reshape(-1, 1))\n",
    "    df['nearestStation'] = imputer.transform(df['nearestStation'].values.reshape(-1, 1))\n",
    "\n",
    "if 'keyFeatures' in features:\n",
    "    df['keyFeatures'] = df['keyFeatures'].str.lower()\n",
    "\n",
    "if 'analyticsProperty.priceQualifier' in features:\n",
    "\n",
    "    if 'keyFeatures' in features:\n",
    "\n",
    "        # df[df['keyFeatures'].str.contains('shared ownership')]\n",
    "\n",
    "        df['sharedOwnership'] = (\n",
    "                (df['sharedOwnership.sharedOwnership'] == True) |\n",
    "                (df['analyticsProperty.priceQualifier'] == 'Shared ownership') |\n",
    "                (df['keyFeatures'].str.contains('shared ownership'))\n",
    "        )\n",
    "\n",
    "        df.drop(['keyFeatures'], axis=1, inplace=True)\n",
    "    else:\n",
    "        df['sharedOwnership'] = (\n",
    "                (df['sharedOwnership.sharedOwnership'] == True) |\n",
    "                (df['analyticsProperty.priceQualifier'] == 'Shared ownership')\n",
    "        )\n",
    "\n",
    "    df['sharedOwnership'] = pd.to_numeric(df['sharedOwnership'], 'coerce').dropna().astype(int)\n",
    "    df.drop(['sharedOwnership.sharedOwnership'], axis=1, inplace=True)\n",
    "\n",
    "    if 'analyticsProperty.priceQualifier' not in categories:\n",
    "        df.drop(['analyticsProperty.priceQualifier'], axis=1, inplace=True)\n",
    "\n",
    "    #df.drop(['shared_ownership'], axis=1, inplace=True)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#df[df['keyFeatures'].str.contains('shared ownership')]\n",
    "#df['keyFeatures'] = df['keyFeatures'].apply(lambda x: x.astype(str).str.upper())\n",
    "#df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_train_index, X_test_index, y_train_index, y_test_index = create_train_test_data(df,\n",
    "                                                                                                                    return_index=True,\n",
    "                                                                                                                    drop_nulls=True)\n",
    "#X_train[:5]\n",
    "\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_train_index.shape, X_test_index.shape,\n",
    "      y_train_index.shape, y_test_index.shape)\n",
    "#X_train_index\n",
    "print(type(X_train))\n",
    "X_train[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#imputer = SimpleImputer(strategy='mean')\n",
    "#imputer.fit(X_train[6])\n",
    "#X_train[6] = imputer.transform(X_train[6])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "md = [6, 10, 50]\n",
    "lr = [0.01, 0.02, 0.05]\n",
    "ne = [100, 500, 1000]\n",
    "cb = [0.7, 1.0]\n",
    "params = { 'max_depth': md,  #Maximum tree depth for base learners\n",
    "           'learning_rate': lr,  #Boosting learning rate\n",
    "           'n_estimators': ne,  #Number of gradient boosted trees. Equivalent to number of boosting rounds\n",
    "           'colsample_bytree': cb} #Subsample ratio of columns when constructing each tree\n",
    "\n",
    "params = { 'max_depth': [6], #Maximum tree depth for base learners\n",
    "           'learning_rate': [0.01], #Boosting learning rate\n",
    "           'n_estimators': [100], #Number of gradient boosted trees. Equivalent to number of boosting rounds\n",
    "           'colsample_bytree': [0.7]} #Subsample ratio of columns when constructing each tree\n",
    "\n",
    "# params = { 'max_depth': [50], #Maximum tree depth for base learners\n",
    "#            'learning_rate': [0.05], #Boosting learning rate\n",
    "#            'n_estimators': [500], #Number of gradient boosted trees. Equivalent to number of boosting rounds\n",
    "#            'colsample_bytree': [0.7]} #Subsample ratio of columns when constructing each tree\n",
    "\n",
    "# params = { 'max_depth': md.index(0), #Maximum tree depth for base learners\n",
    "#            'learning_rate': lr.index(0), #Boosting learning rate\n",
    "#            'n_estimators': ne.index(0), #Number of gradient boosted trees. Equivalent to number of boosting rounds\n",
    "#            'colsample_bytree': cb.index(0)} #Subsample ratio of columns when constructing each tree\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(seed=20)\n",
    "\n",
    "xgb_grid = GridSearchCV(estimator=xgb_reg, param_grid=params, cv=2)\n",
    "#xgb_grid = RandomizedSearchCV(estimator=xgb_reg, param_grid=params, cv=2)\n",
    "\n",
    "xgb_grid.fit(X_train,y_train)\n",
    "\n",
    "model = xgb_grid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "\n",
    "result = xgb_grid.predict(X_test)\n",
    "R2 = r2_score(y_test,result)\n",
    "MSE = mean_squared_error(y_test,result)\n",
    "RMSE = math.sqrt(MSE)\n",
    "print('-'*10+'XGB'+'-'*10)\n",
    "print('R square Accuracy: ',R2)\n",
    "print('Mean Squared Error Accuracy: ',MSE)\n",
    "print('Root Mean Squared Error: ',RMSE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = result.reshape((-1, 1))\n",
    "\n",
    "print(y_test_index.reshape((-1, 1)).shape)\n",
    "print(result.reshape((-1, 1)).shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(y_test_index.shape)\n",
    "print(result.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compare = np.hstack((y_test_index, y_test, result))\n",
    "#compare[0:4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compare_df = DataFrame(compare, columns=['reference', 'actual', 'predicted'])\n",
    "compare_df['difference'] = abs(compare_df['actual'] - compare_df['predicted'])\n",
    "compare_df['diff 1 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['actual'] * 100)\n",
    "compare_df['diff 2 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['predicted']) * 100\n",
    "compare_df['reference'] = compare_df['reference'].astype(int)\n",
    "compare_df.set_index('reference', inplace=True)\n",
    "compare_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compare_df.join(df_orig)\n",
    "# 85514838\n",
    "# 115470422"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
