{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T17:55:32.004521Z",
     "iopub.status.busy": "2022-11-14T17:55:32.003662Z",
     "iopub.status.idle": "2022-11-14T17:55:32.008601Z",
     "shell.execute_reply": "2022-11-14T17:55:32.008123Z",
     "shell.execute_reply.started": "2022-11-14T17:55:32.004488Z"
    }
   },
   "outputs": [],
   "source": [
    "ALGORITHM = 'Neural Network'\n",
    "ALGORITHM_DETAIL = 'random search'\n",
    "ALGORITHM_DETAIL_ORIG = ALGORITHM_DETAIL\n",
    "ALGORITHM_DETAIL += ' [input11, d^20-500-500-20-5, dense1]'\n",
    "DATA_DETAIL = []\n",
    "#DATA_DETAIL = ['no scale','no dummies']\n",
    "VERSION = '06'\n",
    "\n",
    "RANDOM_STATE = 101\n",
    "TRAINING_SIZE = 0.9\n",
    "\n",
    "CROSS_VALIDATION_SCORING = 'r2'\n",
    "\n",
    "OVERRIDE_CV, OVERRIDE_N_ITER, OVERRIDE_JOBS = None, None, None\n",
    "\n",
    "debug_mode = False\n",
    "quick_mode = False\n",
    "quick_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:12.903669Z",
     "iopub.status.busy": "2022-11-14T17:50:12.903131Z",
     "iopub.status.idle": "2022-11-14T17:50:27.606418Z",
     "shell.execute_reply": "2022-11-14T17:50:27.605521Z",
     "shell.execute_reply.started": "2022-11-14T17:50:12.903648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (0.9.0)\r\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from scikeras) (1.1.2)\r\n",
      "Requirement already satisfied: packaging>=0.21 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from scikeras) (21.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from packaging>=0.21->scikeras) (3.0.9)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.23.3)\r\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.9.1)\r\n",
      "Requirement already satisfied: catboost in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (1.1.1)\r\n",
      "Requirement already satisfied: six in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from catboost) (1.16.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from catboost) (1.23.3)\r\n",
      "Requirement already satisfied: graphviz in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from catboost) (0.20.1)\r\n",
      "Requirement already satisfied: scipy in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from catboost) (1.9.1)\r\n",
      "Requirement already satisfied: matplotlib in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from catboost) (3.6.0)\r\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from catboost) (1.5.0)\r\n",
      "Requirement already satisfied: plotly in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from catboost) (5.10.0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2022.2.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from matplotlib->catboost) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from matplotlib->catboost) (4.37.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from matplotlib->catboost) (21.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from matplotlib->catboost) (1.0.5)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from matplotlib->catboost) (3.0.9)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from matplotlib->catboost) (1.4.4)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from matplotlib->catboost) (9.2.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/guava/PycharmProjects/capstone_streamlit/venv/lib/python3.8/site-packages (from plotly->catboost) (8.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install scikeras\n",
    "! pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:27.608294Z",
     "iopub.status.busy": "2022-11-14T17:50:27.608049Z",
     "iopub.status.idle": "2022-11-14T17:50:32.094482Z",
     "shell.execute_reply": "2022-11-14T17:50:32.093735Z",
     "shell.execute_reply.started": "2022-11-14T17:50:27.608252Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 21:39:05.940740: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "def make_regression_ann(initializer='uniform', activation='relu', optimizer='adam', loss='mse'):\n",
    "    normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "    model = Sequential()\n",
    "    #model.add(normalizer)\n",
    "    model.add(Dense(11, input_shape=(len(X_train[0]),), activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    #print(model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:32.095998Z",
     "iopub.status.busy": "2022-11-14T17:50:32.095597Z",
     "iopub.status.idle": "2022-11-14T17:50:33.378816Z",
     "shell.execute_reply": "2022-11-14T17:50:33.378157Z",
     "shell.execute_reply.started": "2022-11-14T17:50:32.095977Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'notebook_environment': 'local', 'use_gpu': False, 'debug_mode': False, 'quick_mode': False, 'quick_override_cv_splits': 2, 'quick_override_n_iter': 10, 'quick_override_n_jobs': 3}\n"
     ]
    }
   ],
   "source": [
    "#confirm_colab = True\n",
    "confirm_colab = False\n",
    "IN_CLOUD = False\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "from termcolor import colored\n",
    "from time import time\n",
    "import sklearn\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('../../z_envs/_envs.json') as f:\n",
    "    env_vars = json.loads(f.read())\n",
    "print(env_vars)\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    run_env = 'colab'\n",
    "except:\n",
    "    try:\n",
    "        run_env = env_vars['notebook_environment']\n",
    "    except:\n",
    "        run_env = 'unknown'\n",
    "\n",
    "use_gpu = env_vars.get('use_gpu', False)\n",
    "debug_mode = env_vars.get('debug_mode', False)\n",
    "quick_mode = env_vars.get('quick_mode', False)\n",
    "OVERRIDE_CV = env_vars.get('quick_override_cv_splits', None) if quick_mode else None\n",
    "OVERRIDE_N_ITER = env_vars.get('quick_override_n_iter', None) if quick_mode else None\n",
    "OVERRIDE_JOBS = env_vars.get('quick_override_n_jobs', None) if quick_mode else None\n",
    "#if quick_mode:OVERRIDE_CV, OVERRIDE_N_ITER = 2, 10\n",
    "\n",
    "already_timed = False\n",
    "no_dummies = 'no dummies' in DATA_DETAIL\n",
    "no_scaling = 'no scaling' in DATA_DETAIL\n",
    "not_catboost = 'catboost' not in ALGORITHM.lower() or not no_dummies\n",
    "\n",
    "if run_env not in ['colab', 'gradient', 'cloud']:\n",
    "    cloud_run = False\n",
    "    from functions_20221109 import set_csv_directory, get_columns\n",
    "    from functions_modelling_20221109 import make_modelling_pipeline, tidy_dataset, preprocess, feature_engineer, create_train_test_data\n",
    "    from functions_modelling_20221109 import get_cv_params, fit_model_with_cross_validation, get_best_estimator_average_time\n",
    "    from functions_modelling_20221109 import get_results, update_results, get_chosen_model\n",
    "    from functions_modelling_20221109 import get_hyperparameters\n",
    "\n",
    "    set_csv_directory('final_split')\n",
    "else:\n",
    "    cloud_run = True\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    module_path = os.path.abspath(os.path.join('..', '..', '..'))\n",
    "    if module_path not in sys.path:\n",
    "        #sys.path.append(module_path+\"\\\\zfunctions\")\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "    from functions_20221109 import set_csv_directory, get_columns\n",
    "    #from functions_20221109 import add_supplements, get_combined_dataset\n",
    "    from functions_modelling_20221109 import make_modelling_pipeline, tidy_dataset, preprocess, feature_engineer, create_train_test_data\n",
    "    from functions_modelling_20221109 import get_cv_params, fit_model_with_cross_validation, get_best_estimator_average_time\n",
    "    from functions_modelling_20221109 import get_results, update_results, get_chosen_model\n",
    "    from functions_modelling_20221109 import get_hyperparameters\n",
    "\n",
    "if quick_mode:\n",
    "    OVERRIDE_CV, OVERRIDE_N_ITER = 2, 10\n",
    "\n",
    "if 'neural' in ALGORITHM.lower():\n",
    "    OVERRIDE_JOBS=1\n",
    "\n",
    "if 'neural' in ALGORITHM.lower() and not cloud_run:\n",
    "    OVERRIDE_N_ITER = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.381016Z",
     "iopub.status.busy": "2022-11-14T17:50:33.380601Z",
     "iopub.status.idle": "2022-11-14T17:50:33.385195Z",
     "shell.execute_reply": "2022-11-14T17:50:33.384629Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.380995Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mfeatures\u001B[0m ->  ['bedrooms', 'bathrooms', 'nearestStation', 'location.latitude', 'location.longitude', 'latitude_deviation', 'longitude_deviation', 'tenure.tenureType']\n",
      "\u001B[1m\u001B[32mlabel\u001B[0m ->  Price\n"
     ]
    }
   ],
   "source": [
    "#cutdown_rows = 1000\n",
    "cutdown_rows = 0\n",
    "\n",
    "LABEL = 'Price'\n",
    "\n",
    "columns, booleans, floats, categories, custom, wildcard = get_columns(version=VERSION)\n",
    "\n",
    "print(colored(f\"features\", \"blue\"), \"-> \", columns)\n",
    "columns.insert(0, LABEL)\n",
    "print(colored(f\"label\", \"green\", None, ['bold']), \"-> \", LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.386344Z",
     "iopub.status.busy": "2022-11-14T17:50:33.386160Z",
     "iopub.status.idle": "2022-11-14T17:50:33.390622Z",
     "shell.execute_reply": "2022-11-14T17:50:33.390093Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.386325Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_source_dataframe(rows=cutdown_rows, folder_prefix='../../../'):\n",
    "    retrieval_type = None\n",
    "\n",
    "    filename = f'df_listings_v{VERSION}.csv'\n",
    "    remote_pathname = f'https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/{filename}'\n",
    "    df_pathname_raw = folder_prefix + f'data/source/{filename}'\n",
    "    df_pathname_tidy = folder_prefix + f'data/final/{filename}'\n",
    "\n",
    "    if cloud_run:\n",
    "        inDF = pd.read_csv(remote_pathname, on_bad_lines='error', index_col=0)\n",
    "        retrieval_type = 'tidy'\n",
    "        print('loaded data from', folder_prefix + remote_pathname)\n",
    "    else:\n",
    "        inDF = pd.read_csv(df_pathname_tidy, on_bad_lines='error', index_col=0)\n",
    "        retrieval_type = 'tidy'\n",
    "        print('loaded data from', df_pathname_tidy)\n",
    "\n",
    "    if rows and rows > 0:\n",
    "        inDF = inDF[:rows]\n",
    "    return inDF, retrieval_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.391680Z",
     "iopub.status.busy": "2022-11-14T17:50:33.391486Z",
     "iopub.status.idle": "2022-11-14T17:50:33.700294Z",
     "shell.execute_reply": "2022-11-14T17:50:33.699591Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.391662Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data from ../../../data/final/df_listings_v06.csv\n",
      "(46871, 9)\n"
     ]
    }
   ],
   "source": [
    "df, retrieval_type = get_source_dataframe(folder_prefix='../../../')\n",
    "df_orig = df.copy()\n",
    "\n",
    "if retrieval_type != 'tidy':\n",
    "    df = tidy_dataset(df, version=int(VERSION))\n",
    "    df = feature_engineer(df, version=int(VERSION))\n",
    "\n",
    "    df = df[columns]\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.701517Z",
     "iopub.status.busy": "2022-11-14T17:50:33.701313Z",
     "iopub.status.idle": "2022-11-14T17:50:33.724736Z",
     "shell.execute_reply": "2022-11-14T17:50:33.724076Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.701498Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             Price  bedrooms  bathrooms  nearestStation  location.latitude  \\\n14520525  550000.0       3.0        1.0        0.274316          51.529950   \n27953107  400000.0       2.0        2.0        0.305845          51.549390   \n33593487  579950.0       2.0        1.0        0.438045          51.447180   \n35271294  370000.0       2.0        1.0        0.399307          51.449568   \n35429088  599950.0       2.0        1.0        0.238187          51.577030   \n44749111  475000.0       2.0        1.0        0.410550          51.370050   \n46204665  435000.0       3.0        2.0        0.314779          51.539070   \n49020666  200000.0       1.0        1.0        0.875911          51.539959   \n49036279  275000.0       2.0        1.0        0.474368          51.541780   \n49303873  450000.0       3.0        2.0        0.577040          51.524880   \n52064391  349950.0       2.0        2.0        0.212734          51.470800   \n52187854  450000.0       1.0        1.0        0.446802          51.527199   \n52675628  490000.0       2.0        2.0        0.215040          51.501114   \n52845963  200000.0       2.0        1.0        0.650562          51.398040   \n52913496  220000.0       1.0        1.0        0.945991          51.539383   \n53609433  489995.0       1.0        1.0        0.087081          51.532620   \n53649578  284950.0       1.0        1.0        0.806597          51.479890   \n53938989  450000.0       2.0        1.0        0.775203          51.658287   \n54713232  332000.0       2.0        1.0        0.319226          51.612300   \n54904122  365000.0       2.0        1.0        0.260722          51.593595   \n54991934  430000.0       3.0        1.0        0.497268          51.528720   \n55043230  260000.0       1.0        1.0        0.384607          51.544430   \n55187658  430000.0       2.0        2.0        0.289033          51.507570   \n55531367  599950.0       2.0        1.0        0.406725          51.467410   \n55768232  550000.0       2.0        1.0        0.478349          51.472890   \n55805965  280000.0       2.0        1.0        0.742859          51.520910   \n55839051  599950.0       2.0        1.0        0.259168          51.579186   \n55940994  385000.0       2.0        2.0        0.403987          51.376930   \n56449305  380000.0       2.0        1.0        0.310271          51.600483   \n57221413  475000.0       3.0        2.0        0.409784          51.497260   \n\n          location.longitude  latitude_deviation  longitude_deviation  \\\n14520525           -0.207020            0.030230             0.102600   \n27953107           -0.482600            0.049670             0.378180   \n33593487           -0.338770            0.052540             0.234350   \n35271294           -0.140154            0.050152             0.035734   \n35429088           -0.141230            0.077310             0.036810   \n44749111           -0.212410            0.129670             0.107990   \n46204665           -0.198935            0.039350             0.094515   \n49020666           -0.380863            0.040239             0.276443   \n49036279            0.037890            0.042060             0.142310   \n49303873            0.187200            0.025160             0.291620   \n52064391           -0.361820            0.028920             0.257400   \n52187854           -0.202898            0.027479             0.098478   \n52675628            0.026315            0.001394             0.130735   \n52845963           -0.076812            0.101680             0.027608   \n52913496           -0.382239            0.039663             0.277819   \n53609433           -0.107860            0.032900             0.003440   \n53649578           -0.078500            0.019830             0.025920   \n53938989           -0.207902            0.158567             0.103482   \n54713232           -0.119860            0.112580             0.015440   \n54904122            0.022046            0.093875             0.126466   \n54991934            0.039180            0.029000             0.143600   \n55043230            0.014500            0.044710             0.118920   \n55187658            0.078030            0.007850             0.182450   \n55531367           -0.079170            0.032310             0.025250   \n55768232           -0.078940            0.026830             0.025480   \n55805965            0.022680            0.021190             0.127100   \n55839051           -0.209020            0.079466             0.104600   \n55940994           -0.238870            0.122790             0.134450   \n56449305           -0.062096            0.100763             0.042324   \n57221413           -0.422530            0.002460             0.318110   \n\n          tenure.tenureType  \n14520525          LEASEHOLD  \n27953107          LEASEHOLD  \n33593487           FREEHOLD  \n35271294          LEASEHOLD  \n35429088                NaN  \n44749111           FREEHOLD  \n46204665          LEASEHOLD  \n49020666          LEASEHOLD  \n49036279          LEASEHOLD  \n49303873           FREEHOLD  \n52064391          LEASEHOLD  \n52187854          LEASEHOLD  \n52675628                NaN  \n52845963          LEASEHOLD  \n52913496          LEASEHOLD  \n53609433          LEASEHOLD  \n53649578                NaN  \n53938989           FREEHOLD  \n54713232  SHARE_OF_FREEHOLD  \n54904122  SHARE_OF_FREEHOLD  \n54991934           FREEHOLD  \n55043230          LEASEHOLD  \n55187658          LEASEHOLD  \n55531367                NaN  \n55768232                NaN  \n55805965          LEASEHOLD  \n55839051          LEASEHOLD  \n55940994          LEASEHOLD  \n56449305           FREEHOLD  \n57221413           FREEHOLD  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n      <th>location.latitude</th>\n      <th>location.longitude</th>\n      <th>latitude_deviation</th>\n      <th>longitude_deviation</th>\n      <th>tenure.tenureType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14520525</th>\n      <td>550000.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.274316</td>\n      <td>51.529950</td>\n      <td>-0.207020</td>\n      <td>0.030230</td>\n      <td>0.102600</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>27953107</th>\n      <td>400000.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.305845</td>\n      <td>51.549390</td>\n      <td>-0.482600</td>\n      <td>0.049670</td>\n      <td>0.378180</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>33593487</th>\n      <td>579950.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.438045</td>\n      <td>51.447180</td>\n      <td>-0.338770</td>\n      <td>0.052540</td>\n      <td>0.234350</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>35271294</th>\n      <td>370000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.399307</td>\n      <td>51.449568</td>\n      <td>-0.140154</td>\n      <td>0.050152</td>\n      <td>0.035734</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>35429088</th>\n      <td>599950.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.238187</td>\n      <td>51.577030</td>\n      <td>-0.141230</td>\n      <td>0.077310</td>\n      <td>0.036810</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>44749111</th>\n      <td>475000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.410550</td>\n      <td>51.370050</td>\n      <td>-0.212410</td>\n      <td>0.129670</td>\n      <td>0.107990</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>46204665</th>\n      <td>435000.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.314779</td>\n      <td>51.539070</td>\n      <td>-0.198935</td>\n      <td>0.039350</td>\n      <td>0.094515</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>49020666</th>\n      <td>200000.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.875911</td>\n      <td>51.539959</td>\n      <td>-0.380863</td>\n      <td>0.040239</td>\n      <td>0.276443</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>49036279</th>\n      <td>275000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.474368</td>\n      <td>51.541780</td>\n      <td>0.037890</td>\n      <td>0.042060</td>\n      <td>0.142310</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>49303873</th>\n      <td>450000.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.577040</td>\n      <td>51.524880</td>\n      <td>0.187200</td>\n      <td>0.025160</td>\n      <td>0.291620</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>52064391</th>\n      <td>349950.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.212734</td>\n      <td>51.470800</td>\n      <td>-0.361820</td>\n      <td>0.028920</td>\n      <td>0.257400</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>52187854</th>\n      <td>450000.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.446802</td>\n      <td>51.527199</td>\n      <td>-0.202898</td>\n      <td>0.027479</td>\n      <td>0.098478</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>52675628</th>\n      <td>490000.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.215040</td>\n      <td>51.501114</td>\n      <td>0.026315</td>\n      <td>0.001394</td>\n      <td>0.130735</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>52845963</th>\n      <td>200000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.650562</td>\n      <td>51.398040</td>\n      <td>-0.076812</td>\n      <td>0.101680</td>\n      <td>0.027608</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>52913496</th>\n      <td>220000.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.945991</td>\n      <td>51.539383</td>\n      <td>-0.382239</td>\n      <td>0.039663</td>\n      <td>0.277819</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>53609433</th>\n      <td>489995.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.087081</td>\n      <td>51.532620</td>\n      <td>-0.107860</td>\n      <td>0.032900</td>\n      <td>0.003440</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>53649578</th>\n      <td>284950.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.806597</td>\n      <td>51.479890</td>\n      <td>-0.078500</td>\n      <td>0.019830</td>\n      <td>0.025920</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>53938989</th>\n      <td>450000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.775203</td>\n      <td>51.658287</td>\n      <td>-0.207902</td>\n      <td>0.158567</td>\n      <td>0.103482</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>54713232</th>\n      <td>332000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.319226</td>\n      <td>51.612300</td>\n      <td>-0.119860</td>\n      <td>0.112580</td>\n      <td>0.015440</td>\n      <td>SHARE_OF_FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>54904122</th>\n      <td>365000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.260722</td>\n      <td>51.593595</td>\n      <td>0.022046</td>\n      <td>0.093875</td>\n      <td>0.126466</td>\n      <td>SHARE_OF_FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>54991934</th>\n      <td>430000.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.497268</td>\n      <td>51.528720</td>\n      <td>0.039180</td>\n      <td>0.029000</td>\n      <td>0.143600</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>55043230</th>\n      <td>260000.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.384607</td>\n      <td>51.544430</td>\n      <td>0.014500</td>\n      <td>0.044710</td>\n      <td>0.118920</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>55187658</th>\n      <td>430000.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.289033</td>\n      <td>51.507570</td>\n      <td>0.078030</td>\n      <td>0.007850</td>\n      <td>0.182450</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>55531367</th>\n      <td>599950.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.406725</td>\n      <td>51.467410</td>\n      <td>-0.079170</td>\n      <td>0.032310</td>\n      <td>0.025250</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>55768232</th>\n      <td>550000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.478349</td>\n      <td>51.472890</td>\n      <td>-0.078940</td>\n      <td>0.026830</td>\n      <td>0.025480</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>55805965</th>\n      <td>280000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.742859</td>\n      <td>51.520910</td>\n      <td>0.022680</td>\n      <td>0.021190</td>\n      <td>0.127100</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>55839051</th>\n      <td>599950.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.259168</td>\n      <td>51.579186</td>\n      <td>-0.209020</td>\n      <td>0.079466</td>\n      <td>0.104600</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>55940994</th>\n      <td>385000.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.403987</td>\n      <td>51.376930</td>\n      <td>-0.238870</td>\n      <td>0.122790</td>\n      <td>0.134450</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>56449305</th>\n      <td>380000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.310271</td>\n      <td>51.600483</td>\n      <td>-0.062096</td>\n      <td>0.100763</td>\n      <td>0.042324</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>57221413</th>\n      <td>475000.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.409784</td>\n      <td>51.497260</td>\n      <td>-0.422530</td>\n      <td>0.002460</td>\n      <td>0.318110</td>\n      <td>FREEHOLD</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.725907Z",
     "iopub.status.busy": "2022-11-14T17:50:33.725716Z",
     "iopub.status.idle": "2022-11-14T17:50:33.736870Z",
     "shell.execute_reply": "2022-11-14T17:50:33.736183Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.725890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Price                     0\nbedrooms                  0\nbathrooms                 0\nnearestStation            0\nlocation.latitude         0\nlocation.longitude        0\nlatitude_deviation        0\nlongitude_deviation       0\ntenure.tenureType      2744\ndtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.737836Z",
     "iopub.status.busy": "2022-11-14T17:50:33.737654Z",
     "iopub.status.idle": "2022-11-14T17:50:33.809709Z",
     "shell.execute_reply": "2022-11-14T17:50:33.809008Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.737820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46871 entries, 14520525 to 126181118\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Price                46871 non-null  float64\n",
      " 1   bedrooms             46871 non-null  float64\n",
      " 2   bathrooms            46871 non-null  float64\n",
      " 3   nearestStation       46871 non-null  float64\n",
      " 4   location.latitude    46871 non-null  float64\n",
      " 5   location.longitude   46871 non-null  float64\n",
      " 6   latitude_deviation   46871 non-null  float64\n",
      " 7   longitude_deviation  46871 non-null  float64\n",
      " 8   tenure.tenureType    44127 non-null  object \n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "                       count           mean            std            min  \\\nPrice                46871.0  425069.390775  107227.324906  100000.000000   \nbedrooms             46871.0       1.992469       0.828837       1.000000   \nbathrooms            46871.0       1.182074       0.409879       1.000000   \nnearestStation       46871.0       0.438847       0.325942       0.000000   \nlocation.latitude    46871.0      51.497049       0.077085      51.298317   \nlocation.longitude   46871.0      -0.113269       0.156489      -0.498315   \nlatitude_deviation   46871.0       0.064317       0.042573       0.000000   \nlongitude_deviation  46871.0       0.124202       0.095607       0.000000   \n\n                               25%            50%            75%  \\\nPrice                349950.000000  425000.000000  515000.000000   \nbedrooms                  1.000000       2.000000       3.000000   \nbathrooms                 1.000000       1.000000       1.000000   \nnearestStation            0.227169       0.367971       0.559620   \nlocation.latitude        51.438861      51.499977      51.556183   \nlocation.longitude       -0.210796      -0.102230      -0.010343   \nlatitude_deviation        0.028876       0.058595       0.094362   \nlongitude_deviation       0.043560       0.098984       0.192684   \n\n                               max  \nPrice                600000.000000  \nbedrooms                  7.000000  \nbathrooms                 5.000000  \nnearestStation            7.197700  \nlocation.latitude        51.683185  \nlocation.longitude        0.279726  \nlatitude_deviation        0.201403  \nlongitude_deviation       0.393895  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Price</th>\n      <td>46871.0</td>\n      <td>425069.390775</td>\n      <td>107227.324906</td>\n      <td>100000.000000</td>\n      <td>349950.000000</td>\n      <td>425000.000000</td>\n      <td>515000.000000</td>\n      <td>600000.000000</td>\n    </tr>\n    <tr>\n      <th>bedrooms</th>\n      <td>46871.0</td>\n      <td>1.992469</td>\n      <td>0.828837</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>bathrooms</th>\n      <td>46871.0</td>\n      <td>1.182074</td>\n      <td>0.409879</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>nearestStation</th>\n      <td>46871.0</td>\n      <td>0.438847</td>\n      <td>0.325942</td>\n      <td>0.000000</td>\n      <td>0.227169</td>\n      <td>0.367971</td>\n      <td>0.559620</td>\n      <td>7.197700</td>\n    </tr>\n    <tr>\n      <th>location.latitude</th>\n      <td>46871.0</td>\n      <td>51.497049</td>\n      <td>0.077085</td>\n      <td>51.298317</td>\n      <td>51.438861</td>\n      <td>51.499977</td>\n      <td>51.556183</td>\n      <td>51.683185</td>\n    </tr>\n    <tr>\n      <th>location.longitude</th>\n      <td>46871.0</td>\n      <td>-0.113269</td>\n      <td>0.156489</td>\n      <td>-0.498315</td>\n      <td>-0.210796</td>\n      <td>-0.102230</td>\n      <td>-0.010343</td>\n      <td>0.279726</td>\n    </tr>\n    <tr>\n      <th>latitude_deviation</th>\n      <td>46871.0</td>\n      <td>0.064317</td>\n      <td>0.042573</td>\n      <td>0.000000</td>\n      <td>0.028876</td>\n      <td>0.058595</td>\n      <td>0.094362</td>\n      <td>0.201403</td>\n    </tr>\n    <tr>\n      <th>longitude_deviation</th>\n      <td>46871.0</td>\n      <td>0.124202</td>\n      <td>0.095607</td>\n      <td>0.000000</td>\n      <td>0.043560</td>\n      <td>0.098984</td>\n      <td>0.192684</td>\n      <td>0.393895</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.812627Z",
     "iopub.status.busy": "2022-11-14T17:50:33.812396Z",
     "iopub.status.idle": "2022-11-14T17:50:33.858568Z",
     "shell.execute_reply": "2022-11-14T17:50:33.857841Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.812608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe contract due to cleaning: 46871 ==> 46871\n"
     ]
    },
    {
     "data": {
      "text/plain": "                       count           mean            std            min  \\\nPrice                46871.0  425069.390775  107227.324906  100000.000000   \nbedrooms             46871.0       1.992469       0.828837       1.000000   \nbathrooms            46871.0       1.182074       0.409879       1.000000   \nnearestStation       46871.0       0.438847       0.325942       0.000000   \nlocation.latitude    46871.0      51.497049       0.077085      51.298317   \nlocation.longitude   46871.0      -0.113269       0.156489      -0.498315   \nlatitude_deviation   46871.0       0.064317       0.042573       0.000000   \nlongitude_deviation  46871.0       0.124202       0.095607       0.000000   \n\n                               25%            50%            75%  \\\nPrice                349950.000000  425000.000000  515000.000000   \nbedrooms                  1.000000       2.000000       3.000000   \nbathrooms                 1.000000       1.000000       1.000000   \nnearestStation            0.227169       0.367971       0.559620   \nlocation.latitude        51.438861      51.499977      51.556183   \nlocation.longitude       -0.210796      -0.102230      -0.010343   \nlatitude_deviation        0.028876       0.058595       0.094362   \nlongitude_deviation       0.043560       0.098984       0.192684   \n\n                               max  \nPrice                600000.000000  \nbedrooms                  7.000000  \nbathrooms                 5.000000  \nnearestStation            7.197700  \nlocation.latitude        51.683185  \nlocation.longitude        0.279726  \nlatitude_deviation        0.201403  \nlongitude_deviation       0.393895  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Price</th>\n      <td>46871.0</td>\n      <td>425069.390775</td>\n      <td>107227.324906</td>\n      <td>100000.000000</td>\n      <td>349950.000000</td>\n      <td>425000.000000</td>\n      <td>515000.000000</td>\n      <td>600000.000000</td>\n    </tr>\n    <tr>\n      <th>bedrooms</th>\n      <td>46871.0</td>\n      <td>1.992469</td>\n      <td>0.828837</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>bathrooms</th>\n      <td>46871.0</td>\n      <td>1.182074</td>\n      <td>0.409879</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>nearestStation</th>\n      <td>46871.0</td>\n      <td>0.438847</td>\n      <td>0.325942</td>\n      <td>0.000000</td>\n      <td>0.227169</td>\n      <td>0.367971</td>\n      <td>0.559620</td>\n      <td>7.197700</td>\n    </tr>\n    <tr>\n      <th>location.latitude</th>\n      <td>46871.0</td>\n      <td>51.497049</td>\n      <td>0.077085</td>\n      <td>51.298317</td>\n      <td>51.438861</td>\n      <td>51.499977</td>\n      <td>51.556183</td>\n      <td>51.683185</td>\n    </tr>\n    <tr>\n      <th>location.longitude</th>\n      <td>46871.0</td>\n      <td>-0.113269</td>\n      <td>0.156489</td>\n      <td>-0.498315</td>\n      <td>-0.210796</td>\n      <td>-0.102230</td>\n      <td>-0.010343</td>\n      <td>0.279726</td>\n    </tr>\n    <tr>\n      <th>latitude_deviation</th>\n      <td>46871.0</td>\n      <td>0.064317</td>\n      <td>0.042573</td>\n      <td>0.000000</td>\n      <td>0.028876</td>\n      <td>0.058595</td>\n      <td>0.094362</td>\n      <td>0.201403</td>\n    </tr>\n    <tr>\n      <th>longitude_deviation</th>\n      <td>46871.0</td>\n      <td>0.124202</td>\n      <td>0.095607</td>\n      <td>0.000000</td>\n      <td>0.043560</td>\n      <td>0.098984</td>\n      <td>0.192684</td>\n      <td>0.393895</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_length = len(df)\n",
    "\n",
    "df = preprocess(df, version=VERSION)\n",
    "\n",
    "print(f\"dataframe contract due to cleaning: {old_length} ==> {len(df)}\")\n",
    "old_length = len(df)\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.859847Z",
     "iopub.status.busy": "2022-11-14T17:50:33.859651Z",
     "iopub.status.idle": "2022-11-14T17:50:33.868919Z",
     "shell.execute_reply": "2022-11-14T17:50:33.868134Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.859829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Price                     0\nbedrooms                  0\nbathrooms                 0\nnearestStation            0\nlocation.latitude         0\nlocation.longitude        0\nlatitude_deviation        0\nlongitude_deviation       0\ntenure.tenureType      2744\ndtype: int64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.870039Z",
     "iopub.status.busy": "2022-11-14T17:50:33.869858Z",
     "iopub.status.idle": "2022-11-14T17:50:33.903990Z",
     "shell.execute_reply": "2022-11-14T17:50:33.903481Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.870022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46871 ==> 44127\n"
     ]
    },
    {
     "data": {
      "text/plain": "               Price      bedrooms    bathrooms  nearestStation  \\\ncount   44127.000000  44127.000000  44127.00000    44127.000000   \nmean   425224.642373      1.990981      1.18134        0.438522   \nstd    107203.332660      0.827621      0.40893        0.324152   \nmin    100000.000000      1.000000      1.00000        0.000000   \n25%    349950.000000      1.000000      1.00000        0.227551   \n50%    425000.000000      2.000000      1.00000        0.368351   \n75%    515000.000000      3.000000      1.00000        0.559486   \nmax    600000.000000      7.000000      5.00000        7.197700   \n\n       location.latitude  location.longitude  latitude_deviation  \\\ncount       44127.000000        44127.000000        44127.000000   \nmean           51.496711           -0.113106            0.064544   \nstd             0.077267            0.155863            0.042583   \nmin            51.298317           -0.498315            0.000000   \n25%            51.438303           -0.210633            0.029023   \n50%            51.498780           -0.101910            0.058904   \n75%            51.556343           -0.010854            0.094620   \nmax            51.683185            0.279726            0.201403   \n\n       longitude_deviation  \ncount         44127.000000  \nmean              0.123699  \nstd               0.095220  \nmin               0.000000  \n25%               0.043551  \n50%               0.098750  \n75%               0.191727  \nmax               0.393895  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n      <th>location.latitude</th>\n      <th>location.longitude</th>\n      <th>latitude_deviation</th>\n      <th>longitude_deviation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>44127.000000</td>\n      <td>44127.000000</td>\n      <td>44127.00000</td>\n      <td>44127.000000</td>\n      <td>44127.000000</td>\n      <td>44127.000000</td>\n      <td>44127.000000</td>\n      <td>44127.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>425224.642373</td>\n      <td>1.990981</td>\n      <td>1.18134</td>\n      <td>0.438522</td>\n      <td>51.496711</td>\n      <td>-0.113106</td>\n      <td>0.064544</td>\n      <td>0.123699</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>107203.332660</td>\n      <td>0.827621</td>\n      <td>0.40893</td>\n      <td>0.324152</td>\n      <td>0.077267</td>\n      <td>0.155863</td>\n      <td>0.042583</td>\n      <td>0.095220</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>100000.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>0.000000</td>\n      <td>51.298317</td>\n      <td>-0.498315</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>349950.000000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>0.227551</td>\n      <td>51.438303</td>\n      <td>-0.210633</td>\n      <td>0.029023</td>\n      <td>0.043551</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>425000.000000</td>\n      <td>2.000000</td>\n      <td>1.00000</td>\n      <td>0.368351</td>\n      <td>51.498780</td>\n      <td>-0.101910</td>\n      <td>0.058904</td>\n      <td>0.098750</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>515000.000000</td>\n      <td>3.000000</td>\n      <td>1.00000</td>\n      <td>0.559486</td>\n      <td>51.556343</td>\n      <td>-0.010854</td>\n      <td>0.094620</td>\n      <td>0.191727</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>600000.000000</td>\n      <td>7.000000</td>\n      <td>5.00000</td>\n      <td>7.197700</td>\n      <td>51.683185</td>\n      <td>0.279726</td>\n      <td>0.201403</td>\n      <td>0.393895</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(f\"{old_length} ==> {len(df)}\")\n",
    "old_length = len(df)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.905003Z",
     "iopub.status.busy": "2022-11-14T17:50:33.904814Z",
     "iopub.status.idle": "2022-11-14T17:50:33.939375Z",
     "shell.execute_reply": "2022-11-14T17:50:33.938757Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.904985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39714, 11) (4413, 11) (39714, 1) (4413, 1) (39714, 1) (4413, 1) (39714, 1) (4413, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_train_index, X_test_index, y_train_index, y_test_index, df_features, df_labels = create_train_test_data(\n",
    "    df,\n",
    "    categories=categories,\n",
    "    RANDOM_STATE=RANDOM_STATE, return_index=True,\n",
    "    drop_nulls=True)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_train_index.shape, X_test_index.shape,\n",
    "      y_train_index.shape, y_test_index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.940563Z",
     "iopub.status.busy": "2022-11-14T17:50:33.940351Z",
     "iopub.status.idle": "2022-11-14T17:50:33.943721Z",
     "shell.execute_reply": "2022-11-14T17:50:33.943004Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.940543Z"
    }
   },
   "outputs": [],
   "source": [
    "#imputer = SimpleImputer(strategy='mean')\n",
    "#imputer.fit(X_train[6])\n",
    "#X_train[6] = imputer.transform(X_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.944751Z",
     "iopub.status.busy": "2022-11-14T17:50:33.944575Z",
     "iopub.status.idle": "2022-11-14T17:50:33.952329Z",
     "shell.execute_reply": "2022-11-14T17:50:33.951765Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.944734Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('std_scaler', StandardScaler()),\n                ('model',\n                 KerasRegressor(model=<function make_regression_ann at 0x7f2e9e323af0>, verbose=0))])",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;std_scaler&#x27;, StandardScaler()),\n                (&#x27;model&#x27;,\n                 KerasRegressor(model=&lt;function make_regression_ann at 0x7f2e9e323af0&gt;, verbose=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;std_scaler&#x27;, StandardScaler()),\n                (&#x27;model&#x27;,\n                 KerasRegressor(model=&lt;function make_regression_ann at 0x7f2e9e323af0&gt;, verbose=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n\tmodel=&lt;function make_regression_ann at 0x7f2e9e323af0&gt;\n\tbuild_fn=None\n\twarm_start=False\n\trandom_state=None\n\toptimizer=rmsprop\n\tloss=None\n\tmetrics=None\n\tbatch_size=None\n\tvalidation_batch_size=None\n\tverbose=0\n\tcallbacks=None\n\tvalidation_split=0.0\n\tshuffle=True\n\trun_eagerly=False\n\tepochs=1\n)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starter_pipe = make_modelling_pipeline(KerasRegressor(make_regression_ann, verbose=0), DATA_DETAIL)\n",
    "starter_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.953300Z",
     "iopub.status.busy": "2022-11-14T17:50:33.953097Z",
     "iopub.status.idle": "2022-11-14T17:50:33.957332Z",
     "shell.execute_reply": "2022-11-14T17:50:33.956807Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.953279Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'model': <function __main__.make_regression_ann(initializer='uniform', activation='relu', optimizer='adam', loss='mse')>,\n 'build_fn': None,\n 'warm_start': False,\n 'random_state': None,\n 'optimizer': 'rmsprop',\n 'loss': None,\n 'metrics': None,\n 'batch_size': None,\n 'validation_batch_size': None,\n 'verbose': 0,\n 'callbacks': None,\n 'validation_split': 0.0,\n 'shuffle': True,\n 'run_eagerly': False,\n 'epochs': 1}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starter_model = starter_pipe[-1]\n",
    "default_model_params = starter_model.get_params()\n",
    "default_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.958438Z",
     "iopub.status.busy": "2022-11-14T17:50:33.958260Z",
     "iopub.status.idle": "2022-11-14T17:50:33.962787Z",
     "shell.execute_reply": "2022-11-14T17:50:33.962081Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.958422Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['accuracy',\n 'adjusted_mutual_info_score',\n 'adjusted_rand_score',\n 'average_precision',\n 'balanced_accuracy',\n 'completeness_score',\n 'explained_variance',\n 'f1',\n 'f1_macro',\n 'f1_micro',\n 'f1_samples',\n 'f1_weighted',\n 'fowlkes_mallows_score',\n 'homogeneity_score',\n 'jaccard',\n 'jaccard_macro',\n 'jaccard_micro',\n 'jaccard_samples',\n 'jaccard_weighted',\n 'matthews_corrcoef',\n 'max_error',\n 'mutual_info_score',\n 'neg_brier_score',\n 'neg_log_loss',\n 'neg_mean_absolute_error',\n 'neg_mean_absolute_percentage_error',\n 'neg_mean_gamma_deviance',\n 'neg_mean_poisson_deviance',\n 'neg_mean_squared_error',\n 'neg_mean_squared_log_error',\n 'neg_median_absolute_error',\n 'neg_root_mean_squared_error',\n 'normalized_mutual_info_score',\n 'precision',\n 'precision_macro',\n 'precision_micro',\n 'precision_samples',\n 'precision_weighted',\n 'r2',\n 'rand_score',\n 'recall',\n 'recall_macro',\n 'recall_micro',\n 'recall_samples',\n 'recall_weighted',\n 'roc_auc',\n 'roc_auc_ovo',\n 'roc_auc_ovo_weighted',\n 'roc_auc_ovr',\n 'roc_auc_ovr_weighted',\n 'top_k_accuracy',\n 'v_measure_score']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.get_scorer_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-14T17:50:33.964255Z",
     "iopub.status.busy": "2022-11-14T17:50:33.964037Z",
     "iopub.status.idle": "2022-11-14T17:50:33.967099Z",
     "shell.execute_reply": "2022-11-14T17:50:33.966505Z",
     "shell.execute_reply.started": "2022-11-14T17:50:33.964230Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# SKIP %timeit starter_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-14T17:55:40.014530Z",
     "iopub.status.busy": "2022-11-14T17:55:40.013696Z",
     "iopub.status.idle": "2022-11-14T17:55:40.021215Z",
     "shell.execute_reply": "2022-11-14T17:55:40.020667Z",
     "shell.execute_reply.started": "2022-11-14T17:55:40.014499Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "({'model__model__initializer': ['normal'],\n  'model__model__activation': ['relu'],\n  'model__optimizer': ['adam'],\n  'model__loss': ['mse'],\n  'model__verbose': [1],\n  'model__batch_size': [1000],\n  'model__epochs': [10, 20]},\n 3,\n 1,\n True,\n 2)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_block = {\n",
    "    'model__model__initializer': ['normal'], #, 'uniform'],\n",
    "    'model__model__activation': ['relu'],\n",
    "    'model__optimizer': ['adam'],\n",
    "    'model__loss': ['mse'],\n",
    "    'model__verbose':[1],\n",
    "    'model__batch_size': [64, 132] if cloud_run else [1000, 5000],\n",
    "    'model__epochs': [1000, 5000] if cloud_run else [5,10,15],\n",
    "}\n",
    "\n",
    "redundant, cv, n_jobs, refit, n_iter, verbose = get_cv_params(options_block, debug_mode=debug_mode,\n",
    "                                                                  override_cv=OVERRIDE_CV,\n",
    "                                                                  override_niter=OVERRIDE_N_ITER,\n",
    "                                                                  override_njobs=OVERRIDE_JOBS)\n",
    "\n",
    "\n",
    "def automl_step(param_options, vary):\n",
    "    for key, value in param_options.items():\n",
    "        #print(key, value, vary)\n",
    "        if key != vary and key != 'model__' + vary:\n",
    "            param_options[key] = [param_options[key][0]]\n",
    "    return param_options\n",
    "\n",
    "options_block = automl_step(options_block, \"model__epochs\")\n",
    "pipeline_search_cv = make_modelling_pipeline(KerasRegressor(make_regression_ann, verbose=1), DATA_DETAIL)\n",
    "    \n",
    "options_block, cv, n_jobs, refit, n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-14T17:57:51.055425Z",
     "iopub.status.busy": "2022-11-14T17:57:51.054863Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 2s 39ms/step - loss: 192556957696.0000\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 192393625600.0000\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 190222696448.0000\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 173310984192.0000\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 102250405888.0000\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 34887364608.0000\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 24510406656.0000\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 19941976064.0000\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 17071387648.0000\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 15116819456.0000\n",
      "14/14 [==============================] - 0s 8ms/step\n",
      "27/27 [==============================] - 0s 11ms/step\n",
      "[CV 1/3] END model__batch_size=1000, model__epochs=10, model__loss=mse, model__model__activation=relu, model__model__initializer=normal, model__optimizer=adam, model__verbose=1;, score=(train=-0.243, test=-0.378) total time=  11.8s\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 2s 41ms/step - loss: 192498876416.0000\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 192108904448.0000\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 187509587968.0000\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 157324918784.0000\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 62778191872.0000\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 21715212288.0000\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 16699215872.0000\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 14487450624.0000\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 13048116224.0000\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 12017826816.0000\n",
      "14/14 [==============================] - 0s 13ms/step\n",
      "27/27 [==============================] - 0s 13ms/step\n",
      "[CV 2/3] END model__batch_size=1000, model__epochs=10, model__loss=mse, model__model__activation=relu, model__model__initializer=normal, model__optimizer=adam, model__verbose=1;, score=(train=0.007, test=0.011) total time=  12.1s\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 2s 34ms/step - loss: 191936954368.0000\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 191175622656.0000\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 182193209344.0000\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 127853617152.0000\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 40588054528.0000\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 21004335104.0000\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 15736226816.0000\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 13585157120.0000\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 11935292416.0000\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 10884004864.0000\n",
      "14/14 [==============================] - 1s 24ms/step\n",
      "27/27 [==============================] - 1s 18ms/step\n",
      "[CV 3/3] END model__batch_size=1000, model__epochs=10, model__loss=mse, model__model__activation=relu, model__model__initializer=normal, model__optimizer=adam, model__verbose=1;, score=(train=0.085, test=0.146) total time=  11.6s\n",
      "Epoch 1/20\n",
      "27/27 [==============================] - 3s 60ms/step - loss: 192544948224.0000\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 192019890176.0000\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 185572179968.0000\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 144304357376.0000\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 52289540096.0000\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 25630203904.0000\n",
      "Epoch 7/20\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 19460085760.0000\n",
      "Epoch 8/20\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 16446879744.0000\n",
      "Epoch 9/20\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 14381702144.0000\n",
      "Epoch 10/20\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 12836954112.0000\n",
      "Epoch 11/20\n",
      "27/27 [==============================] - 2s 69ms/step - loss: 11692925952.0000\n",
      "Epoch 12/20\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 10786522112.0000\n",
      "Epoch 13/20\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 10037523456.0000\n",
      "Epoch 14/20\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 9478080512.0000\n",
      "Epoch 15/20\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 8995367936.0000\n",
      "Epoch 16/20\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 8607288320.0000\n",
      "Epoch 17/20\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 8289006080.0000\n",
      "Epoch 18/20\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 8019702272.0000\n",
      "Epoch 19/20\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 7791981568.0000\n",
      "Epoch 20/20\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 7598333952.0000\n",
      "14/14 [==============================] - 0s 12ms/step\n",
      "27/27 [==============================] - 0s 12ms/step\n",
      "[CV 1/3] END model__batch_size=1000, model__epochs=20, model__loss=mse, model__model__activation=relu, model__model__initializer=normal, model__optimizer=adam, model__verbose=1;, score=(train=0.351, test=0.351) total time=  26.0s\n",
      "Epoch 1/20\n",
      "27/27 [==============================] - 2s 45ms/step - loss: 192496205824.0000\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 192016564224.0000\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 186197458944.0000\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 150036758528.0000\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 58682667008.0000\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 27471501312.0000\n",
      "Epoch 7/20\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 19953510400.0000\n",
      "Epoch 8/20\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 16308744192.0000\n",
      "Epoch 9/20\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 14122714112.0000\n",
      "Epoch 10/20\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 12626194432.0000\n",
      "Epoch 11/20\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 11548756992.0000\n",
      "Epoch 12/20\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 10751526912.0000\n",
      "Epoch 13/20\n",
      "27/27 [==============================] - 2s 75ms/step - loss: 10110796800.0000\n",
      "Epoch 14/20\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 9604541440.0000\n",
      "Epoch 15/20\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 9179270144.0000\n",
      "Epoch 16/20\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 8820152320.0000\n",
      "Epoch 17/20\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 8517180928.0000\n",
      "Epoch 18/20\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 8261730816.0000\n",
      "Epoch 19/20\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 8042417152.0000\n",
      "Epoch 20/20\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 7858304512.0000\n",
      "14/14 [==============================] - 0s 14ms/step\n",
      "27/27 [==============================] - 0s 8ms/step\n",
      "[CV 2/3] END model__batch_size=1000, model__epochs=20, model__loss=mse, model__model__activation=relu, model__model__initializer=normal, model__optimizer=adam, model__verbose=1;, score=(train=0.327, test=0.324) total time=  42.8s\n",
      "Epoch 1/20\n",
      "27/27 [==============================] - 2s 42ms/step - loss: 191953764352.0000\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 191680544768.0000\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 188036136960.0000\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 161587970048.0000\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 72774123520.0000\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 25012994048.0000\n",
      "Epoch 7/20\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 16998034432.0000\n",
      "Epoch 8/20\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 14138003456.0000\n",
      "Epoch 9/20\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 12353929216.0000\n",
      "Epoch 10/20\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 11133142016.0000\n",
      "Epoch 11/20\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 10284130304.0000\n",
      "Epoch 12/20\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 9653081088.0000\n",
      "Epoch 13/20\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 9175333888.0000\n",
      "Epoch 14/20\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 8793890816.0000\n",
      "Epoch 15/20\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 8488762368.0000\n",
      "Epoch 16/20\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 8229746688.0000\n",
      "Epoch 17/20\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 8006245376.0000\n",
      "Epoch 18/20\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 7809506816.0000\n",
      "Epoch 19/20\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 7637604352.0000\n",
      "Epoch 20/20\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 7481244160.0000\n",
      "14/14 [==============================] - 0s 11ms/step\n",
      "27/27 [==============================] - 0s 12ms/step\n",
      "[CV 3/3] END model__batch_size=1000, model__epochs=20, model__loss=mse, model__model__activation=relu, model__model__initializer=normal, model__optimizer=adam, model__verbose=1;, score=(train=0.354, test=0.348) total time=  22.0s\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 2s 31ms/step - loss: 192264978432.0000\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 186536640512.0000\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 106172121088.0000\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 24922877952.0000\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 18140608512.0000\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 14722328576.0000\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 12565715968.0000\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 11047649280.0000\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 2s 56ms/step - loss: 9954945024.0000\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 9160145920.0000\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 8607211520.0000\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 8099789312.0000\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 7758190592.0000\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 7484791296.0000\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 7257335808.0000\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 7079501312.0000\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 6917203456.0000\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 6785681920.0000\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 6669108736.0000\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 6569989120.0000\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 2s 29ms/step - loss: 192557056000.0000\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 192385466368.0000\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 190071078912.0000\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 172807667712.0000\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 100654481408.0000\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 28464951296.0000\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 20996902912.0000\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 16887681024.0000\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 14484774912.0000\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 13099623424.0000\n",
      "14/14 [==============================] - 0s 10ms/step\n",
      "27/27 [==============================] - 0s 16ms/step\n",
      "[CV 1/3] END model__batch_size=1000, model__epochs=10, model__loss=mse, model__model__activation=relu, model__model__initializer=normal, model__optimizer=adam, model__verbose=1;, score=(train=-0.093, test=-0.329) total time=  10.4s\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 2s 36ms/step - loss: 192502792192.0000\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 192216793088.0000\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 1s 56ms/step - loss: 188342976512.0000\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 159375720448.0000\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 70772441088.0000\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 31390697472.0000\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 19974627328.0000\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 15612495872.0000\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 13421019136.0000\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 12283183104.0000\n",
      "14/14 [==============================] - 0s 10ms/step\n",
      "27/27 [==============================] - 0s 11ms/step\n",
      "[CV 2/3] END model__batch_size=1000, model__epochs=10, model__loss=mse, model__model__activation=relu, model__model__initializer=normal, model__optimizer=adam, model__verbose=1;, score=(train=-0.023, test=-0.021) total time=  12.2s\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 191961382912.0000\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 191961382912.0000\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 191961366528.0000\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 191961317376.0000\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 191961300992.0000\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 1s 32ms/step - loss: 191961300992.0000\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 191961268224.0000\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 191961235456.0000\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 191961219072.0000\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 1s 28ms/step - loss: 191961186304.0000\n",
      "14/14 [==============================] - 0s 9ms/step\n",
      "27/27 [==============================] - 0s 11ms/step\n",
      "[CV 3/3] END model__batch_size=1000, model__epochs=10, model__loss=mse, model__model__activation=relu, model__model__initializer=normal, model__optimizer=adam, model__verbose=1;, score=(train=-15.750, test=-15.618) total time=  10.0s\n",
      "Epoch 1/20\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 192549093376.0000\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 192163037184.0000\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 187776237568.0000\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 160204472320.0000\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 74791665664.0000\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 23959019520.0000\n",
      "Epoch 7/20\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 18135304192.0000\n",
      "Epoch 8/20\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 15413366784.0000\n",
      "Epoch 9/20\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 13538857984.0000\n",
      "Epoch 10/20\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 12251184128.0000\n",
      "Epoch 11/20\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 11247036416.0000\n",
      "Epoch 12/20\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 10486690816.0000\n",
      "Epoch 13/20\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 9872683008.0000\n",
      "Epoch 14/20\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 9386615808.0000\n",
      "Epoch 15/20\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 8983884800.0000\n",
      "Epoch 16/20\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 8662769664.0000\n",
      "Epoch 17/20\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 8381871616.0000\n",
      "Epoch 18/20\n",
      "27/27 [==============================] - 2s 75ms/step - loss: 8130610688.0000\n",
      "Epoch 19/20\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 7930703360.0000\n",
      "Epoch 20/20\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 7743301632.0000\n",
      "14/14 [==============================] - 0s 12ms/step\n",
      "27/27 [==============================] - 0s 14ms/step\n",
      "[CV 1/3] END model__batch_size=1000, model__epochs=20, model__loss=mse, model__model__activation=relu, model__model__initializer=normal, model__optimizer=adam, model__verbose=1;, score=(train=0.337, test=0.328) total time=  25.1s\n",
      "Epoch 1/20\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 192509149184.0000\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 192439926784.0000\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 191398412288.0000\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 182488154112.0000\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 135902396416.0000\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 41534480384.0000\n",
      "Epoch 7/20\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 16190882816.0000\n",
      "Epoch 8/20\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 12301977600.0000\n",
      "Epoch 9/20\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 10888642560.0000\n",
      "Epoch 10/20\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 10049068032.0000\n",
      "Epoch 11/20\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 9469133824.0000\n",
      "Epoch 12/20\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 9012158464.0000\n",
      "Epoch 13/20\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 8654990336.0000\n",
      "Epoch 14/20\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 8375920640.0000\n",
      "Epoch 15/20\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 8129462272.0000\n",
      "Epoch 16/20\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 7934356480.0000\n",
      "Epoch 17/20\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 7769189888.0000\n",
      "Epoch 18/20\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 7617581568.0000\n",
      "Epoch 19/20\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 7476294656.0000\n",
      "Epoch 20/20\n",
      "27/27 [==============================] - 1s 37ms/step - loss: 7353065472.0000\n",
      "14/14 [==============================] - 0s 14ms/step\n",
      "27/27 [==============================] - 0s 14ms/step\n",
      "[CV 2/3] END model__batch_size=1000, model__epochs=20, model__loss=mse, model__model__activation=relu, model__model__initializer=normal, model__optimizer=adam, model__verbose=1;, score=(train=0.368, test=0.363) total time=  23.7s\n",
      "Epoch 1/20\n",
      "27/27 [==============================] - 2s 47ms/step - loss: 191947669504.0000\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 191532826624.0000\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 186752319488.0000\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 1s 34ms/step - loss: 156250128384.0000\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 65466802176.0000\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 20622073856.0000\n",
      "Epoch 7/20\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 14597873664.0000\n",
      "Epoch 8/20\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 12804288512.0000\n",
      "Epoch 9/20\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 11778839552.0000\n",
      "Epoch 10/20\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 10989946880.0000\n",
      "Epoch 11/20\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 10401608704.0000\n",
      "Epoch 12/20\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 9886093312.0000\n",
      "Epoch 13/20\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 9463365632.0000\n",
      "Epoch 14/20\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 9095256064.0000\n",
      "Epoch 15/20\n",
      "27/27 [==============================] - 1s 39ms/step - loss: 8772860928.0000\n",
      "Epoch 16/20\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 8484348928.0000\n",
      "Epoch 17/20\n",
      "27/27 [==============================] - 1s 33ms/step - loss: 8230455296.0000\n",
      "Epoch 18/20\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 8002419200.0000\n",
      "Epoch 19/20\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 7802054144.0000\n",
      "Epoch 20/20\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 7620695552.0000\n",
      "14/14 [==============================] - 0s 15ms/step\n",
      "27/27 [==============================] - 0s 15ms/step\n",
      "[CV 3/3] END model__batch_size=1000, model__epochs=20, model__loss=mse, model__model__activation=relu, model__model__initializer=normal, model__optimizer=adam, model__verbose=1;, score=(train=0.342, test=0.335) total time=  23.3s\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 192344752128.0000\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 192344735744.0000\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 192344702976.0000\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 192344653824.0000\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 192344621056.0000\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 192344588288.0000\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 192344522752.0000\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 192344489984.0000\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 192344489984.0000\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 192344440832.0000\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 192344391680.0000\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 1s 30ms/step - loss: 192344358912.0000\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 192344326144.0000\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 192344342528.0000\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 192344260608.0000\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 192344227840.0000\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 192344211456.0000\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 1s 32ms/step - loss: 192344211456.0000\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 192344129536.0000\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 1s 33ms/step - loss: 192344129536.0000\n",
      "Total fit/CV time      : 300 seconds   (1668462841.8783722 ==> 1668463142.2481728)\n",
      "\n",
      "average fit/score time = 17.02s/0.42s\n",
      "max fit/score time     = 23.55s/0.49s\n",
      "refit time             = 29.93s\n"
     ]
    }
   ],
   "source": [
    "def fit_model_with_cross_validation(gs, X_train, y_train, fits):\n",
    "    pipe_start = time()\n",
    "    cv_result = gs.fit(X_train, y_train)\n",
    "    gs.fit(X_train, y_train)\n",
    "    pipe_end = time()\n",
    "    average_time = round((pipe_end - pipe_start) / (fits), 2)\n",
    "\n",
    "    print(f\"Total fit/CV time      : {int(pipe_end - pipe_start)} seconds   ({pipe_start} ==> {pipe_end})\")\n",
    "    print()\n",
    "    print(\n",
    "        f'average fit/score time = {round(cv_result.cv_results_[\"mean_fit_time\"].mean(), 2)}s/{round(cv_result.cv_results_[\"mean_score_time\"].mean(), 2)}s')\n",
    "    print(\n",
    "        f'max fit/score time     = {round(cv_result.cv_results_[\"mean_fit_time\"].max(), 2)}s/{round(cv_result.cv_results_[\"mean_score_time\"].max(), 2)}s')\n",
    "    print(f'refit time             = {round(cv_result.refit_time_, 2)}s')\n",
    "\n",
    "    #return cv_result, average_time, cv_result.refit_time_, len(cv_result.cv_results_[\"mean_fit_time\"])\n",
    "    return average_time, cv_result.refit_time_, len(cv_result.cv_results_[\"mean_fit_time\"])\n",
    "\n",
    "\n",
    "crossval_runner = GridSearchCV(\n",
    "    estimator=pipeline_search_cv,\n",
    "    param_grid=options_block,\n",
    "    cv=cv, n_jobs=n_jobs, # get the AVX/AVX2 info if use n_jobs > 2\n",
    "    verbose=5, scoring=CROSS_VALIDATION_SCORING,\n",
    "    refit=refit,\n",
    "    return_train_score=True, #n_iter=n_iter,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "cv_average_fit_time, cv_best_model_fit_time, total_fits = fit_model_with_cross_validation(\n",
    "    crossval_runner, X_train, y_train, fits=cv * n_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'model__batch_size': 1000,\n 'model__epochs': 20,\n 'model__loss': 'mse',\n 'model__model__activation': 'relu',\n 'model__model__initializer': 'normal',\n 'model__optimizer': 'adam',\n 'model__verbose': 1}"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossval_runner.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "best_estimator_pipe = crossval_runner.best_estimator_\n",
    "\n",
    "if debug_mode:\n",
    "    crossval_runner.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                          params2  rank_test_score  mean_test_score  \\\n0  1000/20/mse/relu/normal/adam/1                1         0.342380   \n1  1000/10/mse/relu/normal/adam/1                2        -5.322623   \n\n   mean_fit_time  mean_score_time  \\\n0      23.549170         0.485042   \n1      10.490758         0.360912   \n\n                                              params  \n0  {'model__batch_size': 1000, 'model__epochs': 2...  \n1  {'model__batch_size': 1000, 'model__epochs': 1...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params2</th>\n      <th>rank_test_score</th>\n      <th>mean_test_score</th>\n      <th>mean_fit_time</th>\n      <th>mean_score_time</th>\n      <th>params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000/20/mse/relu/normal/adam/1</td>\n      <td>1</td>\n      <td>0.342380</td>\n      <td>23.549170</td>\n      <td>0.485042</td>\n      <td>{'model__batch_size': 1000, 'model__epochs': 2...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000/10/mse/relu/normal/adam/1</td>\n      <td>2</td>\n      <td>-5.322623</td>\n      <td>10.490758</td>\n      <td>0.360912</td>\n      <td>{'model__batch_size': 1000, 'model__epochs': 1...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_df = pd.DataFrame(crossval_runner.cv_results_)\n",
    "\n",
    "cv_results_df['params2'] = cv_results_df['params'].apply(lambda l: '/'.join([str(c) for c in l.values()]))\n",
    "\n",
    "cv_columns = ['params2', 'rank_test_score', 'mean_test_score', 'mean_fit_time', 'mean_score_time','params']\n",
    "# if 'Neural' not in ALGORITHM:\n",
    "#     cv_columns.insert(2, 'mean_train_score')\n",
    "\n",
    "cv_results_df_sorted = cv_results_df.sort_values('rank_test_score')[cv_columns].reset_index(drop=True)\n",
    "cv_results_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def print_results(cross_validation_result):\n",
    "    means = cross_validation_result.cv_results_['mean_test_score']\n",
    "    stds = cross_validation_result.cv_results_['std_test_score']\n",
    "    params = cross_validation_result.cv_results_['params']\n",
    "    times = cross_validation_result.cv_results_['std_test_score']\n",
    "\n",
    "    print(\"params:\" + \"/\".join([c.replace(\"model__\", \"\") for c in params[0].keys()]))\n",
    "    print()\n",
    "    for mean, std, param, time in zip(means, stds, params, times):\n",
    "        #param2 = \"/\".join(list(param.values()))\n",
    "        param2 = \"/\".join(list([str(c) for c in param.values()]))\n",
    "        print(f'{round(mean, 3)} (+/-{round(std * 2, 3)}) in {round(time, 4)}s for {param2}')\n",
    "\n",
    "\n",
    "if debug_mode:\n",
    "    print_results(crossval_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Index:  1\n",
      "Best Score:  0.3423797211301995\n",
      "Best Params:  {'model__batch_size': 1000, 'model__epochs': 20, 'model__loss': 'mse', 'model__model__activation': 'relu', 'model__model__initializer': 'normal', 'model__optimizer': 'adam', 'model__verbose': 1}\n"
     ]
    }
   ],
   "source": [
    "print('Best Index: ', crossval_runner.best_index_)\n",
    "print('Best Score: ', crossval_runner.best_score_)\n",
    "print('Best Params: ', crossval_runner.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_estimator_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Neural Network----------\n",
      "R square Accuracy -15.994729649667892\n",
      "Mean Absolute Error Accuracy 425068.1757622057\n",
      "Mean Squared Error Accuracy 191979359674.61978\n",
      "Root Mean Squared Error 438154.49292985664\n"
     ]
    }
   ],
   "source": [
    "y_pred = y_pred.reshape((-1, 1))\n",
    "\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = math.sqrt(MSE)\n",
    "print('-' * 10 + ALGORITHM + '-' * 10)\n",
    "print('R square Accuracy', R2)\n",
    "print('Mean Absolute Error Accuracy', MAE)\n",
    "print('Mean Squared Error Accuracy', MSE)\n",
    "print('Root Mean Squared Error', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    print(y_test_index.reshape((-1, 1)).shape);\n",
    "    print(y_pred.reshape((-1, 1)).shape);\n",
    "    print(y_test.shape);\n",
    "    print(y_test_index.shape);\n",
    "    print(y_pred.shape);\n",
    "    print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "             actual  predicted     difference   diff 1 %      diff 2 %\nreference                                                             \n85490754   400000.0   0.799991  399999.200009  99.999800  5.000045e+07\n119328242  369950.0   0.799991  369949.200009  99.999784  4.624416e+07\n125716790  350000.0   0.799991  349999.200009  99.999771  4.375038e+07\n122440040  549000.0   0.799991  548999.200009  99.999854  6.862565e+07\n120508103  495000.0   0.799991  494999.200009  99.999838  6.187558e+07\n...             ...        ...            ...        ...           ...\n68620869   475000.0   0.799991  474999.200009  99.999832  5.937555e+07\n85735665   575000.0   0.799991  574999.200009  99.999861  7.187569e+07\n125706338  400000.0   0.799991  399999.200009  99.999800  5.000045e+07\n112739354  450000.0   0.799991  449999.200009  99.999822  5.625052e+07\n122707001  275000.0   0.799991  274999.200009  99.999709  3.437528e+07\n\n[4413 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>actual</th>\n      <th>predicted</th>\n      <th>difference</th>\n      <th>diff 1 %</th>\n      <th>diff 2 %</th>\n    </tr>\n    <tr>\n      <th>reference</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>85490754</th>\n      <td>400000.0</td>\n      <td>0.799991</td>\n      <td>399999.200009</td>\n      <td>99.999800</td>\n      <td>5.000045e+07</td>\n    </tr>\n    <tr>\n      <th>119328242</th>\n      <td>369950.0</td>\n      <td>0.799991</td>\n      <td>369949.200009</td>\n      <td>99.999784</td>\n      <td>4.624416e+07</td>\n    </tr>\n    <tr>\n      <th>125716790</th>\n      <td>350000.0</td>\n      <td>0.799991</td>\n      <td>349999.200009</td>\n      <td>99.999771</td>\n      <td>4.375038e+07</td>\n    </tr>\n    <tr>\n      <th>122440040</th>\n      <td>549000.0</td>\n      <td>0.799991</td>\n      <td>548999.200009</td>\n      <td>99.999854</td>\n      <td>6.862565e+07</td>\n    </tr>\n    <tr>\n      <th>120508103</th>\n      <td>495000.0</td>\n      <td>0.799991</td>\n      <td>494999.200009</td>\n      <td>99.999838</td>\n      <td>6.187558e+07</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>68620869</th>\n      <td>475000.0</td>\n      <td>0.799991</td>\n      <td>474999.200009</td>\n      <td>99.999832</td>\n      <td>5.937555e+07</td>\n    </tr>\n    <tr>\n      <th>85735665</th>\n      <td>575000.0</td>\n      <td>0.799991</td>\n      <td>574999.200009</td>\n      <td>99.999861</td>\n      <td>7.187569e+07</td>\n    </tr>\n    <tr>\n      <th>125706338</th>\n      <td>400000.0</td>\n      <td>0.799991</td>\n      <td>399999.200009</td>\n      <td>99.999800</td>\n      <td>5.000045e+07</td>\n    </tr>\n    <tr>\n      <th>112739354</th>\n      <td>450000.0</td>\n      <td>0.799991</td>\n      <td>449999.200009</td>\n      <td>99.999822</td>\n      <td>5.625052e+07</td>\n    </tr>\n    <tr>\n      <th>122707001</th>\n      <td>275000.0</td>\n      <td>0.799991</td>\n      <td>274999.200009</td>\n      <td>99.999709</td>\n      <td>3.437528e+07</td>\n    </tr>\n  </tbody>\n</table>\n<p>4413 rows  5 columns</p>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = np.hstack((y_test_index, y_test, y_pred))\n",
    "compare_df = DataFrame(compare, columns=['reference', 'actual', 'predicted'])\n",
    "compare_df['difference'] = abs(compare_df['actual'] - compare_df['predicted'])\n",
    "compare_df['diff 1 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['actual'] * 100)\n",
    "compare_df['diff 2 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['predicted']) * 100\n",
    "compare_df['reference'] = compare_df['reference'].astype(int)\n",
    "compare_df.set_index('reference', inplace=True)\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "           actual  predicted     difference   diff 1 %      diff 2 %   Price  \\\n126010535  600000          0  599999.200009  99.999867  7.500072e+07  600000   \n123142541  600000          0  599999.200009  99.999867  7.500072e+07  600000   \n124261850  600000          0  599999.200009  99.999867  7.500072e+07  600000   \n96642211   600000          0  599999.200009  99.999867  7.500072e+07  600000   \n122484119  600000          0  599999.200009  99.999867  7.500072e+07  600000   \n...           ...        ...            ...        ...           ...     ...   \n120334940  170000          0  169999.200009  99.999529  2.125013e+07  170000   \n85626486   165000          0  164999.200009  99.999515  2.062513e+07  165000   \n122265818  160000          0  159999.200009  99.999500  2.000012e+07  160000   \n85667184   122000          0  121999.200009  99.999344  1.525007e+07  122000   \n109722224  108000          0  107999.200009  99.999259  1.350005e+07  108000   \n\n           bedrooms  bathrooms  nearestStation  location.latitude  \\\n126010535         2          2        0.161803          51.498310   \n123142541         3          1        0.489043          51.458232   \n124261850         3          1        0.086917          51.445241   \n96642211          4          2        0.322629          51.423443   \n122484119         2          1        0.336476          51.591028   \n...             ...        ...             ...                ...   \n120334940         1          1        1.122157          51.443746   \n85626486          1          1        0.357113          51.390834   \n122265818         3          1        0.166024          51.510420   \n85667184          1          1        0.838896          51.540462   \n109722224         1          1        0.302667          51.406803   \n\n           location.longitude  latitude_deviation  longitude_deviation  \\\n126010535           -0.018230            0.001410             0.086190   \n123142541           -0.199814            0.041488             0.095394   \n124261850           -0.027952            0.054479             0.076468   \n96642211            -0.008986            0.076277             0.095434   \n122484119           -0.159937            0.091308             0.055517   \n...                       ...                 ...                  ...   \n120334940           -0.382156            0.055974             0.277736   \n85626486            -0.071057            0.108886             0.033363   \n122265818           -0.037730            0.010700             0.066690   \n85667184            -0.280301            0.040742             0.175881   \n109722224           -0.261328            0.092917             0.156908   \n\n          tenure.tenureType  \n126010535         LEASEHOLD  \n123142541         LEASEHOLD  \n124261850          FREEHOLD  \n96642211           FREEHOLD  \n122484119         LEASEHOLD  \n...                     ...  \n120334940         LEASEHOLD  \n85626486          LEASEHOLD  \n122265818          FREEHOLD  \n85667184          LEASEHOLD  \n109722224         LEASEHOLD  \n\n[4413 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>actual</th>\n      <th>predicted</th>\n      <th>difference</th>\n      <th>diff 1 %</th>\n      <th>diff 2 %</th>\n      <th>Price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n      <th>location.latitude</th>\n      <th>location.longitude</th>\n      <th>latitude_deviation</th>\n      <th>longitude_deviation</th>\n      <th>tenure.tenureType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>126010535</th>\n      <td>600000</td>\n      <td>0</td>\n      <td>599999.200009</td>\n      <td>99.999867</td>\n      <td>7.500072e+07</td>\n      <td>600000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.161803</td>\n      <td>51.498310</td>\n      <td>-0.018230</td>\n      <td>0.001410</td>\n      <td>0.086190</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>123142541</th>\n      <td>600000</td>\n      <td>0</td>\n      <td>599999.200009</td>\n      <td>99.999867</td>\n      <td>7.500072e+07</td>\n      <td>600000</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.489043</td>\n      <td>51.458232</td>\n      <td>-0.199814</td>\n      <td>0.041488</td>\n      <td>0.095394</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>124261850</th>\n      <td>600000</td>\n      <td>0</td>\n      <td>599999.200009</td>\n      <td>99.999867</td>\n      <td>7.500072e+07</td>\n      <td>600000</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.086917</td>\n      <td>51.445241</td>\n      <td>-0.027952</td>\n      <td>0.054479</td>\n      <td>0.076468</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>96642211</th>\n      <td>600000</td>\n      <td>0</td>\n      <td>599999.200009</td>\n      <td>99.999867</td>\n      <td>7.500072e+07</td>\n      <td>600000</td>\n      <td>4</td>\n      <td>2</td>\n      <td>0.322629</td>\n      <td>51.423443</td>\n      <td>-0.008986</td>\n      <td>0.076277</td>\n      <td>0.095434</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>122484119</th>\n      <td>600000</td>\n      <td>0</td>\n      <td>599999.200009</td>\n      <td>99.999867</td>\n      <td>7.500072e+07</td>\n      <td>600000</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0.336476</td>\n      <td>51.591028</td>\n      <td>-0.159937</td>\n      <td>0.091308</td>\n      <td>0.055517</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>120334940</th>\n      <td>170000</td>\n      <td>0</td>\n      <td>169999.200009</td>\n      <td>99.999529</td>\n      <td>2.125013e+07</td>\n      <td>170000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.122157</td>\n      <td>51.443746</td>\n      <td>-0.382156</td>\n      <td>0.055974</td>\n      <td>0.277736</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>85626486</th>\n      <td>165000</td>\n      <td>0</td>\n      <td>164999.200009</td>\n      <td>99.999515</td>\n      <td>2.062513e+07</td>\n      <td>165000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.357113</td>\n      <td>51.390834</td>\n      <td>-0.071057</td>\n      <td>0.108886</td>\n      <td>0.033363</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>122265818</th>\n      <td>160000</td>\n      <td>0</td>\n      <td>159999.200009</td>\n      <td>99.999500</td>\n      <td>2.000012e+07</td>\n      <td>160000</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.166024</td>\n      <td>51.510420</td>\n      <td>-0.037730</td>\n      <td>0.010700</td>\n      <td>0.066690</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>85667184</th>\n      <td>122000</td>\n      <td>0</td>\n      <td>121999.200009</td>\n      <td>99.999344</td>\n      <td>1.525007e+07</td>\n      <td>122000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.838896</td>\n      <td>51.540462</td>\n      <td>-0.280301</td>\n      <td>0.040742</td>\n      <td>0.175881</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>109722224</th>\n      <td>108000</td>\n      <td>0</td>\n      <td>107999.200009</td>\n      <td>99.999259</td>\n      <td>1.350005e+07</td>\n      <td>108000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.302667</td>\n      <td>51.406803</td>\n      <td>-0.261328</td>\n      <td>0.092917</td>\n      <td>0.156908</td>\n      <td>LEASEHOLD</td>\n    </tr>\n  </tbody>\n</table>\n<p>4413 rows  14 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = compare_df.merge(df[columns], how='inner', left_index=True, right_index=True).sort_values(['diff 1 %'], ascending=False)\n",
    "#pd.options.display.float_format = '{:.4f}'.format\n",
    "combined[['predicted','actual','Price','bedrooms','bathrooms']] = combined[['predicted','actual','Price','bedrooms','bathrooms']].astype(int)\n",
    "combined['bedrooms'] = combined['bedrooms'].astype(int)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "-15.994729649667892"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = best_estimator_pipe.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-15.994729649667892"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, best_estimator_pipe.predict(X_test), edgecolors=(0, 0, 1))\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_xlabel('Actual')\n",
    "#ax.title.set_text(f'CV Chosen best option ({calculated_best_pipe[1]})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "range() arg 3 must not be zero",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [48], line 17\u001B[0m\n\u001B[1;32m     14\u001B[0m best_model_scores \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     16\u001B[0m showable_increment \u001B[38;5;241m=\u001B[39m total_fits \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m4\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m quick_mode \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, total_fits, showable_increment):\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m debug_mode \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m: \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ==> \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[0;31mValueError\u001B[0m: range() arg 3 must not be zero"
     ]
    }
   ],
   "source": [
    "def custom_model_and_predictions(model, graph_params, X_train, y_train, X_test):\n",
    "    graph_model = model\n",
    "    graph_model.set_params(**graph_params)\n",
    "    graph_model.fit(X_train, y_train)\n",
    "    y_pred_graph = model.predict(X_test)\n",
    "\n",
    "    return model, y_pred_graph\n",
    "\n",
    "\n",
    "best_model_count = 10 if not quick_mode else 2\n",
    "best_model_count = 3 if not quick_mode else 1\n",
    "best_models = {}\n",
    "best_model_predictions = {}\n",
    "best_model_scores = {}\n",
    "\n",
    "showable_increment = total_fits // 4 if not quick_mode else 2\n",
    "for i in range(0, total_fits, showable_increment):\n",
    "    if debug_mode or True: print(f'{i} ==> {i}')\n",
    "\n",
    "    if i == 0:\n",
    "        fitted_graph_model = crossval_runner.best_estimator_\n",
    "        y_pred_graph = y_pred\n",
    "    else:\n",
    "        graph_pipe_params = cv_results_df_sorted['params'][i]\n",
    "        print (graph_pipe_params)\n",
    "        # would always return the best! graph_pipe_params = cv_results_df_sorted.loc[cv_results_df_sorted['rank_test_score'] == 1, 'params'].values[0]\n",
    "\n",
    "        graph_params = {}\n",
    "        for key, value in graph_pipe_params.items():\n",
    "            graph_params[key.replace('model__', '')] = value\n",
    "\n",
    "        fitted_graph_model, y_pred_graph = custom_model_and_predictions(starter_pipe, graph_pipe_params, X_train,\n",
    "                                                                        y_train, X_test)\n",
    "\n",
    "    best_models[i] = fitted_graph_model[-1].get_params()\n",
    "    best_model_predictions[i] = y_pred_graph\n",
    "    best_model_scores[i] = fitted_graph_model.score(X_test, y_test)\n",
    "\n",
    "if debug_mode or True: print(f'{-1} ==> {-1}')\n",
    "graph_pipe_params = cv_results_df_sorted['params'][total_fits - 1]\n",
    "print (graph_pipe_params)\n",
    "graph_params = {}\n",
    "for key, value in graph_pipe_params.items():\n",
    "    graph_params[key.replace('model__', '')] = value\n",
    "fitted_graph_model, y_pred_graph = custom_model_and_predictions(starter_pipe, graph_pipe_params, X_train,\n",
    "                                                                y_train, X_test)\n",
    "best_models[-1] = fitted_graph_model[-1].get_params()\n",
    "best_model_predictions[-1] = y_pred_graph\n",
    "best_model_scores[-1] = fitted_graph_model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                          params2  rank_test_score  mean_test_score  \\\n0  1000/20/mse/relu/normal/adam/1                1         0.342380   \n1  1000/10/mse/relu/normal/adam/1                2        -5.322623   \n\n   mean_fit_time  mean_score_time  \\\n0      23.549170         0.485042   \n1      10.490758         0.360912   \n\n                                              params  \n0  {'model__batch_size': 1000, 'model__epochs': 2...  \n1  {'model__batch_size': 1000, 'model__epochs': 1...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params2</th>\n      <th>rank_test_score</th>\n      <th>mean_test_score</th>\n      <th>mean_fit_time</th>\n      <th>mean_score_time</th>\n      <th>params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000/20/mse/relu/normal/adam/1</td>\n      <td>1</td>\n      <td>0.342380</td>\n      <td>23.549170</td>\n      <td>0.485042</td>\n      <td>{'model__batch_size': 1000, 'model__epochs': 2...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000/10/mse/relu/normal/adam/1</td>\n      <td>2</td>\n      <td>-5.322623</td>\n      <td>10.490758</td>\n      <td>0.360912</td>\n      <td>{'model__batch_size': 1000, 'model__epochs': 1...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    {'model__batch_size': 1000, 'model__epochs': 2...\n1    {'model__batch_size': 1000, 'model__epochs': 1...\nName: params, dtype: object"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_df_sorted['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{}"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [53], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m         plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[1;32m      9\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot([y_test\u001B[38;5;241m.\u001B[39mmin(), y_test\u001B[38;5;241m.\u001B[39mmax()], [y_test\u001B[38;5;241m.\u001B[39mmin(), y_test\u001B[38;5;241m.\u001B[39mmax()], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr--\u001B[39m\u001B[38;5;124m'\u001B[39m, lw\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m plt\u001B[38;5;241m.\u001B[39mscatter(y_test, best_model_predictions[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# plt.title(str(i) + \" \" + str(round(best_model_scores[i], 4)) + \" for \" + str(best_models[i]))\u001B[39;00m\n\u001B[1;32m     12\u001B[0m plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;28mstr\u001B[39m(i) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mround\u001B[39m(best_model_scores[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], \u001B[38;5;241m4\u001B[39m)) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m for (worst) entry \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(i))\n",
      "\u001B[0;31mKeyError\u001B[0m: -1"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in best_model_scores.keys():\n",
    "    if i >= 0:\n",
    "        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "        plt.scatter(y_test, best_model_predictions[i])\n",
    "        # plt.title(str(i) + \" \" + str(round(best_model_scores[i], 4)) + \" for \" + str(best_models[i]))\n",
    "        plt.title(str(i) + \" \" + str(round(best_model_scores[i], 4)) + \" for entry \" + str(i))\n",
    "        plt.show()\n",
    "\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "plt.scatter(y_test, best_model_predictions[-1])\n",
    "# plt.title(str(i) + \" \" + str(round(best_model_scores[i], 4)) + \" for \" + str(best_models[i]))\n",
    "plt.title(str(i) + \" \" + str(round(best_model_scores[-1], 4)) + \" for (worst) entry \" + str(i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    sns.set_theme(font_scale=2, rc=None)\n",
    "    sns.set_theme(font_scale=1, rc=None)\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "    #.flatten()\n",
    "    coordinates = axes[0]\n",
    "    sns.lineplot(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], ax=axes[0], color='red')\n",
    "    sns.scatterplot(x=y_test.flatten(), y=best_model_predictions[0].flatten(), ax=axes[0],\n",
    "                    s=100).set(title=f'\"BEST\" model')\n",
    "\n",
    "    sns.lineplot(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], ax=axes[1], color='red')\n",
    "    sns.scatterplot(x=y_test.flatten(), y=best_model_predictions[-1].flatten(), ax=axes[1],\n",
    "                    s=100).set(title=f'\"WORST\" model')\n",
    "\n",
    "    sns.lineplot(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], ax=axes[2], color='red')\n",
    "    sns.scatterplot(x=y_test.flatten(), y=best_model_predictions[-1].flatten(), ax=axes[2],\n",
    "                    s=120, color='orange')\n",
    "    sns.scatterplot(x=y_test.flatten(), y=best_model_predictions[0].flatten(), ax=axes[2],\n",
    "                    s=30, alpha=0.6, color='black').set(\n",
    "        title='best (black) vs worst (orange)')\n",
    "    #title='best (orange) vs worst (black)')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cv_best_model_fit_time = cv_results_df_sorted.iloc[0][\"mean_fit_time\"]\n",
    "#cv_best_model_fit_time = cv_results_df_sorted.iloc[0][\"mean_fit_time\"]\n",
    "cv_best_model_fit_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <catboost.core.CatBoostRegressor object at 0x7fb167387490>\n",
    "# {'depth': 6}\n",
    "# defaultdict(<class 'list'>, {'iterations': [0, 1, 2],\n",
    "# 'test-RMSE-mean': [396884.9605444017, 359548.6632536235, 326027.84885587444],\n",
    "# 'test-RMSE-std': [308.9495320039113, 260.0967808594464, 219.65856329246023],\n",
    "# 'train-RMSE-mean': [396884.77936957515, 359542.3612912551, 326018.9404460669],\n",
    "# 'train-RMSE-std': [91.44140078375503, 86.77961380623475, 69.4038638987425]})\n",
    "\n",
    "cv_best_model_fit_time = cv_results_df_sorted.iloc[0][\"mean_fit_time\"] if not_catboost else 999\n",
    "\n",
    "DD2 = \"(\" + \",\".join(DATA_DETAIL) + \")\" if len(DATA_DETAIL) >= 1 else \"\"\n",
    "key = f'{ALGORITHM} - {ALGORITHM_DETAIL}{DD2} (v{VERSION})'.lower()\n",
    "\n",
    "results = {\n",
    "    '_score': score,\n",
    "    'R square Accuracy': R2,\n",
    "    'Mean Absolute Error Accuracy': MAE,\n",
    "    'Mean Squared Error Accuracy': MSE,\n",
    "    'Root Mean Squared Error': RMSE,\n",
    "    '_train time': cv_best_model_fit_time,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'date': str(datetime.now()),\n",
    "    '_params': crossval_runner.best_params_ if not_catboost else cat_params,\n",
    "    'run_env': run_env\n",
    "}\n",
    "\n",
    "if run_env not in ['colab']:\n",
    "    results_json = get_results()\n",
    "    this_model_is_best = update_results(results_json, results, key)\n",
    "\n",
    "print(key, this_model_is_best, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "crossval_runner.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if this_model_is_best:\n",
    "    with open(f'../../../models/optimised_model_{ALGORITHM}_v{VERSION}{DD2}.pkl', 'wb') as f:\n",
    "        if not_catboost:\n",
    "            pickle.dump(crossval_runner.best_estimator_, f)\n",
    "        else:\n",
    "            pickle.dump(starter_model, f)\n",
    "        print('pickled new version of model')\n",
    "        print(results_json[key]['_score'], 'is new best score')\n",
    "        #print(results_json[key]['_score'], 'is an improvement on', results_json[key]['second best score'])\n",
    "else:\n",
    "    print(\"not updated saved model, the previous run was better\")\n",
    "    print(results_json[key]['best score'], 'better than or equal to', results_json[key]['_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "feature_importances = crossval_runner.best_estimator_[-1].feature_importances_\n",
    "#std = np.std([tree.feature_importances_ for tree in model.estimators_], axis = 0)\n",
    "\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "print('Feature Ranking:')\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print('%d. features %d (%f)' % (f + 1, indices[f], feature_importances[indices[f]]),\n",
    "          df_features.columns[indices[f] + 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "feature_importances = crossval_runner.best_estimator_[-1].feature_importances_\n",
    "indices = np.argsort(feature_importances)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(range(len(feature_importances)), feature_importances[indices])\n",
    "ax.set_yticks(range(len(feature_importances)))\n",
    "_ = ax.set_yticklabels(df_features.columns[[c + 1 for c in indices]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
