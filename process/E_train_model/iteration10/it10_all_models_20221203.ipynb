{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Decide which algorithm and version of the data we are going to use for model training\n",
    "\n",
    "Additionally, choose:\n",
    "* if we'll skip scaling the data\n",
    "* if we'll use full categories instead of dummies\n",
    "* what fraction of the data we'll use for testing (0.1)\n",
    "* if the data split will be randomised (it won't!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:40.722406Z",
     "iopub.status.busy": "2022-12-02T18:52:40.721717Z",
     "iopub.status.idle": "2022-12-02T18:52:40.728296Z",
     "shell.execute_reply": "2022-12-02T18:52:40.727139Z",
     "shell.execute_reply.started": "2022-12-02T18:52:40.722380Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALGORITHM: XG Boost (tree)\n",
      "ALGORITHM_DETAIL: random search\n",
      "DATA VERSION: 06\n",
      "DATA_DETAIL: []\n"
     ]
    }
   ],
   "source": [
    "#ALGORITHM = 'Linear Regression (Ridge)'\n",
    "#ALGORITHM = 'KNN'\n",
    "#ALGORITHM = 'Decision Tree'\n",
    "#ALGORITHM = 'Random Forest'\n",
    "ALGORITHM = 'XG Boost (tree)'\n",
    "#ALGORITHM = 'CatBoost'\n",
    "#ALGORITHM = 'Light Gradient Boosting'\n",
    "\n",
    "ALGORITHM_DETAIL = 'random search'\n",
    "DATA_DETAIL = []\n",
    "#DATA_DETAIL = ['linear']\n",
    "#DATA_DETAIL = ['explore param']\n",
    "#DATA_DETAIL = ['no scale','no dummies']\n",
    "#DATA_DETAIL = ['no dummies']\n",
    "#VERSION = '06'\n",
    "VERSION = '06'\n",
    "\n",
    "RANDOM_STATE = 101\n",
    "TRAINING_SIZE = 0.9\n",
    "\n",
    "CROSS_VALIDATION_SCORING = 'r2'\n",
    "\n",
    "print(f'ALGORITHM: {ALGORITHM}')\n",
    "print(f'ALGORITHM_DETAIL: {ALGORITHM_DETAIL}')\n",
    "print(f'DATA VERSION: {VERSION}')\n",
    "print(f'DATA_DETAIL: {DATA_DETAIL}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: loading all dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:40.734752Z",
     "iopub.status.busy": "2022-12-02T18:52:40.733909Z",
     "iopub.status.idle": "2022-12-02T18:52:43.532855Z",
     "shell.execute_reply": "2022-12-02T18:52:43.531968Z",
     "shell.execute_reply.started": "2022-12-02T18:52:40.734748Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (0.9.0)\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tabulate\n",
    "\n",
    "if ALGORITHM == 'CatBoost':\n",
    "    %pip install catboost\n",
    "\n",
    "if ALGORITHM == 'Light Gradient Boosting':\n",
    "    %pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:43.534951Z",
     "iopub.status.busy": "2022-12-02T18:52:43.534676Z",
     "iopub.status.idle": "2022-12-02T18:52:43.549629Z",
     "shell.execute_reply": "2022-12-02T18:52:43.548836Z",
     "shell.execute_reply.started": "2022-12-02T18:52:43.534926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'notebook_environment': 'gradient', 'use_gpu': True, 'debug_mode': False, 'quick_mode': False, 'quick_override_cv_splits': 2, 'quick_override_n_iter': 10, 'quick_override_n_jobs': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "from termcolor import colored\n",
    "from time import time\n",
    "import sklearn\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('../../z_envs/_envs.json') as f:\n",
    "    env_vars = json.loads(f.read())\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    run_env = 'colab'\n",
    "except:\n",
    "    try:\n",
    "        run_env = env_vars['notebook_environment']\n",
    "    except:\n",
    "        run_env = 'unknown'\n",
    "\n",
    "use_gpu = env_vars.get('use_gpu', False)\n",
    "debug_mode = env_vars.get('debug_mode', False)\n",
    "quick_mode = env_vars.get('quick_mode', False)\n",
    "OVERRIDE_CV = env_vars.get('quick_override_cv_splits', None) if quick_mode else None\n",
    "OVERRIDE_N_ITER = env_vars.get('quick_override_n_iter', None) if quick_mode else None\n",
    "OVERRIDE_JOBS = env_vars.get('quick_override_n_jobs', None) if quick_mode else None\n",
    "#if quick_mode:OVERRIDE_CV, OVERRIDE_N_ITER = 2, 10\n",
    "\n",
    "already_timed = False\n",
    "no_dummies = 'no dummies' in DATA_DETAIL\n",
    "no_scaling = 'no scaling' in DATA_DETAIL\n",
    "#not_catboost = 'catboost' not in ALGORITHM.lower() or not no_dummies\n",
    "using_catboost = 'catboost' in ALGORITHM.lower()\n",
    "\n",
    "if run_env not in ['colab', 'gradient', 'cloud']:\n",
    "    cloud_run = False\n",
    "    from functions_b__get_the_data_20221116 import set_csv_directory\n",
    "    set_csv_directory('final_split')\n",
    "else:\n",
    "    cloud_run = True\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    module_path = os.path.abspath(os.path.join('..', '..', '..'))\n",
    "    if module_path not in sys.path:\n",
    "        #sys.path.append(module_path+\"\\\\zfunctions\")\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "from functions_0__common_20221116 import get_columns\n",
    "from functions_b__get_the_data_20221116 import get_combined_dataset, get_source_dataframe\n",
    "from functions_d1__prepare_cleanse_data_20221116 import tidy_dataset\n",
    "from functions_d2__transform_enrich_data_20221116 import preprocess, feature_engineer\n",
    "from functions_d3__prepare_store_data_20221116 import create_train_test_data\n",
    "from functions_e__train_model_20221116 import get_chosen_model, make_modelling_pipeline, get_cv_params, fit_model_with_cross_validation, get_hyperparameters\n",
    "from functions_f_evaluate_model_20221116 import get_best_estimator_average_time, get_results, update_results\n",
    "\n",
    "print(env_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Include any overrides specific to the algorthm / python environment being used"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:43.550784Z",
     "iopub.status.busy": "2022-12-02T18:52:43.550566Z",
     "iopub.status.idle": "2022-12-02T18:52:43.555623Z",
     "shell.execute_reply": "2022-12-02T18:52:43.554873Z",
     "shell.execute_reply.started": "2022-12-02T18:52:43.550784Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "running_locally = run_env == 'local'\n",
    "\n",
    "if 'forest' in ALGORITHM.lower():\n",
    "    #OVERRIDE_N_ITER = 5\n",
    "    if use_gpu:\n",
    "        OVERRIDE_JOBS = 8\n",
    "\n",
    "if running_locally:\n",
    "    if ALGORITHM.lower() in ['random forest','xg boost','xg boost (linear)','xg boost (tree)' ]:\n",
    "        OVERRIDE_N_ITER = 3\n",
    "    elif 'linear regression' in ALGORITHM.lower():\n",
    "        OVERRIDE_N_ITER = 15\n",
    "    else:\n",
    "        OVERRIDE_N_ITER = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: defining the model pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:43.557932Z",
     "iopub.status.busy": "2022-12-02T18:52:43.557676Z",
     "iopub.status.idle": "2022-12-02T18:52:43.567373Z",
     "shell.execute_reply": "2022-12-02T18:52:43.566457Z",
     "shell.execute_reply.started": "2022-12-02T18:52:43.557908Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('std_scaler', StandardScaler()),\n                ('model',\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=None,\n                              colsample_bytree=None, early_stopping_rounds=None,\n                              enable_categorical=False, eval_metric=None,\n                              gamma=None, gpu_id=None, grow_policy=None,\n                              importance_type=None,\n                              interaction_constraints=None, learning_rate=None,\n                              max_bin=None, max_cat_to_onehot=None,\n                              max_delta_step=None, max_depth=None,\n                              max_leaves=None, min_child_weight=None,\n                              missing=nan, monotone_constraints=None,\n                              n_estimators=100, n_jobs=None,\n                              num_parallel_tree=None, predictor=None,\n                              random_state=None, reg_alpha=None,\n                              reg_lambda=None, ...))])",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;std_scaler&#x27;, StandardScaler()),\n                (&#x27;model&#x27;,\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=None,\n                              colsample_bytree=None, early_stopping_rounds=None,\n                              enable_categorical=False, eval_metric=None,\n                              gamma=None, gpu_id=None, grow_policy=None,\n                              importance_type=None,\n                              interaction_constraints=None, learning_rate=None,\n                              max_bin=None, max_cat_to_onehot=None,\n                              max_delta_step=None, max_depth=None,\n                              max_leaves=None, min_child_weight=None,\n                              missing=nan, monotone_constraints=None,\n                              n_estimators=100, n_jobs=None,\n                              num_parallel_tree=None, predictor=None,\n                              random_state=None, reg_alpha=None,\n                              reg_lambda=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;std_scaler&#x27;, StandardScaler()),\n                (&#x27;model&#x27;,\n                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n                              colsample_bylevel=None, colsample_bynode=None,\n                              colsample_bytree=None, early_stopping_rounds=None,\n                              enable_categorical=False, eval_metric=None,\n                              gamma=None, gpu_id=None, grow_policy=None,\n                              importance_type=None,\n                              interaction_constraints=None, learning_rate=None,\n                              max_bin=None, max_cat_to_onehot=None,\n                              max_delta_step=None, max_depth=None,\n                              max_leaves=None, min_child_weight=None,\n                              missing=nan, monotone_constraints=None,\n                              n_estimators=100, n_jobs=None,\n                              num_parallel_tree=None, predictor=None,\n                              random_state=None, reg_alpha=None,\n                              reg_lambda=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, gamma=None,\n             gpu_id=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n             max_leaves=None, min_child_weight=None, missing=nan,\n             monotone_constraints=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, predictor=None, random_state=None,\n             reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "def make_pipeline():\n",
    "    return Pipeline([\n",
    "        #('mms', MinMaxScaler()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('model', get_chosen_model(ALGORITHM))\n",
    "    ])\n",
    "\n",
    "\n",
    "starter_pipe = make_pipeline()\n",
    "starter_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:43.574409Z",
     "iopub.status.busy": "2022-12-02T18:52:43.574204Z",
     "iopub.status.idle": "2022-12-02T18:52:43.581864Z",
     "shell.execute_reply": "2022-12-02T18:52:43.581172Z",
     "shell.execute_reply.started": "2022-12-02T18:52:43.574390Z"
    }
   },
   "outputs": [],
   "source": [
    "columns, booleans, floats, categories, custom, wildcard = get_columns(version=VERSION)\n",
    "LABEL = 'Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:43.582888Z",
     "iopub.status.busy": "2022-12-02T18:52:43.582689Z",
     "iopub.status.idle": "2022-12-02T18:52:43.815717Z",
     "shell.execute_reply": "2022-12-02T18:52:43.815052Z",
     "shell.execute_reply.started": "2022-12-02T18:52:43.582870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data from ../../../https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/df_listings_v06.csv\n"
     ]
    }
   ],
   "source": [
    "df, retrieval_type = get_source_dataframe(cloud_run, VERSION, folder_prefix='../../../', row_limit=None)\n",
    "df_orig = df.copy()\n",
    "\n",
    "if retrieval_type != 'tidy':\n",
    "    df = tidy_dataset(df, version=int(VERSION))\n",
    "    df = feature_engineer(df, version=int(VERSION))\n",
    "\n",
    "\n",
    "    df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:43.816867Z",
     "iopub.status.busy": "2022-12-02T18:52:43.816640Z",
     "iopub.status.idle": "2022-12-02T18:52:43.836125Z",
     "shell.execute_reply": "2022-12-02T18:52:43.835493Z",
     "shell.execute_reply.started": "2022-12-02T18:52:43.816851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mfeatures\u001B[0m ->  ['bedrooms', 'bathrooms', 'nearestStation', 'location.latitude', 'location.longitude', 'latitude_deviation', 'longitude_deviation', 'tenure.tenureType']\n",
      "\u001B[1m\u001B[32mlabel\u001B[0m ->  Price\n"
     ]
    }
   ],
   "source": [
    "print(colored(f\"features\", \"blue\"), \"-> \", columns)\n",
    "columns.insert(0, LABEL)\n",
    "print(colored(f\"label\", \"green\", None, ['bold']), \"-> \", LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:43.929127Z",
     "iopub.status.busy": "2022-12-02T18:52:43.928899Z",
     "iopub.status.idle": "2022-12-02T18:52:43.982071Z",
     "shell.execute_reply": "2022-12-02T18:52:43.981264Z",
     "shell.execute_reply.started": "2022-12-02T18:52:43.929106Z"
    }
   },
   "outputs": [],
   "source": [
    "df = preprocess(df, version=VERSION)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:43.996311Z",
     "iopub.status.busy": "2022-12-02T18:52:43.996110Z",
     "iopub.status.idle": "2022-12-02T18:52:44.042393Z",
     "shell.execute_reply": "2022-12-02T18:52:44.041707Z",
     "shell.execute_reply.started": "2022-12-02T18:52:43.996294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             Price  bedrooms  bathrooms  nearestStation  location.latitude  \\\n14520525  550000.0       3.0        1.0        0.274316          51.529950   \n27953107  400000.0       2.0        2.0        0.305845          51.549390   \n33593487  579950.0       2.0        1.0        0.438045          51.447180   \n35271294  370000.0       2.0        1.0        0.399307          51.449568   \n44749111  475000.0       2.0        1.0        0.410550          51.370050   \n\n          location.longitude  latitude_deviation  longitude_deviation  \\\n14520525           -0.207020            0.030230             0.102600   \n27953107           -0.482600            0.049670             0.378180   \n33593487           -0.338770            0.052540             0.234350   \n35271294           -0.140154            0.050152             0.035734   \n44749111           -0.212410            0.129670             0.107990   \n\n         tenure.tenureType  \n14520525         LEASEHOLD  \n27953107         LEASEHOLD  \n33593487          FREEHOLD  \n35271294         LEASEHOLD  \n44749111          FREEHOLD  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n      <th>location.latitude</th>\n      <th>location.longitude</th>\n      <th>latitude_deviation</th>\n      <th>longitude_deviation</th>\n      <th>tenure.tenureType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14520525</th>\n      <td>550000.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.274316</td>\n      <td>51.529950</td>\n      <td>-0.207020</td>\n      <td>0.030230</td>\n      <td>0.102600</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>27953107</th>\n      <td>400000.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.305845</td>\n      <td>51.549390</td>\n      <td>-0.482600</td>\n      <td>0.049670</td>\n      <td>0.378180</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>33593487</th>\n      <td>579950.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.438045</td>\n      <td>51.447180</td>\n      <td>-0.338770</td>\n      <td>0.052540</td>\n      <td>0.234350</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>35271294</th>\n      <td>370000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.399307</td>\n      <td>51.449568</td>\n      <td>-0.140154</td>\n      <td>0.050152</td>\n      <td>0.035734</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>44749111</th>\n      <td>475000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.410550</td>\n      <td>51.370050</td>\n      <td>-0.212410</td>\n      <td>0.129670</td>\n      <td>0.107990</td>\n      <td>FREEHOLD</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:44.043638Z",
     "iopub.status.busy": "2022-12-02T18:52:44.043409Z",
     "iopub.status.idle": "2022-12-02T18:52:44.078993Z",
     "shell.execute_reply": "2022-12-02T18:52:44.078270Z",
     "shell.execute_reply.started": "2022-12-02T18:52:44.043635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44127, 9)\n",
      "(39714, 11) (4413, 11) (39714, 1) (4413, 1) (39714, 1) (4413, 1) (39714, 1) (4413, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_train_index, X_test_index, y_train_index, y_test_index, df_features, df_labels = create_train_test_data(\n",
    "    df,\n",
    "    categories=categories,\n",
    "    RANDOM_STATE=RANDOM_STATE, return_index=True,\n",
    "    drop_nulls=True,\n",
    "    no_dummies=no_dummies\n",
    ")\n",
    "\n",
    "\n",
    "if 'forest' in ALGORITHM.lower() or ALGORITHM.lower()=='light gradient boosting':\n",
    "    y_train_orig = y_train\n",
    "    y_train = y_train.ravel()\n",
    "\n",
    "#print(X_train[0])\n",
    "print(df.shape)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_train_index.shape, X_test_index.shape,\n",
    "      y_train_index.shape, y_test_index.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:44.080076Z",
     "iopub.status.busy": "2022-12-02T18:52:44.079840Z",
     "iopub.status.idle": "2022-12-02T18:52:44.083337Z",
     "shell.execute_reply": "2022-12-02T18:52:44.082725Z",
     "shell.execute_reply.started": "2022-12-02T18:52:44.080054Z"
    }
   },
   "outputs": [],
   "source": [
    "#imputer = SimpleImputer(strategy='mean')\n",
    "#imputer.fit(X_train[6])\n",
    "#X_train[6] = imputer.transform(X_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:44.084452Z",
     "iopub.status.busy": "2022-12-02T18:52:44.084239Z",
     "iopub.status.idle": "2022-12-02T18:52:44.088810Z",
     "shell.execute_reply": "2022-12-02T18:52:44.088140Z",
     "shell.execute_reply.started": "2022-12-02T18:52:44.084452Z"
    }
   },
   "outputs": [],
   "source": [
    "starter_model = starter_pipe[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage:\n",
    "* #### retrieve the hyperparameters for this model, and\n",
    "* #### train the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:44.090263Z",
     "iopub.status.busy": "2022-12-02T18:52:44.089739Z",
     "iopub.status.idle": "2022-12-02T18:52:44.101239Z",
     "shell.execute_reply": "2022-12-02T18:52:44.100537Z",
     "shell.execute_reply.started": "2022-12-02T18:52:44.090250Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv: 3 n_jobs: 3 refit: True n_iter: 100 verbose: 2\n",
      "\n",
      "\n",
      "Hyperparameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'model__booster': ['gbtree', 'dart'],\n 'model__n_estimators': [100, 200, 500, 1000],\n 'model__learning_rate': [None, 0.3, 0.1, 0.01],\n 'model__lambda': [None, 1, 10, 100, 1000, 10000, 100000],\n 'model__tree_method': ['auto', 'hist'],\n 'model__max_depth': [6, 3, 8, 10],\n 'model__subsample': [1, 0.5, 0.75, 0.9],\n 'model__colsample_bytree': [1, 0.5, 0.75, 0.9],\n 'model__objective': ['reg:squarederror', 'reg:squaredlogerror'],\n 'model__n_jobs': [3],\n 'model__verbosity': [1]}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_block = get_hyperparameters(ALGORITHM, use_gpu, prefix='../../../')\n",
    "\n",
    "if 'explore param' in DATA_DETAIL:\n",
    "    def automl_step(param_options, vary):\n",
    "        for key2, value in param_options.items():\n",
    "            #print(key2, value, vary)\n",
    "            if key2 != vary and key2 != 'model__' + vary:\n",
    "                param_options[key2] = [param_options[key2][0]]\n",
    "        return param_options\n",
    "\n",
    "    #options_block = automl_step(options_block, \"model__epochs\")\n",
    "    explore_param = \"alpha\"\n",
    "    options_block = automl_step(options_block, explore_param)\n",
    "\n",
    "param_options, cv, n_jobs, refit, n_iter, verbose = get_cv_params(options_block, debug_mode=debug_mode,\n",
    "                                                                  override_cv=OVERRIDE_CV,\n",
    "                                                                  override_niter=OVERRIDE_N_ITER,\n",
    "                                                                  override_njobs=OVERRIDE_JOBS)\n",
    "\n",
    "if 'forest' in ALGORITHM.lower() or True: #JH\n",
    "    verbose = 2\n",
    "\n",
    "\n",
    "if not using_catboost and len(param_options.keys()) > 2 and not already_timed and debug_mode:\n",
    "    already_timed = True\n",
    "    %timeit starter_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"cv:\", cv, \"n_jobs:\", n_jobs, \"refit:\", refit, \"n_iter:\", n_iter, \"verbose:\", verbose)\n",
    "print('\\n\\nHyperparameters:')\n",
    "param_options if not using_catboost else options_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T18:52:44.102213Z",
     "iopub.status.busy": "2022-12-02T18:52:44.102009Z",
     "iopub.status.idle": "2022-12-02T18:54:14.356141Z",
     "shell.execute_reply": "2022-12-02T18:54:14.351545Z",
     "shell.execute_reply.started": "2022-12-02T18:52:44.102195Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "def fit_model_with_cross_validation(gs, X_train, y_train, fits):\n",
    "    pipe_start = time()\n",
    "    cv_result = gs.fit(X_train, y_train)\n",
    "    gs.fit(X_train, y_train)\n",
    "    pipe_end = time()\n",
    "    average_time = round((pipe_end - pipe_start) / (fits), 2)\n",
    "\n",
    "    print(f\"Total fit/CV time      : {int(pipe_end - pipe_start)} seconds   ({pipe_start} ==> {pipe_end})\")\n",
    "    print()\n",
    "    print(\n",
    "        f'average fit/score time = {round(cv_result.cv_results_[\"mean_fit_time\"].mean(), 2)}s/{round(cv_result.cv_results_[\"mean_score_time\"].mean(), 2)}s')\n",
    "    print(\n",
    "        f'max fit/score time     = {round(cv_result.cv_results_[\"mean_fit_time\"].max(), 2)}s/{round(cv_result.cv_results_[\"mean_score_time\"].max(), 2)}s')\n",
    "    print(f'refit time             = {round(cv_result.refit_time_, 2)}s')\n",
    "\n",
    "    #return cv_result, average_time, cv_result.refit_time_, len(cv_result.cv_results_[\"mean_fit_time\"])\n",
    "    return average_time, cv_result.refit_time_, len(cv_result.cv_results_[\"mean_fit_time\"])\n",
    "\n",
    "\n",
    "if not using_catboost:\n",
    "    if ALGORITHM_DETAIL == 'grid search':\n",
    "        crossval_runner = GridSearchCV(\n",
    "            estimator=starter_pipe,\n",
    "            param_grid=param_options,\n",
    "            cv=cv, n_jobs=n_jobs, # get the AVX/AVX2 info if use n_jobs > 2\n",
    "            verbose=verbose, scoring=CROSS_VALIDATION_SCORING,\n",
    "            refit=refit,\n",
    "            return_train_score=True, #n_iter=n_iter,\n",
    "            #error_score='raise'\n",
    "        )\n",
    "    else:\n",
    "        crossval_runner = RandomizedSearchCV(\n",
    "            estimator=starter_pipe,\n",
    "            param_distributions=param_options,\n",
    "            cv=cv, n_jobs=n_jobs,  # get the AVX/AVX2 info if use n_jobs > 2\n",
    "            verbose=verbose, scoring=CROSS_VALIDATION_SCORING,\n",
    "            refit=refit,\n",
    "            return_train_score=True,  #n_iter=n_iter,\n",
    "            n_iter=n_iter,  # 1, #3\n",
    "            #error_score='raise'\n",
    "    )\n",
    "    cv_average_fit_time, cv_best_model_fit_time, total_fits = fit_model_with_cross_validation(\n",
    "        crossval_runner, X_train, y_train, fits=cv * n_iter)\n",
    "\n",
    "else:\n",
    "    from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "    #pool = Pool(df, cat_features=['tenure.tenureType'], label=df['Price'].values)\n",
    "    pool_Xtrain = Pool(X_train, cat_features=[7], label=y_train)\n",
    "    #pool_Xtest = Pool(X_train, cat_features=[7], label=y_train)\n",
    "    pool_Xtest = Pool(X_test, cat_features=[7], label=y_test)\n",
    "    import sys\n",
    "    starter_model = model=CatBoostRegressor(iterations=3, depth=3, learning_rate=0.1, loss_function='RMSE', objective='RMSE')\n",
    "\n",
    "    output = starter_model.randomized_search(options_block, # param_options,\n",
    "                                    X=pool_Xtrain, # X_train,\n",
    "                                    #y=y_train,\n",
    "                                    #cat_features=[],\n",
    "                                    cv=5,\n",
    "                                    n_iter=100,\n",
    "                                    partition_random_seed=101,\n",
    "                                    calc_cv_statistics=True,\n",
    "                                    #search_by_train_test_split=True,\n",
    "                                    refit=True,\n",
    "                                    shuffle=True,\n",
    "                                    stratified=None,\n",
    "                                    #train_size=0.8,\n",
    "                                    #train_size=1,\n",
    "                                    verbose=True,\n",
    "                                    plot=True,\n",
    "                                    log_cout=sys.stdout,\n",
    "                                    log_cerr=sys.stderr)\n",
    "\n",
    "    cat_params, cat_cv_results = output['params'], output['cv_results']\n",
    "    crossval_runner = {\"best_params_\": cat_params, \"cv_results_\": cat_cv_results, \"best_estimator_\": None}\n",
    "crossval_runner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Get the results and print some graphs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.356888Z",
     "iopub.status.idle": "2022-12-02T18:54:14.357575Z",
     "shell.execute_reply": "2022-12-02T18:54:14.357445Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.357424Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if not using_catboost:\n",
    "    best_estimator_pipe = crossval_runner.best_estimator_\n",
    "    cv_results_df = pd.DataFrame(crossval_runner.cv_results_).sort_values('rank_test_score')\n",
    "\n",
    "    print(\"Best Params\\n\",crossval_runner.best_params_, \"\\n---------------------\")\n",
    "\n",
    "    if debug_mode:\n",
    "        print(\"CV results\\n\",crossval_runner.cv_results_, \"\\n---------------------\")\n",
    "        #print(\"Best Params\\n\",crossval_runner[\"best_params_\"], \"\\n---------------------\")\n",
    "\n",
    "else:\n",
    "    print(cat_params)\n",
    "    print(cat_cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.359538Z",
     "iopub.status.idle": "2022-12-02T18:54:14.360146Z",
     "shell.execute_reply": "2022-12-02T18:54:14.360018Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.359998Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.360811Z",
     "iopub.status.idle": "2022-12-02T18:54:14.361488Z",
     "shell.execute_reply": "2022-12-02T18:54:14.361361Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.361345Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.364634Z",
     "iopub.status.idle": "2022-12-02T18:54:14.365214Z",
     "shell.execute_reply": "2022-12-02T18:54:14.365083Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.365065Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "key = f'{ALGORITHM} (v{VERSION})'.lower()\n",
    "\n",
    "if not using_catboost:\n",
    "    cv_results_df['params2'] = cv_results_df['params'].apply(lambda l: '/'.join([str(c) for c in l.values()]))\n",
    "\n",
    "    cv_columns = ['params2', 'rank_test_score', 'mean_test_score', 'mean_fit_time', 'mean_score_time', 'params']\n",
    "    # if 'Neural' not in ALGORITHM:\n",
    "    #     cv_columns.insert(2, 'mean_train_score')\n",
    "    cv_results_df_full_sorted = cv_results_df.sort_values('rank_test_score')[cv_columns].reset_index(drop=True)\n",
    "\n",
    "    cv_results_df_sorted = cv_results_df_full_sorted[cv_results_df_full_sorted['mean_test_score'] > -2]\n",
    "    if len(cv_results_df_sorted) != len(cv_results_df_full_sorted):\n",
    "        print(-len(cv_results_df_sorted) + len(cv_results_df_full_sorted), \"fits were total failures\")\n",
    "        total_fits = len(cv_results_df_sorted)\n",
    "\n",
    "if not using_catboost:\n",
    "    display(cv_results_df_sorted)\n",
    "\n",
    "    orig_debug_mode, orig_display_df_cols = debug_mode, pd.get_option('display.max_columns')\n",
    "    debug_mode = True\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    if debug_mode:\n",
    "        debug_cols = ['rank_test_score', 'mean_test_score', 'mean_fit_time', 'mean_score_time']\n",
    "        debug_cols.extend([c for c in cv_results_df.columns if 'param' in c and c != 'params'])\n",
    "\n",
    "    cv_results_df_summary = cv_results_df[debug_cols].head(7)\n",
    "    cv_results_df_summary.set_index('rank_test_score', inplace=True)\n",
    "\n",
    "    display(cv_results_df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.368480Z",
     "iopub.status.idle": "2022-12-02T18:54:14.369053Z",
     "shell.execute_reply": "2022-12-02T18:54:14.368919Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.368903Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "<code style=\"background:blue;color:blue\">**************</code>\n",
    "\n",
    "#### Mini Stage: Make predictions\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.375227Z",
     "iopub.status.idle": "2022-12-02T18:54:14.375909Z",
     "shell.execute_reply": "2022-12-02T18:54:14.375776Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.375732Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if not using_catboost:\n",
    "    y_pred = best_estimator_pipe.predict(X_test)\n",
    "else:\n",
    "    y_pred = starter_model.predict(pool_Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.377757Z",
     "iopub.status.idle": "2022-12-02T18:54:14.378402Z",
     "shell.execute_reply": "2022-12-02T18:54:14.378279Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.378264Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = y_pred.reshape((-1, 1))\n",
    "\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = math.sqrt(MSE)\n",
    "print('-' * 10 + ALGORITHM + '-' * 10)\n",
    "print('R square Accuracy', R2)\n",
    "print('Mean Absolute Error Accuracy', MAE)\n",
    "print('Mean Squared Error Accuracy', MSE)\n",
    "print('Root Mean Squared Error', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.378988Z",
     "iopub.status.idle": "2022-12-02T18:54:14.379839Z",
     "shell.execute_reply": "2022-12-02T18:54:14.379679Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.379662Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.380443Z",
     "iopub.status.idle": "2022-12-02T18:54:14.381079Z",
     "shell.execute_reply": "2022-12-02T18:54:14.380955Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.380943Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "compare = np.hstack((y_test_index, y_test, y_pred))\n",
    "compare_df = DataFrame(compare, columns=['reference', 'actual', 'predicted'])\n",
    "compare_df['difference'] = abs(compare_df['actual'] - compare_df['predicted'])\n",
    "compare_df['diff 1 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['actual'] * 100)\n",
    "compare_df['diff 2 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['predicted']) * 100\n",
    "compare_df['reference'] = compare_df['reference'].astype(int)\n",
    "compare_df.set_index('reference', inplace=True)\n",
    "\n",
    "combined = compare_df.merge(df[columns], how='inner', left_index=True, right_index=True).sort_values(['diff 1 %'],\n",
    "                                                                                                     ascending=False)\n",
    "#pd.options.display.float_format = '{:.4f}'.format\n",
    "combined[['predicted', 'actual', 'Price', 'bedrooms', 'bathrooms']] = combined[\n",
    "    ['predicted', 'actual', 'Price', 'bedrooms', 'bathrooms']].astype(int)\n",
    "combined['bedrooms'] = combined['bedrooms'].astype(int)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.381726Z",
     "iopub.status.idle": "2022-12-02T18:54:14.382632Z",
     "shell.execute_reply": "2022-12-02T18:54:14.382499Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.382477Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.383238Z",
     "iopub.status.idle": "2022-12-02T18:54:14.383896Z",
     "shell.execute_reply": "2022-12-02T18:54:14.383771Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.383759Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "best_model_fig, best_model_ax = plt.subplots()\n",
    "best_model_ax.scatter(y_test, y_pred, edgecolors=(0, 0, 1))\n",
    "best_model_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "best_model_ax.set_ylabel('Predicted')\n",
    "best_model_ax.set_xlabel('Actual')\n",
    "#ax.title.set_text(f'CV Chosen best option ({calculated_best_pipe[1]})')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.384534Z",
     "iopub.status.idle": "2022-12-02T18:54:14.385183Z",
     "shell.execute_reply": "2022-12-02T18:54:14.385051Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.385036Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if not using_catboost:\n",
    "    def custom_model_and_predictions(model, graph_params, X_train, y_train, X_test):\n",
    "        graph_model = model\n",
    "        graph_model.set_params(**graph_params)\n",
    "        graph_model.fit(X_train, y_train)\n",
    "        y_pred_graph = model.predict(X_test)\n",
    "\n",
    "        return model, y_pred_graph\n",
    "\n",
    "\n",
    "    best_model_count = 10 if not quick_mode else 2\n",
    "    best_model_count = 3 if not quick_mode else 1\n",
    "    best_models = {}\n",
    "    best_model_predictions = {}\n",
    "    best_model_scores = {}\n",
    "\n",
    "    showable_increment = total_fits // (4 if not quick_mode else 2)\n",
    "    if showable_increment==0:showable_increment=1\n",
    "    for i in range(0, total_fits, showable_increment):\n",
    "        if debug_mode: print(f'{i} ==> {i}')\n",
    "\n",
    "        if i == 0:\n",
    "            fitted_graph_model = crossval_runner.best_estimator_\n",
    "            y_pred_graph = y_pred\n",
    "        else:\n",
    "            graph_pipe_params = cv_results_df_sorted['params'][i]\n",
    "            print(graph_pipe_params)\n",
    "            # would always return the best! graph_pipe_params = cv_results_df_sorted.loc[cv_results_df_sorted['rank_test_score'] == 1, 'params'].values[0]\n",
    "\n",
    "            graph_params = {}\n",
    "            for key2, value in graph_pipe_params.items():\n",
    "                graph_params[key2.replace('model__', '')] = value\n",
    "\n",
    "            fitted_graph_model, y_pred_graph = custom_model_and_predictions(make_pipeline(), graph_pipe_params, X_train,\n",
    "                                                                            y_train, X_test)\n",
    "\n",
    "        best_models[i] = fitted_graph_model[-1].get_params()\n",
    "        best_model_predictions[i] = y_pred_graph\n",
    "        best_model_scores[i] = fitted_graph_model.score(X_test, y_test)\n",
    "\n",
    "    if debug_mode: print(f'{-1} ==> {-1}')\n",
    "    graph_pipe_params = cv_results_df_sorted['params'][total_fits - 1]\n",
    "    print(graph_pipe_params)\n",
    "    graph_params = {}\n",
    "    for key2, value in graph_pipe_params.items():\n",
    "        graph_params[key2.replace('model__', '')] = value\n",
    "    fitted_graph_model, y_pred_graph = custom_model_and_predictions(make_pipeline(), graph_pipe_params, X_train,\n",
    "                                                                    y_train, X_test)\n",
    "    best_models[-1] = fitted_graph_model[-1].get_params()\n",
    "    best_model_predictions[-1] = y_pred_graph\n",
    "    best_model_scores[-1] = fitted_graph_model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.390857Z",
     "iopub.status.idle": "2022-12-02T18:54:14.391498Z",
     "shell.execute_reply": "2022-12-02T18:54:14.391371Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.391355Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if not using_catboost:\n",
    "    for i in best_model_scores.keys():\n",
    "        if i >= 0:\n",
    "            plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "            plt.scatter(y_test, best_model_predictions[i])\n",
    "            # plt.title(str(i) + \" \" + str(round(best_model_scores[i], 4)) + \" for \" + str(best_models[i]))\n",
    "            if len(best_models[i].keys()) < 30:\n",
    "                plt.title(str(i) + \" \" + str(round(best_model_scores[i], 4)) + \" for \" + str(best_models[i]))\n",
    "            else:\n",
    "                plt.title(str(i) + \" \" + str(round(best_model_scores[i], 4)) + \" for entry \" + str(i))\n",
    "            plt.show()\n",
    "\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "    plt.scatter(y_test, best_model_predictions[-1])\n",
    "    # plt.title(str(i) + \" \" + str(round(best_model_scores[i], 4)) + \" for \" + str(best_models[i]))\n",
    "    if len(best_models[i].keys()) < 30:\n",
    "        plt.title(str(i) + \" \" + str(round(best_model_scores[-1], 4)) + \" for \" + str(best_models[-1]))\n",
    "    else:\n",
    "        plt.title(str(i) + \" \" + str(round(best_model_scores[-1], 4)) + \" for (worst) entry \" + str(i))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.392126Z",
     "iopub.status.idle": "2022-12-02T18:54:14.392836Z",
     "shell.execute_reply": "2022-12-02T18:54:14.392706Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.392694Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if not using_catboost:\n",
    "    sns.set_theme(font_scale=2, rc=None)\n",
    "    sns.set_theme(font_scale=1, rc=None)\n",
    "\n",
    "    worst_and_best_model_fig, axes = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    plt.subplots_adjust(wspace=0.2)\n",
    "\n",
    "    #.flatten()\n",
    "    coordinates = axes[0]\n",
    "    sns.lineplot(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], ax=axes[0], color='red')\n",
    "    sns.scatterplot(x=y_test.flatten(), y=best_model_predictions[0].flatten(), ax=axes[0],\n",
    "                    s=100).set(title=f'\"BEST\" model')\n",
    "\n",
    "    sns.lineplot(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], ax=axes[1], color='red')\n",
    "    sns.scatterplot(x=y_test.flatten(), y=best_model_predictions[-1].flatten(), ax=axes[1],\n",
    "                    s=100).set(title=f'\"WORST\" model')\n",
    "\n",
    "    sns.lineplot(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], ax=axes[2], color='red')\n",
    "    sns.scatterplot(x=y_test.flatten(), y=best_model_predictions[-1].flatten(), ax=axes[2],\n",
    "                    s=120, color='orange')\n",
    "    sns.scatterplot(x=y_test.flatten(), y=best_model_predictions[0].flatten(), ax=axes[2],\n",
    "                    s=30, alpha=0.6, color='black').set(\n",
    "        title='best (black) vs worst (orange)')\n",
    "    #title='best (orange) vs worst (black)')\n",
    "\n",
    "\n",
    "    best_model_fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.393440Z",
     "iopub.status.idle": "2022-12-02T18:54:14.394104Z",
     "shell.execute_reply": "2022-12-02T18:54:14.393981Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.393965Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Evaluate the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.394713Z",
     "iopub.status.idle": "2022-12-02T18:54:14.395347Z",
     "shell.execute_reply": "2022-12-02T18:54:14.395222Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.395203Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# <catboost.core.CatBoostRegressor object at 0x7fb167387490>\n",
    "# {'depth': 6}\n",
    "# defaultdict(<class 'list'>, {'iterations': [0, 1, 2],\n",
    "# 'test-RMSE-mean': [396884.9605444017, 359548.6632536235, 326027.84885587444],\n",
    "# 'test-RMSE-std': [308.9495320039113, 260.0967808594464, 219.65856329246023],\n",
    "# 'train-RMSE-mean': [396884.77936957515, 359542.3612912551, 326018.9404460669],\n",
    "# 'train-RMSE-std': [91.44140078375503, 86.77961380623475, 69.4038638987425]})\n",
    "\n",
    "cv_best_model_fit_time = cv_best_model_fit_time if not using_catboost else 999\n",
    "\n",
    "DD2 = \"(\" + \",\".join(DATA_DETAIL) + \")\" if len(DATA_DETAIL) >= 1 else \"\"\n",
    "\n",
    "method =  f\"{ALGORITHM_DETAIL}{DD2}\"\n",
    "\n",
    "new_results = {\n",
    "    '_score': R2,\n",
    "    'R square Accuracy': R2,\n",
    "    'Mean Absolute Error Accuracy': MAE,\n",
    "    'Mean Squared Error Accuracy': MSE,\n",
    "    'Root Mean Squared Error': RMSE,\n",
    "    '_train time': cv_best_model_fit_time,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'date': str(datetime.now()),\n",
    "    '_params': crossval_runner.best_params_ if not using_catboost else cat_params,\n",
    "    '_method':method,\n",
    "    'run_env': run_env\n",
    "}\n",
    "\n",
    "if run_env not in ['colab']:\n",
    "    old_results_json = get_results()\n",
    "    try:\n",
    "        old_best_score = old_results_json[key]['best score']\n",
    "    except:\n",
    "        print(f\"haven't scored this model yet: {ALGORITHM}\")\n",
    "        old_best_score = -999\n",
    "    this_model_is_best = update_results(old_results_json, new_results, key)\n",
    "\n",
    "print(key)\n",
    "new_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.395959Z",
     "iopub.status.idle": "2022-12-02T18:54:14.396670Z",
     "shell.execute_reply": "2022-12-02T18:54:14.396528Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.396512Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "crossval_runner.best_estimator_  if not using_catboost else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.397360Z",
     "iopub.status.idle": "2022-12-02T18:54:14.398030Z",
     "shell.execute_reply": "2022-12-02T18:54:14.397904Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.397885Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if this_model_is_best:\n",
    "    with open(f'../../../models/optimised_model_{ALGORITHM}_v{VERSION}{DD2}.pkl', 'wb') as f:\n",
    "        if not using_catboost:\n",
    "            pickle.dump(crossval_runner.best_estimator_, f)\n",
    "        else:\n",
    "            pickle.dump(starter_model, f)\n",
    "        print('pickled new version of model')\n",
    "        print(f\"{old_results_json[key]['_score']} is new best score (it's better than {old_best_score})\")\n",
    "        #print(results_json[key]['_score'], 'is an improvement on', results_json[key]['second best score'])\n",
    "else:\n",
    "    print(\"not updated saved model, the previous run was better\")\n",
    "    print(f\"{old_results_json[key]['_score']} is worse than or equal to '{old_best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.398681Z",
     "iopub.status.idle": "2022-12-02T18:54:14.399335Z",
     "shell.execute_reply": "2022-12-02T18:54:14.399181Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.399165Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def include_in_html_report(type, text_list=None, fig=None, content=None):\n",
    "    writePath_html = r'model_results/%s.html' % key\n",
    "    writePath_md = r'model_results/%s.md' % key\n",
    "\n",
    "\n",
    "    if type == 'header':\n",
    "        with open(writePath_html, 'w') as f1:\n",
    "            headers = f'<h1>Results from {ALGORITHM}</h1>'\n",
    "            f1.write(headers)\n",
    "        with open(writePath_md, 'w') as f2:\n",
    "            headers = f'# Results from {ALGORITHM}\\n'\n",
    "            f2.write(headers)\n",
    "    else:\n",
    "        with open(writePath_html, 'a') as f1:\n",
    "            f1.write(f'<h3>{text_list}</h3>')\n",
    "        with open(writePath_md, 'a') as f2:\n",
    "            f2.write(f'### {text_list}\\n')\n",
    "\n",
    "        if type=='dataframe':\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                dfAsString = content.to_html()\n",
    "                f1.write(dfAsString)\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                dfAsString = content.to_markdown()\n",
    "                f2.write(dfAsString + '\\n')\n",
    "        elif type=='graph':\n",
    "            filename = key + \"_\" + content\n",
    "            fig.savefig(f'model_results/artifacts/{filename.replace(\" \",\"_\")}')\n",
    "\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                dfAsString = f'<img src=\"artifacts/{filename.replace(\" \",\"_\")}\"/>'\n",
    "                f1.write(dfAsString)\n",
    "\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                #dfAsString = f'(./model_results/artifacts/{filename}) \\n'\n",
    "                dfAsString = f'![detail](./artifacts/{filename.replace(\" \",\"_\")})'\n",
    "                f2.write(dfAsString)\n",
    "                f2.write('\\n')\n",
    "        elif type=='json':\n",
    "\n",
    "            # html_content_parsed = [[cell.text for cell in row(\"td\")]\n",
    "            #              for row in BeautifulSoup(content,features=\"html.parser\")(\"tr\")]\n",
    "            #\n",
    "            # html_content_dictionary = {element[0]:element[1:] for element in html_content_parsed}\n",
    "\n",
    "            #xxxprint(json.dumps(html_content_dictionary, indent=4))\n",
    "\n",
    "\n",
    "\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                #f.write(json.dumps(html_content_dictionary, indent=4))\n",
    "                soup = BeautifulSoup(content, \"html.parser\")\n",
    "                f1.write(str(soup.prettify()))\n",
    "\n",
    "        elif type=='text':\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                f1.write(content)\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                f2.write(content + '\\n')\n",
    "\n",
    "        with open(writePath_html, 'a') as f1:\n",
    "            f1.write('<hr>')\n",
    "\n",
    "\n",
    "include_in_html_report(\"header\")\n",
    "\n",
    "include_in_html_report(type=\"text\",text_list=\"Summary\", content=f\"{old_results_json[key]['_score']} is new best score (it's better than {old_best_score})\")\n",
    "include_in_html_report(type=\"text\",text_list=\"Summary\", content=\"not updated saved model, the previous run was better\")\n",
    "include_in_html_report(type=\"text\",text_list=None, content=f\"{old_results_json[key]['_score']} is worse than or equal to '{old_best_score}\")\n",
    "\n",
    "#include_in_html_report(type=\"dataframe\",text_list=\"Tuned Models ranked by performance\", content=cv_results_df_sorted)\n",
    "\n",
    "include_in_html_report(type='dataframe',text_list='Tuned Models ranked by performance, with parameter details',content=cv_results_df_summary)\n",
    "\n",
    "include_in_html_report(type='graph', text_list='Best and worst models obtained by tuning', fig=worst_and_best_model_fig, content=\"best_and_worst.png\")\n",
    "\n",
    "include_in_html_report(type='graph', text_list='Comparing model predictions to actual property values', fig=best_model_fig, content='best_model_correlation.png')\n",
    "\n",
    "#include_in_html_report(type=\"dataframe\",text_list=\"Summary\", content=pd.DataFrame(data=new_results))\n",
    "\n",
    "\n",
    "def print_and_report(text_list, title):\n",
    "    include_in_html_report(\"text\",content=title)\n",
    "    for each in text_list:\n",
    "        print(each)\n",
    "        include_in_html_report(\"text\",text_list=\"\",content=each)\n",
    "\n",
    "# if not catboost:\n",
    "#     print_and_report([\n",
    "#         'Best Index:' + str(crossval_runner.best_index_) + '<br>',\n",
    "#         'Best Score:' + str(crossval_runner.best_score_) + '<br>',\n",
    "#         'Best Params: ' + str(crossval_runner.best_params_) + '<br>'\n",
    "#     ], \"Best Model Details\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Investigate the feature importances (if applicable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.399969Z",
     "iopub.status.idle": "2022-12-02T18:54:14.400591Z",
     "shell.execute_reply": "2022-12-02T18:54:14.400467Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.400449Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if 'tree' in ALGORITHM.lower() or 'forest' in ALGORITHM.lower() or 'boost' in ALGORITHM.lower():\n",
    "    feature_importances = crossval_runner.best_estimator_[-1].feature_importances_ if not using_catboost else starter_model.get_feature_importance()\n",
    "    #std = np.std([tree.feature_importances_ for tree in model.estimators_], axis = 0)\n",
    "\n",
    "    indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "    print('Feature Ranking:')\n",
    "\n",
    "    for f in range(X_train.shape[1]):\n",
    "        print('%d. features %d (%f)' % (f + 1, indices[f], feature_importances[indices[f]]),\n",
    "              df_features.columns[indices[f] + 1])\n",
    "else:\n",
    "    print(f'{ALGORITHM} does not have feature_importances, skipping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-02T18:54:14.401191Z",
     "iopub.status.idle": "2022-12-02T18:54:14.401808Z",
     "shell.execute_reply": "2022-12-02T18:54:14.401684Z",
     "shell.execute_reply.started": "2022-12-02T18:54:14.401670Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if 'tree' in ALGORITHM.lower() or 'forest' in ALGORITHM.lower() or 'boost' in ALGORITHM.lower():\n",
    "    indices = np.argsort(feature_importances)\n",
    "\n",
    "    best_model_fig, best_model_ax = plt.subplots(figsize=(20, 20))\n",
    "    best_model_ax.barh(range(len(feature_importances)), feature_importances[indices])\n",
    "    best_model_ax.set_yticks(range(len(feature_importances)))\n",
    "    _ = best_model_ax.set_yticklabels(df_features.columns[[c + 1 for c in indices]])\n",
    "else:\n",
    "    print(f'{ALGORITHM} does not have feature_importances, skipping')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
