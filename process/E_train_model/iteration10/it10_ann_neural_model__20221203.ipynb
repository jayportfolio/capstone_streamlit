{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Decide which algorithm and version of the data we are going to use for model training\n",
    "(it'll be neural network in this file)\n",
    "\n",
    "Additionally, choose:\n",
    "* if we'll skip scaling the data\n",
    "* if we'll use full categories instead of dummies\n",
    "* what fraction of the data we'll use for testing (0.1)\n",
    "* if the data split will be randomised (it won't!)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#ALGORITHM = 'Neural Network'\n",
    "ALGORITHM = 'Neural Network [TYPE]'\n",
    "ALGORITHM_DETAIL = ''\n",
    "ALGORITHM_DETAIL_ORIG = ALGORITHM_DETAIL\n",
    "#ALGORITHM_DETAIL += ' tbc'\n",
    "DATA_DETAIL = []\n",
    "#DATA_DETAIL = ['no scale','no dummies']\n",
    "VERSION = '06'\n",
    "\n",
    "RANDOM_STATE = 101\n",
    "TRAINING_SIZE = 0.9\n",
    "\n",
    "CROSS_VALIDATION_SCORING = 'r2'\n",
    "\n",
    "price_divisor = 1\n",
    "\n",
    "\n",
    "#selected_neural_network='simplest'\n",
    "#selected_neural_network='quite simple'\n",
    "#selected_neural_network='recommended simple v2'\n",
    "#selected_neural_network='adapted v3'\n",
    "\n",
    "\n",
    "# ---- FIRST NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = 'recommended simple v1'\n",
    "#selected_nn_code = 'm01 simple'\n",
    "\n",
    "# ---- 2nd NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m02 two layers\"\n",
    "\n",
    "\n",
    "# ---- 3rd NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "selected_neural_network = selected_nn_code = \"m03 2 layers+wider\"\n",
    "\n",
    "\n",
    "# ---- 4th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m04 3 layers+wider\"\n",
    "\n",
    "# ---- 5th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m05 rec deep\"\n",
    "\n",
    "# ---- 6th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m05 my deep\"\n",
    "\n",
    "#selected_neural_network = selected_nn_code = \"\"\n",
    "\n",
    "# ---- 7th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m11 mega\"\n",
    "\n",
    "# ---- 8th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m12 mega\"\n",
    "\n",
    "# ---- 9th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m13 mega\"\n",
    "\n",
    "# ---- 10th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m14 mega\"\n",
    "\n",
    "\n",
    "\n",
    "ALGORITHM = ALGORITHM.replace(\"[TYPE]\", selected_nn_code)\n",
    "\n",
    "create_python_script = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: loading all dependencies\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:33:51.825942Z",
     "iopub.status.busy": "2022-12-01T11:33:51.825735Z",
     "iopub.status.idle": "2022-12-01T11:33:51.828815Z",
     "shell.execute_reply": "2022-12-01T11:33:51.828239Z",
     "shell.execute_reply.started": "2022-12-01T11:33:51.825942Z"
    }
   },
   "outputs": [],
   "source": [
    "#! pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'notebook_environment': 'gradient', 'use_gpu': True, 'debug_mode': False, 'quick_mode': False, 'quick_override_cv_splits': 2, 'quick_override_n_iter': 10, 'quick_override_n_jobs': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "from termcolor import colored\n",
    "from time import time\n",
    "import sklearn\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "start_timestamp = datetime.now()\n",
    "\n",
    "with open('../../z_envs/_envs.json') as f:\n",
    "    env_vars = json.loads(f.read())\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    run_env = 'colab'\n",
    "except:\n",
    "    try:\n",
    "        run_env = env_vars['notebook_environment']\n",
    "    except:\n",
    "        run_env = 'unknown'\n",
    "\n",
    "if \"JPY_PARENT_PID\" in os.environ:\n",
    "    is_jupyter = True\n",
    "else:\n",
    "    is_jupyter = False\n",
    "\n",
    "use_gpu = env_vars.get('use_gpu', False)\n",
    "debug_mode = env_vars.get('debug_mode', False)\n",
    "quick_mode = env_vars.get('quick_mode', False)\n",
    "OVERRIDE_CV = env_vars.get('quick_override_cv_splits', None) if quick_mode else None\n",
    "OVERRIDE_N_ITER = env_vars.get('quick_override_n_iter', None) if quick_mode else None\n",
    "OVERRIDE_JOBS = env_vars.get('quick_override_n_jobs', None) if quick_mode else None\n",
    "OVERRIDE_VERBOSE = 1\n",
    "#if quick_mode:OVERRIDE_CV, OVERRIDE_N_ITER = 2, 10\n",
    "\n",
    "already_timed = False\n",
    "no_dummies = 'no dummies' in DATA_DETAIL\n",
    "no_scaling = 'no scaling' in DATA_DETAIL\n",
    "#not_catboost = 'catboost' not in ALGORITHM.lower() or not no_dummies\n",
    "using_catboost = 'catboost' in ALGORITHM.lower()\n",
    "\n",
    "if run_env not in ['colab', 'gradient', 'cloud']:\n",
    "    cloud_run = False\n",
    "    from functions_b__get_the_data_20221116 import set_csv_directory\n",
    "    set_csv_directory('final_split')\n",
    "else:\n",
    "    cloud_run = True\n",
    "\n",
    "    module_path = os.path.abspath(os.path.join('..', '..', '..'))\n",
    "    if module_path not in sys.path:\n",
    "        #sys.path.append(module_path+\"\\\\zfunctions\")\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "from functions_0__common_20221116 import get_columns\n",
    "from functions_b__get_the_data_20221116 import get_combined_dataset, get_source_dataframe\n",
    "from functions_d1__prepare_cleanse_data_20221116 import tidy_dataset\n",
    "from functions_d2__transform_enrich_data_20221116 import preprocess, feature_engineer\n",
    "from functions_d3__prepare_store_data_20221116 import create_train_test_data\n",
    "from functions_e__train_model_20221116 import get_chosen_model, make_modelling_pipeline, get_cv_params, fit_model_with_cross_validation, get_hyperparameters\n",
    "from functions_f_evaluate_model_20221116 import get_best_estimator_average_time, get_results, update_results\n",
    "\n",
    "print(env_vars)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Include any overrides specific to the algorthm / python environment being used"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#running_locally = True\n",
    "running_locally = run_env == 'local'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: creating the ANN model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "#from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "\n",
    "loss_dict = {\n",
    "    \"mean_squared_error\":'mse',\n",
    "    \"mean_absolute_error\":'mae'\n",
    "            }\n",
    "\n",
    "def make_simple_ann(key, inputs=-1):\n",
    "    if False:\n",
    "        pass\n",
    "    elif key == 'quite simple':\n",
    "\n",
    "        new_algorithm_detail = ALGORITHM_DETAIL_ORIG + 'quite simple model + normalise, mse'\n",
    "\n",
    "        learn_rate = 0.1\n",
    "        epochs, chosen_loss = 100, 'mean_squared_error'\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'recommended simple v1':\n",
    "\n",
    "        learn_rate = 0.003 #0.3\n",
    "        epochs, chosen_loss = 50, 'mean_squared_error'\n",
    "\n",
    "        new_algorithm_detail = ALGORITHM_DETAIL_ORIG + 'recommended simple model/mse'\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'm02 two layers':\n",
    "\n",
    "        learn_rate = 0.003 #0.3\n",
    "        epochs, chosen_loss = 500, 'mean_squared_error'\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(X_train.shape[1], activation='relu'),\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "\n",
    "    elif key == 'm03 2 layers+wider':\n",
    "\n",
    "        learn_rate = 0.0003 # 0.003 #0.3\n",
    "        epochs, chosen_loss = 500, 'mean_squared_error'\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(30, activation='relu'),\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'm04 3 layers+wider':\n",
    "\n",
    "        learn_rate = 0.003\n",
    "        epochs, chosen_loss = 500, 'mean_squared_error'\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(30, activation='relu'),\n",
    "            layers.Dense(40, activation='relu'),\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'm0x four layers,wider,batchnorm':\n",
    "\n",
    "        learn_rate = 0.0003 #0.3\n",
    "        epochs, chosen_loss = 500, 'mean_squared_error'\n",
    "\n",
    "        #from layers.normalization import BatchNormalization\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        batchnorm = layers.BatchNormalization()\n",
    "        activation = layers.Activation('relu')\n",
    "\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "        #new_algorithm_detail += ' +norm'\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            #normalizer,\n",
    "            layers.Dense(30, activation='relu'),\n",
    "            batchnorm,\n",
    "            activation,\n",
    "            layers.Dense(40, activation='relu'),\n",
    "            layers.Dense(30, activation='relu'),\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'm05 rec deep':\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        # Compile the network :\n",
    "        #chosen_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "        learn_rate = 0.0003 #0.3\n",
    "        epochs, chosen_loss = 500, 'mean_squared_error'\n",
    "\n",
    "    elif key == 'm11 mega':\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(2148, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(2148, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        # Compile the network :\n",
    "        #chosen_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "        learn_rate = 0.0003\n",
    "        epochs, chosen_loss = 400, 'mean_squared_error'\n",
    "\n",
    "    elif key == 'm12 mega':\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        # Compile the network :\n",
    "        #chosen_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "        learn_rate = 0.0003\n",
    "        epochs, chosen_loss = 400, 'mean_squared_error'\n",
    "    elif key == 'm13 mega':\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "        #normalizer.adapt(np.array(128))\n",
    "\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(normalizer),\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        learn_rate = 0.0003\n",
    "        epochs = 400\n",
    "        chosen_loss = 'mean_absolute_error' # 'mean_squared_error'\n",
    "\n",
    "    elif key == 'm14 mega':\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "        batchnorm = layers.BatchNormalization()\n",
    "        activation = layers.Activation('relu')\n",
    "\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(normalizer)\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        learn_rate = 0.0003\n",
    "        epochs = 400\n",
    "        chosen_loss = 'mean_absolute_error' # 'mean_squared_error'\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"make_simple_ann: no entry for key:\", key)\n",
    "\n",
    "    if running_locally:\n",
    "        epochs = 8\n",
    "\n",
    "    # Compile the network :\n",
    "    chosen_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learn_rate),\n",
    "        loss=chosen_loss)\n",
    "\n",
    "\n",
    "    new_algorithm_detail = ALGORITHM_DETAIL_ORIG + loss_dict[chosen_loss]\n",
    "    new_algorithm_detail += f' +epochs={epochs}'\n",
    "    new_algorithm_detail += f' +learn={learn_rate}'\n",
    "\n",
    "    return chosen_model, new_algorithm_detail, epochs, {'learning_rate':learn_rate}\n",
    "\n",
    "#make_simple_ann('m04 four layers,wider,batchnorm')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: get the data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:33:51.876236Z",
     "iopub.status.busy": "2022-12-01T11:33:51.875963Z",
     "iopub.status.idle": "2022-12-01T11:33:51.881453Z",
     "shell.execute_reply": "2022-12-01T11:33:51.880413Z",
     "shell.execute_reply.started": "2022-12-01T11:33:51.876213Z"
    }
   },
   "outputs": [],
   "source": [
    "columns, booleans, floats, categories, custom, wildcard = get_columns(version=VERSION)\n",
    "LABEL = 'Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:33:51.883444Z",
     "iopub.status.busy": "2022-12-01T11:33:51.883201Z",
     "iopub.status.idle": "2022-12-01T11:33:51.888705Z",
     "shell.execute_reply": "2022-12-01T11:33:51.887944Z",
     "shell.execute_reply.started": "2022-12-01T11:33:51.883424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data from ../../../https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/df_listings_v06.csv\n"
     ]
    }
   ],
   "source": [
    "df, retrieval_type = get_source_dataframe(cloud_run, VERSION, folder_prefix='../../../', row_limit=None)\n",
    "df_orig = df.copy()\n",
    "\n",
    "if retrieval_type != 'tidy':\n",
    "    df = tidy_dataset(df, version=int(VERSION))\n",
    "    df = feature_engineer(df, version=int(VERSION))\n",
    "\n",
    "\n",
    "    df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:33:51.889791Z",
     "iopub.status.busy": "2022-12-01T11:33:51.889588Z",
     "iopub.status.idle": "2022-12-01T11:33:52.227509Z",
     "shell.execute_reply": "2022-12-01T11:33:52.226604Z",
     "shell.execute_reply.started": "2022-12-01T11:33:51.889772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mfeatures\u001B[0m ->  ['bedrooms', 'bathrooms', 'nearestStation', 'location.latitude', 'location.longitude', 'latitude_deviation', 'longitude_deviation', 'tenure.tenureType']\n",
      "\u001B[1m\u001B[32mlabel\u001B[0m ->  Price\n"
     ]
    }
   ],
   "source": [
    "print(colored(f\"features\", \"blue\"), \"-> \", columns)\n",
    "columns.insert(0, LABEL)\n",
    "print(colored(f\"label\", \"green\", None, ['bold']), \"-> \", LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df = preprocess(df, version=VERSION)\n",
    "df = df.dropna()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:33:52.228742Z",
     "iopub.status.busy": "2022-12-01T11:33:52.228515Z",
     "iopub.status.idle": "2022-12-01T11:33:52.256377Z",
     "shell.execute_reply": "2022-12-01T11:33:52.255547Z",
     "shell.execute_reply.started": "2022-12-01T11:33:52.228722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             Price  bedrooms  bathrooms  nearestStation  location.latitude  \\\n14520525  550000.0       3.0        1.0        0.274316          51.529950   \n27953107  400000.0       2.0        2.0        0.305845          51.549390   \n33593487  579950.0       2.0        1.0        0.438045          51.447180   \n35271294  370000.0       2.0        1.0        0.399307          51.449568   \n44749111  475000.0       2.0        1.0        0.410550          51.370050   \n46204665  435000.0       3.0        2.0        0.314779          51.539070   \n49020666  200000.0       1.0        1.0        0.875911          51.539959   \n49036279  275000.0       2.0        1.0        0.474368          51.541780   \n49303873  450000.0       3.0        2.0        0.577040          51.524880   \n52064391  349950.0       2.0        2.0        0.212734          51.470800   \n52187854  450000.0       1.0        1.0        0.446802          51.527199   \n52845963  200000.0       2.0        1.0        0.650562          51.398040   \n52913496  220000.0       1.0        1.0        0.945991          51.539383   \n53609433  489995.0       1.0        1.0        0.087081          51.532620   \n53938989  450000.0       2.0        1.0        0.775203          51.658287   \n54713232  332000.0       2.0        1.0        0.319226          51.612300   \n54904122  365000.0       2.0        1.0        0.260722          51.593595   \n54991934  430000.0       3.0        1.0        0.497268          51.528720   \n55043230  260000.0       1.0        1.0        0.384607          51.544430   \n55187658  430000.0       2.0        2.0        0.289033          51.507570   \n55805965  280000.0       2.0        1.0        0.742859          51.520910   \n55839051  599950.0       2.0        1.0        0.259168          51.579186   \n55940994  385000.0       2.0        2.0        0.403987          51.376930   \n56449305  380000.0       2.0        1.0        0.310271          51.600483   \n57221413  475000.0       3.0        2.0        0.409784          51.497260   \n57878227  490000.0       2.0        1.0        0.052498          51.580270   \n59258796  475000.0       3.0        1.0        0.424573          51.536335   \n59658138  499995.0       1.0        1.0        0.396544          51.462211   \n60741240  435000.0       2.0        1.0        0.162014          51.612150   \n61387062  375000.0       2.0        1.0        0.493102          51.448697   \n\n          location.longitude  latitude_deviation  longitude_deviation  \\\n14520525           -0.207020            0.030230             0.102600   \n27953107           -0.482600            0.049670             0.378180   \n33593487           -0.338770            0.052540             0.234350   \n35271294           -0.140154            0.050152             0.035734   \n44749111           -0.212410            0.129670             0.107990   \n46204665           -0.198935            0.039350             0.094515   \n49020666           -0.380863            0.040239             0.276443   \n49036279            0.037890            0.042060             0.142310   \n49303873            0.187200            0.025160             0.291620   \n52064391           -0.361820            0.028920             0.257400   \n52187854           -0.202898            0.027479             0.098478   \n52845963           -0.076812            0.101680             0.027608   \n52913496           -0.382239            0.039663             0.277819   \n53609433           -0.107860            0.032900             0.003440   \n53938989           -0.207902            0.158567             0.103482   \n54713232           -0.119860            0.112580             0.015440   \n54904122            0.022046            0.093875             0.126466   \n54991934            0.039180            0.029000             0.143600   \n55043230            0.014500            0.044710             0.118920   \n55187658            0.078030            0.007850             0.182450   \n55805965            0.022680            0.021190             0.127100   \n55839051           -0.209020            0.079466             0.104600   \n55940994           -0.238870            0.122790             0.134450   \n56449305           -0.062096            0.100763             0.042324   \n57221413           -0.422530            0.002460             0.318110   \n57878227            0.022290            0.080550             0.126710   \n59258796           -0.068537            0.036615             0.035883   \n59658138           -0.196876            0.037509             0.092456   \n60741240           -0.277430            0.112430             0.173010   \n61387062           -0.174068            0.051023             0.069648   \n\n          tenure.tenureType  \n14520525          LEASEHOLD  \n27953107          LEASEHOLD  \n33593487           FREEHOLD  \n35271294          LEASEHOLD  \n44749111           FREEHOLD  \n46204665          LEASEHOLD  \n49020666          LEASEHOLD  \n49036279          LEASEHOLD  \n49303873           FREEHOLD  \n52064391          LEASEHOLD  \n52187854          LEASEHOLD  \n52845963          LEASEHOLD  \n52913496          LEASEHOLD  \n53609433          LEASEHOLD  \n53938989           FREEHOLD  \n54713232  SHARE_OF_FREEHOLD  \n54904122  SHARE_OF_FREEHOLD  \n54991934           FREEHOLD  \n55043230          LEASEHOLD  \n55187658          LEASEHOLD  \n55805965          LEASEHOLD  \n55839051          LEASEHOLD  \n55940994          LEASEHOLD  \n56449305           FREEHOLD  \n57221413           FREEHOLD  \n57878227  SHARE_OF_FREEHOLD  \n59258796          LEASEHOLD  \n59658138          LEASEHOLD  \n60741240          LEASEHOLD  \n61387062          LEASEHOLD  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n      <th>location.latitude</th>\n      <th>location.longitude</th>\n      <th>latitude_deviation</th>\n      <th>longitude_deviation</th>\n      <th>tenure.tenureType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14520525</th>\n      <td>550000.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.274316</td>\n      <td>51.529950</td>\n      <td>-0.207020</td>\n      <td>0.030230</td>\n      <td>0.102600</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>27953107</th>\n      <td>400000.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.305845</td>\n      <td>51.549390</td>\n      <td>-0.482600</td>\n      <td>0.049670</td>\n      <td>0.378180</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>33593487</th>\n      <td>579950.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.438045</td>\n      <td>51.447180</td>\n      <td>-0.338770</td>\n      <td>0.052540</td>\n      <td>0.234350</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>35271294</th>\n      <td>370000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.399307</td>\n      <td>51.449568</td>\n      <td>-0.140154</td>\n      <td>0.050152</td>\n      <td>0.035734</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>44749111</th>\n      <td>475000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.410550</td>\n      <td>51.370050</td>\n      <td>-0.212410</td>\n      <td>0.129670</td>\n      <td>0.107990</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>46204665</th>\n      <td>435000.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.314779</td>\n      <td>51.539070</td>\n      <td>-0.198935</td>\n      <td>0.039350</td>\n      <td>0.094515</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>49020666</th>\n      <td>200000.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.875911</td>\n      <td>51.539959</td>\n      <td>-0.380863</td>\n      <td>0.040239</td>\n      <td>0.276443</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>49036279</th>\n      <td>275000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.474368</td>\n      <td>51.541780</td>\n      <td>0.037890</td>\n      <td>0.042060</td>\n      <td>0.142310</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>49303873</th>\n      <td>450000.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.577040</td>\n      <td>51.524880</td>\n      <td>0.187200</td>\n      <td>0.025160</td>\n      <td>0.291620</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>52064391</th>\n      <td>349950.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.212734</td>\n      <td>51.470800</td>\n      <td>-0.361820</td>\n      <td>0.028920</td>\n      <td>0.257400</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>52187854</th>\n      <td>450000.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.446802</td>\n      <td>51.527199</td>\n      <td>-0.202898</td>\n      <td>0.027479</td>\n      <td>0.098478</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>52845963</th>\n      <td>200000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.650562</td>\n      <td>51.398040</td>\n      <td>-0.076812</td>\n      <td>0.101680</td>\n      <td>0.027608</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>52913496</th>\n      <td>220000.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.945991</td>\n      <td>51.539383</td>\n      <td>-0.382239</td>\n      <td>0.039663</td>\n      <td>0.277819</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>53609433</th>\n      <td>489995.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.087081</td>\n      <td>51.532620</td>\n      <td>-0.107860</td>\n      <td>0.032900</td>\n      <td>0.003440</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>53938989</th>\n      <td>450000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.775203</td>\n      <td>51.658287</td>\n      <td>-0.207902</td>\n      <td>0.158567</td>\n      <td>0.103482</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>54713232</th>\n      <td>332000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.319226</td>\n      <td>51.612300</td>\n      <td>-0.119860</td>\n      <td>0.112580</td>\n      <td>0.015440</td>\n      <td>SHARE_OF_FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>54904122</th>\n      <td>365000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.260722</td>\n      <td>51.593595</td>\n      <td>0.022046</td>\n      <td>0.093875</td>\n      <td>0.126466</td>\n      <td>SHARE_OF_FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>54991934</th>\n      <td>430000.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.497268</td>\n      <td>51.528720</td>\n      <td>0.039180</td>\n      <td>0.029000</td>\n      <td>0.143600</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>55043230</th>\n      <td>260000.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.384607</td>\n      <td>51.544430</td>\n      <td>0.014500</td>\n      <td>0.044710</td>\n      <td>0.118920</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>55187658</th>\n      <td>430000.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.289033</td>\n      <td>51.507570</td>\n      <td>0.078030</td>\n      <td>0.007850</td>\n      <td>0.182450</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>55805965</th>\n      <td>280000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.742859</td>\n      <td>51.520910</td>\n      <td>0.022680</td>\n      <td>0.021190</td>\n      <td>0.127100</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>55839051</th>\n      <td>599950.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.259168</td>\n      <td>51.579186</td>\n      <td>-0.209020</td>\n      <td>0.079466</td>\n      <td>0.104600</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>55940994</th>\n      <td>385000.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.403987</td>\n      <td>51.376930</td>\n      <td>-0.238870</td>\n      <td>0.122790</td>\n      <td>0.134450</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>56449305</th>\n      <td>380000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.310271</td>\n      <td>51.600483</td>\n      <td>-0.062096</td>\n      <td>0.100763</td>\n      <td>0.042324</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>57221413</th>\n      <td>475000.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.409784</td>\n      <td>51.497260</td>\n      <td>-0.422530</td>\n      <td>0.002460</td>\n      <td>0.318110</td>\n      <td>FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>57878227</th>\n      <td>490000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.052498</td>\n      <td>51.580270</td>\n      <td>0.022290</td>\n      <td>0.080550</td>\n      <td>0.126710</td>\n      <td>SHARE_OF_FREEHOLD</td>\n    </tr>\n    <tr>\n      <th>59258796</th>\n      <td>475000.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.424573</td>\n      <td>51.536335</td>\n      <td>-0.068537</td>\n      <td>0.036615</td>\n      <td>0.035883</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>59658138</th>\n      <td>499995.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.396544</td>\n      <td>51.462211</td>\n      <td>-0.196876</td>\n      <td>0.037509</td>\n      <td>0.092456</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>60741240</th>\n      <td>435000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.162014</td>\n      <td>51.612150</td>\n      <td>-0.277430</td>\n      <td>0.112430</td>\n      <td>0.173010</td>\n      <td>LEASEHOLD</td>\n    </tr>\n    <tr>\n      <th>61387062</th>\n      <td>375000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.493102</td>\n      <td>51.448697</td>\n      <td>-0.174068</td>\n      <td>0.051023</td>\n      <td>0.069648</td>\n      <td>LEASEHOLD</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Price'] = df['Price'] / price_divisor # potentially making the price smaller to make the ANN perform better\n",
    "\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:33:52.926171Z",
     "iopub.status.busy": "2022-12-01T11:33:52.925925Z",
     "iopub.status.idle": "2022-12-01T11:33:53.053145Z",
     "shell.execute_reply": "2022-12-01T11:33:53.052322Z",
     "shell.execute_reply.started": "2022-12-01T11:33:52.926167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44127, 9)\n",
      "(39714, 11) (4413, 11) (39714, 1) (4413, 1) (39714, 1) (4413, 1) (39714, 1) (4413, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_train_index, X_test_index, y_train_index, y_test_index, df_features, df_labels = create_train_test_data(\n",
    "    df,\n",
    "    categories=categories,\n",
    "    RANDOM_STATE=RANDOM_STATE, return_index=True,\n",
    "    drop_nulls=True,\n",
    "    no_dummies=no_dummies\n",
    ")\n",
    "\n",
    "#print(X_train[0])\n",
    "print(df.shape)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_train_index.shape, X_test_index.shape,\n",
    "      y_train_index.shape, y_test_index.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage:\n",
    "* #### retrieve the hyperparameters for this model, and\n",
    "* #### train the model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:33:53.054480Z",
     "iopub.status.busy": "2022-12-01T11:33:53.054198Z",
     "iopub.status.idle": "2022-12-01T11:33:54.655149Z",
     "shell.execute_reply": "2022-12-01T11:33:54.654176Z",
     "shell.execute_reply.started": "2022-12-01T11:33:53.054476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'mse +epochs=500 +learn=0.0003'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_model, ALGORITHM_DETAIL, chosen_epochs, chosen_params = make_simple_ann(selected_neural_network)\n",
    "\n",
    "ALGORITHM_DETAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:33:54.656416Z",
     "iopub.status.busy": "2022-12-01T11:33:54.656184Z",
     "iopub.status.idle": "2022-12-01T11:33:54.692848Z",
     "shell.execute_reply": "2022-12-01T11:33:54.692071Z",
     "shell.execute_reply.started": "2022-12-01T11:33:54.656396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 11)                132       \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 11)               23        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                360       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 546\n",
      "Trainable params: 523\n",
      "Non-trainable params: 23\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainable_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:33:54.699481Z",
     "iopub.status.busy": "2022-12-01T11:33:54.699274Z",
     "iopub.status.idle": "2022-12-01T11:52:43.791388Z",
     "shell.execute_reply": "2022-12-01T11:52:43.790724Z",
     "shell.execute_reply.started": "2022-12-01T11:33:54.699462Z"
    },
    "pycharm": {
     "name": "#%%time\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 186270793728.0000 - val_loss: 173739229184.0000\n",
      "Epoch 2/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 141329842176.0000 - val_loss: 103465951232.0000\n",
      "Epoch 3/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 64070545408.0000 - val_loss: 32109025280.0000\n",
      "Epoch 4/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 17986799616.0000 - val_loss: 11596063744.0000\n",
      "Epoch 5/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 10914341888.0000 - val_loss: 10826098688.0000\n",
      "Epoch 6/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 10723268608.0000 - val_loss: 10733958144.0000\n",
      "Epoch 7/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 10622998528.0000 - val_loss: 10623664128.0000\n",
      "Epoch 8/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 10505879552.0000 - val_loss: 10510081024.0000\n",
      "Epoch 9/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 10384588800.0000 - val_loss: 10370360320.0000\n",
      "Epoch 10/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 10262270976.0000 - val_loss: 10245253120.0000\n",
      "Epoch 11/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 10140315648.0000 - val_loss: 10120723456.0000\n",
      "Epoch 12/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 10021067776.0000 - val_loss: 10001033216.0000\n",
      "Epoch 13/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 9904478208.0000 - val_loss: 9885446144.0000\n",
      "Epoch 14/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 9791583232.0000 - val_loss: 9769665536.0000\n",
      "Epoch 15/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 9682139136.0000 - val_loss: 9656354816.0000\n",
      "Epoch 16/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 9574559744.0000 - val_loss: 9545527296.0000\n",
      "Epoch 17/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 9470452736.0000 - val_loss: 9439323136.0000\n",
      "Epoch 18/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 9369489408.0000 - val_loss: 9337817088.0000\n",
      "Epoch 19/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 9272924160.0000 - val_loss: 9246344192.0000\n",
      "Epoch 20/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 9181378560.0000 - val_loss: 9146330112.0000\n",
      "Epoch 21/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 9090534400.0000 - val_loss: 9064664064.0000\n",
      "Epoch 22/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 9007045632.0000 - val_loss: 8971335680.0000\n",
      "Epoch 23/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 8926093312.0000 - val_loss: 8888196096.0000\n",
      "Epoch 24/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 8849467392.0000 - val_loss: 8811456512.0000\n",
      "Epoch 25/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 8777017344.0000 - val_loss: 8741361664.0000\n",
      "Epoch 26/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 8708871168.0000 - val_loss: 8671036416.0000\n",
      "Epoch 27/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 8645251072.0000 - val_loss: 8604078080.0000\n",
      "Epoch 28/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 8584979456.0000 - val_loss: 8543305216.0000\n",
      "Epoch 29/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 8528074752.0000 - val_loss: 8484952064.0000\n",
      "Epoch 30/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 8476182528.0000 - val_loss: 8433835520.0000\n",
      "Epoch 31/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 8428274688.0000 - val_loss: 8382989312.0000\n",
      "Epoch 32/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 8383161856.0000 - val_loss: 8341225984.0000\n",
      "Epoch 33/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 8341789184.0000 - val_loss: 8300527616.0000\n",
      "Epoch 34/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 8302959104.0000 - val_loss: 8258050560.0000\n",
      "Epoch 35/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 8266682880.0000 - val_loss: 8218081280.0000\n",
      "Epoch 36/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 8232442880.0000 - val_loss: 8183986688.0000\n",
      "Epoch 37/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 8200702464.0000 - val_loss: 8151035904.0000\n",
      "Epoch 38/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 8169513984.0000 - val_loss: 8120657408.0000\n",
      "Epoch 39/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 8141296128.0000 - val_loss: 8090230784.0000\n",
      "Epoch 40/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 8113069568.0000 - val_loss: 8062860288.0000\n",
      "Epoch 41/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 8087588864.0000 - val_loss: 8038908928.0000\n",
      "Epoch 42/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 8062052864.0000 - val_loss: 8005960192.0000\n",
      "Epoch 43/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 8036896768.0000 - val_loss: 7980795392.0000\n",
      "Epoch 44/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 8013192192.0000 - val_loss: 7956751360.0000\n",
      "Epoch 45/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7990543872.0000 - val_loss: 7933165568.0000\n",
      "Epoch 46/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7969258496.0000 - val_loss: 7910562816.0000\n",
      "Epoch 47/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7946934784.0000 - val_loss: 7888377344.0000\n",
      "Epoch 48/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7926852096.0000 - val_loss: 7867352064.0000\n",
      "Epoch 49/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7907567104.0000 - val_loss: 7850007040.0000\n",
      "Epoch 50/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7887762432.0000 - val_loss: 7827075584.0000\n",
      "Epoch 51/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7868708864.0000 - val_loss: 7807223296.0000\n",
      "Epoch 52/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7849330176.0000 - val_loss: 7787736576.0000\n",
      "Epoch 53/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7831759360.0000 - val_loss: 7771740160.0000\n",
      "Epoch 54/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7814148096.0000 - val_loss: 7755090944.0000\n",
      "Epoch 55/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7796040704.0000 - val_loss: 7733974016.0000\n",
      "Epoch 56/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7780176896.0000 - val_loss: 7716681216.0000\n",
      "Epoch 57/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7763293184.0000 - val_loss: 7700784128.0000\n",
      "Epoch 58/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7748169216.0000 - val_loss: 7685430784.0000\n",
      "Epoch 59/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7732141056.0000 - val_loss: 7668022784.0000\n",
      "Epoch 60/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7717488128.0000 - val_loss: 7661807104.0000\n",
      "Epoch 61/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7702364160.0000 - val_loss: 7639492608.0000\n",
      "Epoch 62/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7686629888.0000 - val_loss: 7624736256.0000\n",
      "Epoch 63/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7673998848.0000 - val_loss: 7610419712.0000\n",
      "Epoch 64/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7660330496.0000 - val_loss: 7595704320.0000\n",
      "Epoch 65/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7644825088.0000 - val_loss: 7583399936.0000\n",
      "Epoch 66/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7633276928.0000 - val_loss: 7572284416.0000\n",
      "Epoch 67/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7621432832.0000 - val_loss: 7556137984.0000\n",
      "Epoch 68/500\n",
      "1117/1117 [==============================] - 5s 5ms/step - loss: 7607779840.0000 - val_loss: 7544889344.0000\n",
      "Epoch 69/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7596171264.0000 - val_loss: 7533301760.0000\n",
      "Epoch 70/500\n",
      "1117/1117 [==============================] - 5s 5ms/step - loss: 7584459264.0000 - val_loss: 7519480320.0000\n",
      "Epoch 71/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7573528064.0000 - val_loss: 7508048896.0000\n",
      "Epoch 72/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7561031168.0000 - val_loss: 7498460672.0000\n",
      "Epoch 73/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7549330944.0000 - val_loss: 7486845440.0000\n",
      "Epoch 74/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7540066304.0000 - val_loss: 7476455936.0000\n",
      "Epoch 75/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7530002432.0000 - val_loss: 7468615168.0000\n",
      "Epoch 76/500\n",
      "1117/1117 [==============================] - 5s 5ms/step - loss: 7519750656.0000 - val_loss: 7455274496.0000\n",
      "Epoch 77/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7509468672.0000 - val_loss: 7451329536.0000\n",
      "Epoch 78/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7500909056.0000 - val_loss: 7436038656.0000\n",
      "Epoch 79/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7490145792.0000 - val_loss: 7425781248.0000\n",
      "Epoch 80/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7480745472.0000 - val_loss: 7417638400.0000\n",
      "Epoch 81/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7471639040.0000 - val_loss: 7408455680.0000\n",
      "Epoch 82/500\n",
      "1117/1117 [==============================] - 5s 5ms/step - loss: 7462755328.0000 - val_loss: 7400390144.0000\n",
      "Epoch 83/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7454082048.0000 - val_loss: 7390737408.0000\n",
      "Epoch 84/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7444682240.0000 - val_loss: 7381841920.0000\n",
      "Epoch 85/500\n",
      "1117/1117 [==============================] - 5s 5ms/step - loss: 7435500032.0000 - val_loss: 7373397504.0000\n",
      "Epoch 86/500\n",
      "1117/1117 [==============================] - 5s 5ms/step - loss: 7427587584.0000 - val_loss: 7365693952.0000\n",
      "Epoch 87/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7419065856.0000 - val_loss: 7356933632.0000\n",
      "Epoch 88/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7411493376.0000 - val_loss: 7349094400.0000\n",
      "Epoch 89/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7402317312.0000 - val_loss: 7342132736.0000\n",
      "Epoch 90/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7394256384.0000 - val_loss: 7334051328.0000\n",
      "Epoch 91/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7387382272.0000 - val_loss: 7328545280.0000\n",
      "Epoch 92/500\n",
      "1117/1117 [==============================] - 6s 5ms/step - loss: 7379280384.0000 - val_loss: 7319845376.0000\n",
      "Epoch 93/500\n",
      "1117/1117 [==============================] - 6s 5ms/step - loss: 7371627520.0000 - val_loss: 7313243648.0000\n",
      "Epoch 94/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7364375040.0000 - val_loss: 7303827456.0000\n",
      "Epoch 95/500\n",
      "1117/1117 [==============================] - 5s 5ms/step - loss: 7354685440.0000 - val_loss: 7301654016.0000\n",
      "Epoch 96/500\n",
      "1117/1117 [==============================] - 5s 5ms/step - loss: 7349152768.0000 - val_loss: 7289763840.0000\n",
      "Epoch 97/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7340669440.0000 - val_loss: 7283255296.0000\n",
      "Epoch 98/500\n",
      "1117/1117 [==============================] - 5s 5ms/step - loss: 7334182912.0000 - val_loss: 7276857856.0000\n",
      "Epoch 99/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7327541760.0000 - val_loss: 7270115840.0000\n",
      "Epoch 100/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7320842240.0000 - val_loss: 7262159872.0000\n",
      "Epoch 101/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7312084992.0000 - val_loss: 7256453120.0000\n",
      "Epoch 102/500\n",
      "1117/1117 [==============================] - 5s 5ms/step - loss: 7305690624.0000 - val_loss: 7249043968.0000\n",
      "Epoch 103/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7300487680.0000 - val_loss: 7242528256.0000\n",
      "Epoch 104/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7291514368.0000 - val_loss: 7253798400.0000\n",
      "Epoch 105/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7286914048.0000 - val_loss: 7230646272.0000\n",
      "Epoch 106/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7278006784.0000 - val_loss: 7232833536.0000\n",
      "Epoch 107/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7273126912.0000 - val_loss: 7218065920.0000\n",
      "Epoch 108/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7266525184.0000 - val_loss: 7211197952.0000\n",
      "Epoch 109/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7259694080.0000 - val_loss: 7204792832.0000\n",
      "Epoch 110/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7253142528.0000 - val_loss: 7202087424.0000\n",
      "Epoch 111/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7246909440.0000 - val_loss: 7193025536.0000\n",
      "Epoch 112/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7239128576.0000 - val_loss: 7188864512.0000\n",
      "Epoch 113/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7234093056.0000 - val_loss: 7182864896.0000\n",
      "Epoch 114/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7227244032.0000 - val_loss: 7178395136.0000\n",
      "Epoch 115/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7221370368.0000 - val_loss: 7168953856.0000\n",
      "Epoch 116/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7214634496.0000 - val_loss: 7163211264.0000\n",
      "Epoch 117/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7208716800.0000 - val_loss: 7157711360.0000\n",
      "Epoch 118/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7201382912.0000 - val_loss: 7156337664.0000\n",
      "Epoch 119/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7196269056.0000 - val_loss: 7150680576.0000\n",
      "Epoch 120/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7189767168.0000 - val_loss: 7140836352.0000\n",
      "Epoch 121/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7184989696.0000 - val_loss: 7134695936.0000\n",
      "Epoch 122/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7177179136.0000 - val_loss: 7129095680.0000\n",
      "Epoch 123/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7171903488.0000 - val_loss: 7123469312.0000\n",
      "Epoch 124/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7167591424.0000 - val_loss: 7117613568.0000\n",
      "Epoch 125/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7160077824.0000 - val_loss: 7112139776.0000\n",
      "Epoch 126/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7154764288.0000 - val_loss: 7108071424.0000\n",
      "Epoch 127/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7148539904.0000 - val_loss: 7100951040.0000\n",
      "Epoch 128/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 7142718976.0000 - val_loss: 7095474176.0000\n",
      "Epoch 129/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7136513536.0000 - val_loss: 7089981952.0000\n",
      "Epoch 130/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7131141632.0000 - val_loss: 7089029632.0000\n",
      "Epoch 131/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7124105728.0000 - val_loss: 7079515136.0000\n",
      "Epoch 132/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7118781952.0000 - val_loss: 7074315776.0000\n",
      "Epoch 133/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7113846784.0000 - val_loss: 7068657664.0000\n",
      "Epoch 134/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7107274240.0000 - val_loss: 7066915328.0000\n",
      "Epoch 135/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7101518336.0000 - val_loss: 7059360768.0000\n",
      "Epoch 136/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7096175616.0000 - val_loss: 7053472768.0000\n",
      "Epoch 137/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7089955840.0000 - val_loss: 7048918016.0000\n",
      "Epoch 138/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7085005824.0000 - val_loss: 7042911232.0000\n",
      "Epoch 139/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7078302720.0000 - val_loss: 7045969920.0000\n",
      "Epoch 140/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7073336320.0000 - val_loss: 7031509504.0000\n",
      "Epoch 141/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7067028992.0000 - val_loss: 7026344960.0000\n",
      "Epoch 142/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7061991424.0000 - val_loss: 7023196160.0000\n",
      "Epoch 143/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7055591424.0000 - val_loss: 7016875008.0000\n",
      "Epoch 144/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7050647552.0000 - val_loss: 7010905088.0000\n",
      "Epoch 145/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7044863488.0000 - val_loss: 7014523904.0000\n",
      "Epoch 146/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7039758848.0000 - val_loss: 7001985536.0000\n",
      "Epoch 147/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7034419200.0000 - val_loss: 6996024320.0000\n",
      "Epoch 148/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7028680704.0000 - val_loss: 6993121792.0000\n",
      "Epoch 149/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7022793216.0000 - val_loss: 6985694208.0000\n",
      "Epoch 150/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7017734144.0000 - val_loss: 6982268416.0000\n",
      "Epoch 151/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 7011442688.0000 - val_loss: 6981904384.0000\n",
      "Epoch 152/500\n",
      "1117/1117 [==============================] - 5s 5ms/step - loss: 7007046656.0000 - val_loss: 6970910720.0000\n",
      "Epoch 153/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 7001744384.0000 - val_loss: 6968315904.0000\n",
      "Epoch 154/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6996078080.0000 - val_loss: 6965716480.0000\n",
      "Epoch 155/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6991763968.0000 - val_loss: 6957345792.0000\n",
      "Epoch 156/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6985752064.0000 - val_loss: 6952022016.0000\n",
      "Epoch 157/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6981412352.0000 - val_loss: 6947987968.0000\n",
      "Epoch 158/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6975037440.0000 - val_loss: 6942300160.0000\n",
      "Epoch 159/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6970140672.0000 - val_loss: 6937829888.0000\n",
      "Epoch 160/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6964442112.0000 - val_loss: 6932832256.0000\n",
      "Epoch 161/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6959558656.0000 - val_loss: 6934113792.0000\n",
      "Epoch 162/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6954560512.0000 - val_loss: 6923531776.0000\n",
      "Epoch 163/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6948989440.0000 - val_loss: 6919761920.0000\n",
      "Epoch 164/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6944863744.0000 - val_loss: 6915092480.0000\n",
      "Epoch 165/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6939124736.0000 - val_loss: 6909902848.0000\n",
      "Epoch 166/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6934967296.0000 - val_loss: 6906731008.0000\n",
      "Epoch 167/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6929640448.0000 - val_loss: 6906185216.0000\n",
      "Epoch 168/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6924185600.0000 - val_loss: 6896970752.0000\n",
      "Epoch 169/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6920238592.0000 - val_loss: 6892379136.0000\n",
      "Epoch 170/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6915480064.0000 - val_loss: 6887342592.0000\n",
      "Epoch 171/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 6911874048.0000 - val_loss: 6882629120.0000\n",
      "Epoch 172/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6904466432.0000 - val_loss: 6888067072.0000\n",
      "Epoch 173/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 6900466176.0000 - val_loss: 6882968064.0000\n",
      "Epoch 174/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6895087104.0000 - val_loss: 6869967872.0000\n",
      "Epoch 175/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6890155008.0000 - val_loss: 6865227264.0000\n",
      "Epoch 176/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6884649472.0000 - val_loss: 6867088896.0000\n",
      "Epoch 177/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6881165312.0000 - val_loss: 6856875520.0000\n",
      "Epoch 178/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6876823552.0000 - val_loss: 6852918272.0000\n",
      "Epoch 179/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6872183808.0000 - val_loss: 6848460800.0000\n",
      "Epoch 180/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6867926016.0000 - val_loss: 6849778176.0000\n",
      "Epoch 181/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6863552000.0000 - val_loss: 6840920576.0000\n",
      "Epoch 182/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6858691072.0000 - val_loss: 6836314112.0000\n",
      "Epoch 183/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6852647936.0000 - val_loss: 6832737280.0000\n",
      "Epoch 184/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6849411072.0000 - val_loss: 6827918336.0000\n",
      "Epoch 185/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6844883968.0000 - val_loss: 6824417280.0000\n",
      "Epoch 186/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6840237056.0000 - val_loss: 6820241920.0000\n",
      "Epoch 187/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6835426304.0000 - val_loss: 6820210176.0000\n",
      "Epoch 188/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6831574016.0000 - val_loss: 6814218752.0000\n",
      "Epoch 189/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6826305536.0000 - val_loss: 6808111616.0000\n",
      "Epoch 190/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 6822839808.0000 - val_loss: 6804434944.0000\n",
      "Epoch 191/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 6819065856.0000 - val_loss: 6800339456.0000\n",
      "Epoch 192/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 6815556096.0000 - val_loss: 6797420544.0000\n",
      "Epoch 193/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 6809804288.0000 - val_loss: 6794608128.0000\n",
      "Epoch 194/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6805723648.0000 - val_loss: 6789380096.0000\n",
      "Epoch 195/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 6801911808.0000 - val_loss: 6785940992.0000\n",
      "Epoch 196/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6798066688.0000 - val_loss: 6781665792.0000\n",
      "Epoch 197/500\n",
      "1117/1117 [==============================] - 5s 5ms/step - loss: 6794529280.0000 - val_loss: 6779151872.0000\n",
      "Epoch 198/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6789318144.0000 - val_loss: 6775713792.0000\n",
      "Epoch 199/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6786754560.0000 - val_loss: 6771826688.0000\n",
      "Epoch 200/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6781685760.0000 - val_loss: 6767311360.0000\n",
      "Epoch 201/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 6777701376.0000 - val_loss: 6763835392.0000\n",
      "Epoch 202/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6774201856.0000 - val_loss: 6760987648.0000\n",
      "Epoch 203/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6769993216.0000 - val_loss: 6761359872.0000\n",
      "Epoch 204/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6767090688.0000 - val_loss: 6754087424.0000\n",
      "Epoch 205/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6762320384.0000 - val_loss: 6750026240.0000\n",
      "Epoch 206/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6758755840.0000 - val_loss: 6751167488.0000\n",
      "Epoch 207/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6754132480.0000 - val_loss: 6746984960.0000\n",
      "Epoch 208/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6751215616.0000 - val_loss: 6741378560.0000\n",
      "Epoch 209/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6747553280.0000 - val_loss: 6737047040.0000\n",
      "Epoch 210/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6744758272.0000 - val_loss: 6734078976.0000\n",
      "Epoch 211/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6740760064.0000 - val_loss: 6734789632.0000\n",
      "Epoch 212/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6737278464.0000 - val_loss: 6727545344.0000\n",
      "Epoch 213/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6735040000.0000 - val_loss: 6730487296.0000\n",
      "Epoch 214/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6730192384.0000 - val_loss: 6731975680.0000\n",
      "Epoch 215/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6727534592.0000 - val_loss: 6718588416.0000\n",
      "Epoch 216/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6723299840.0000 - val_loss: 6717312000.0000\n",
      "Epoch 217/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6720544256.0000 - val_loss: 6711904768.0000\n",
      "Epoch 218/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6716731392.0000 - val_loss: 6709306368.0000\n",
      "Epoch 219/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6713167872.0000 - val_loss: 6706000896.0000\n",
      "Epoch 220/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6709947392.0000 - val_loss: 6704208384.0000\n",
      "Epoch 221/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6706846720.0000 - val_loss: 6704381440.0000\n",
      "Epoch 222/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6704081408.0000 - val_loss: 6697958400.0000\n",
      "Epoch 223/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6700841984.0000 - val_loss: 6694325248.0000\n",
      "Epoch 224/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6697156096.0000 - val_loss: 6691561472.0000\n",
      "Epoch 225/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6693669888.0000 - val_loss: 6688809472.0000\n",
      "Epoch 226/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6691147264.0000 - val_loss: 6688663040.0000\n",
      "Epoch 227/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 6686273536.0000 - val_loss: 6683991552.0000\n",
      "Epoch 228/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6683996672.0000 - val_loss: 6682283520.0000\n",
      "Epoch 229/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6681699328.0000 - val_loss: 6690249728.0000\n",
      "Epoch 230/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6679389696.0000 - val_loss: 6678664192.0000\n",
      "Epoch 231/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6677051392.0000 - val_loss: 6673160192.0000\n",
      "Epoch 232/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6673808896.0000 - val_loss: 6670668800.0000\n",
      "Epoch 233/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6670948352.0000 - val_loss: 6670835200.0000\n",
      "Epoch 234/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6668180992.0000 - val_loss: 6665775616.0000\n",
      "Epoch 235/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6665008640.0000 - val_loss: 6667716096.0000\n",
      "Epoch 236/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6663176704.0000 - val_loss: 6660959232.0000\n",
      "Epoch 237/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6659214336.0000 - val_loss: 6668909568.0000\n",
      "Epoch 238/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6657971712.0000 - val_loss: 6667278848.0000\n",
      "Epoch 239/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6656360960.0000 - val_loss: 6662394880.0000\n",
      "Epoch 240/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6652254208.0000 - val_loss: 6653166080.0000\n",
      "Epoch 241/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6649172992.0000 - val_loss: 6650473984.0000\n",
      "Epoch 242/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6647023104.0000 - val_loss: 6650146816.0000\n",
      "Epoch 243/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6645760512.0000 - val_loss: 6645394432.0000\n",
      "Epoch 244/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6641701888.0000 - val_loss: 6644342784.0000\n",
      "Epoch 245/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6639593472.0000 - val_loss: 6643841024.0000\n",
      "Epoch 246/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6638018048.0000 - val_loss: 6642251776.0000\n",
      "Epoch 247/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6634533376.0000 - val_loss: 6646953472.0000\n",
      "Epoch 248/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6634144768.0000 - val_loss: 6637296128.0000\n",
      "Epoch 249/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6630376448.0000 - val_loss: 6633436672.0000\n",
      "Epoch 250/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6628244480.0000 - val_loss: 6634000896.0000\n",
      "Epoch 251/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6626519552.0000 - val_loss: 6635830784.0000\n",
      "Epoch 252/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6624796160.0000 - val_loss: 6627395072.0000\n",
      "Epoch 253/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6621954048.0000 - val_loss: 6626309632.0000\n",
      "Epoch 254/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6620585472.0000 - val_loss: 6625823744.0000\n",
      "Epoch 255/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6617684992.0000 - val_loss: 6621972992.0000\n",
      "Epoch 256/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 6616667648.0000 - val_loss: 6623538688.0000\n",
      "Epoch 257/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6615172608.0000 - val_loss: 6618765824.0000\n",
      "Epoch 258/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6613082624.0000 - val_loss: 6616872448.0000\n",
      "Epoch 259/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6609725440.0000 - val_loss: 6617910784.0000\n",
      "Epoch 260/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6607219712.0000 - val_loss: 6613750272.0000\n",
      "Epoch 261/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6605375488.0000 - val_loss: 6612344320.0000\n",
      "Epoch 262/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 6604819968.0000 - val_loss: 6611319808.0000\n",
      "Epoch 263/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 6603698688.0000 - val_loss: 6610460672.0000\n",
      "Epoch 264/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6601527296.0000 - val_loss: 6611139584.0000\n",
      "Epoch 265/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6598583808.0000 - val_loss: 6611910656.0000\n",
      "Epoch 266/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6598808064.0000 - val_loss: 6604672512.0000\n",
      "Epoch 267/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6596736512.0000 - val_loss: 6603028480.0000\n",
      "Epoch 268/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6594487296.0000 - val_loss: 6607513600.0000\n",
      "Epoch 269/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6592680448.0000 - val_loss: 6606565888.0000\n",
      "Epoch 270/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6591133184.0000 - val_loss: 6600579584.0000\n",
      "Epoch 271/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6590740480.0000 - val_loss: 6597741568.0000\n",
      "Epoch 272/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6588335104.0000 - val_loss: 6600363008.0000\n",
      "Epoch 273/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6587024384.0000 - val_loss: 6594877952.0000\n",
      "Epoch 274/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 6585794560.0000 - val_loss: 6593823744.0000\n",
      "Epoch 275/500\n",
      "1117/1117 [==============================] - 5s 5ms/step - loss: 6584267776.0000 - val_loss: 6595097600.0000\n",
      "Epoch 276/500\n",
      "1117/1117 [==============================] - 5s 4ms/step - loss: 6583002112.0000 - val_loss: 6591165440.0000\n",
      "Epoch 277/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6580546048.0000 - val_loss: 6595240960.0000\n",
      "Epoch 278/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6579063296.0000 - val_loss: 6590546944.0000\n",
      "Epoch 279/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6579435520.0000 - val_loss: 6588765184.0000\n",
      "Epoch 280/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6577633280.0000 - val_loss: 6588383744.0000\n",
      "Epoch 281/500\n",
      "1117/1117 [==============================] - 4s 3ms/step - loss: 6575155200.0000 - val_loss: 6586860544.0000\n",
      "Epoch 282/500\n",
      "1117/1117 [==============================] - 4s 4ms/step - loss: 6575210496.0000 - val_loss: 6585363456.0000\n",
      "Epoch 283/500\n",
      " 347/1117 [========>.....................] - ETA: 3s - loss: 6632877568.0000"
     ]
    }
   ],
   "source": [
    "val_split = 0.1\n",
    "min_delta=0 #10, #50, #10, #50,\n",
    "\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", #\"loss\", #\"val_loss\",\n",
    "    min_delta=min_delta, \n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True # False,\n",
    ")\n",
    "\n",
    "pipe_start = time()\n",
    "\n",
    "history = trainable_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=chosen_epochs,\n",
    "    # verbose=0 to suppress logging.\n",
    "    verbose=1,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split=val_split,  #0.2,\n",
    "    callbacks=[callback],\n",
    ")\n",
    "pipe_end = time()\n",
    "estimated_time = round((pipe_end - pipe_start), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:52:43.793240Z",
     "iopub.status.busy": "2022-12-01T11:52:43.792288Z",
     "iopub.status.idle": "2022-12-01T11:52:43.795972Z",
     "shell.execute_reply": "2022-12-01T11:52:43.795421Z",
     "shell.execute_reply.started": "2022-12-01T11:52:43.793223Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#ALGORITHM_DETAIL.replace(\"epochs=\", f\"epochs={len(hist)}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Get the results and print some graphs\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:52:43.797437Z",
     "iopub.status.busy": "2022-12-01T11:52:43.796751Z",
     "iopub.status.idle": "2022-12-01T11:52:43.808970Z",
     "shell.execute_reply": "2022-12-01T11:52:43.808424Z",
     "shell.execute_reply.started": "2022-12-01T11:52:43.797421Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "early_end_lossX = hist.iloc[-1]['loss']\n",
    "early_end_loss = hist['loss'].min()\n",
    "early_end_valloss = hist['val_loss'].min()\n",
    "\n",
    "more_detail = f\"loss={round(early_end_loss,2)} valloss={round(early_end_valloss,2)}\"\n",
    "more_detail = f\"loss={early_end_loss:.2e} valloss={early_end_valloss:.2e}\"\n",
    "more_detail += f' +valsplit={val_split}'\n",
    "\n",
    "# f\"{x:.2e}\"\n",
    "\n",
    "if len(hist) != chosen_epochs:\n",
    "    print(f'stopped at {len(hist)}, loss={round(early_end_loss,2)} valloss={round(early_end_valloss,2)}')\n",
    "    #ALGORITHM_DETAIL += f\" +stop={len(hist)}\"\n",
    "    more_detail += f\" stop={len(hist)}/{chosen_epochs} \"\n",
    "    #more_detail += ALGORITHM_DETAIL.replace(\"epochs=\", f\"epochs={len(hist)}/\")\n",
    "\n",
    "\n",
    "if price_divisor!=1:\n",
    "    print('in preprocessing, divided all Prices by ', price_divisor)\n",
    "    more_detail += f' div={price_divisor}'\n",
    "\n",
    "\n",
    "print(more_detail)\n",
    "print(ALGORITHM_DETAIL)\n",
    "    \n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:52:43.810320Z",
     "iopub.status.busy": "2022-12-01T11:52:43.809749Z",
     "iopub.status.idle": "2022-12-01T11:52:43.937042Z",
     "shell.execute_reply": "2022-12-01T11:52:43.936118Z",
     "shell.execute_reply.started": "2022-12-01T11:52:43.810302Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    loss_fig, loss_ax = plt.subplots()\n",
    "    loss_ax.plot(history.history['loss'], label='loss')\n",
    "    loss_ax.plot(history.history['val_loss'], label='val_loss')\n",
    "    #plt.ylim([0, 10])\n",
    "    min_y = min(min(history.history['val_loss']),min(history.history['loss'])) - 100\n",
    "    #max_y = min(max(history.history['val_loss']),max(history.history['loss'])) + 500\n",
    "    #max_y = min(sorted(history.history['val_loss'])[-3],sorted(history.history['loss'])[-3]) + 100\n",
    "    max_y = min(sorted(history.history['val_loss'])[-1],sorted(history.history['val_loss'])[-1])\n",
    "    \n",
    "    print(max_y - min_y)\n",
    "    ticks = (max_y - min_y)/10\n",
    "    print(ticks)\n",
    "    \n",
    "    plt.ylim([min_y, max_y])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [Property Price]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.yticks(np.arange(min_y, max_y, ticks))  # JHJH\n",
    "    return loss_fig, loss_ax\n",
    "\n",
    "loss_fig, loss_ax = plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:52:43.939193Z",
     "iopub.status.busy": "2022-12-01T11:52:43.938272Z",
     "iopub.status.idle": "2022-12-01T11:52:44.457220Z",
     "shell.execute_reply": "2022-12-01T11:52:44.456259Z",
     "shell.execute_reply.started": "2022-12-01T11:52:43.939161Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = trainable_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:52:44.459290Z",
     "iopub.status.busy": "2022-12-01T11:52:44.458653Z",
     "iopub.status.idle": "2022-12-01T11:52:44.466580Z",
     "shell.execute_reply": "2022-12-01T11:52:44.465797Z",
     "shell.execute_reply.started": "2022-12-01T11:52:44.459264Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = y_pred.reshape((-1, 1))\n",
    "\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = math.sqrt(MSE)\n",
    "print('-' * 10 + ALGORITHM + '-' * 10)\n",
    "print('R square Accuracy', R2)\n",
    "print('Mean Absolute Error Accuracy', MAE)\n",
    "print('Mean Squared Error Accuracy', MSE)\n",
    "print('Root Mean Squared Error', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:52:44.470280Z",
     "iopub.status.busy": "2022-12-01T11:52:44.469617Z",
     "iopub.status.idle": "2022-12-01T11:52:44.474109Z",
     "shell.execute_reply": "2022-12-01T11:52:44.473342Z",
     "shell.execute_reply.started": "2022-12-01T11:52:44.470255Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    print(y_test_index.reshape((-1, 1)).shape);\n",
    "    print(y_pred.reshape((-1, 1)).shape);\n",
    "    print(y_test.shape);\n",
    "    print(y_test_index.shape);\n",
    "    print(y_pred.shape);\n",
    "    print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:52:44.475657Z",
     "iopub.status.busy": "2022-12-01T11:52:44.475420Z",
     "iopub.status.idle": "2022-12-01T11:52:44.493166Z",
     "shell.execute_reply": "2022-12-01T11:52:44.492309Z",
     "shell.execute_reply.started": "2022-12-01T11:52:44.475637Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "compare = np.hstack((y_test_index, y_test, y_pred))\n",
    "compare_df = DataFrame(compare, columns=['reference', 'actual', 'predicted'])\n",
    "compare_df['difference'] = abs(compare_df['actual'] - compare_df['predicted'])\n",
    "compare_df['diff 1 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['actual'] * 100)\n",
    "compare_df['diff 2 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['predicted']) * 100\n",
    "compare_df['reference'] = compare_df['reference'].astype(int)\n",
    "compare_df.set_index('reference', inplace=True)\n",
    "\n",
    "combined = compare_df.merge(df[columns], how='inner', left_index=True, right_index=True).sort_values(['diff 1 %'],\n",
    "                                                                                                     ascending=False)\n",
    "#pd.options.display.float_format = '{:.4f}'.format\n",
    "combined[['predicted', 'actual', 'Price', 'bedrooms', 'bathrooms']] = combined[\n",
    "    ['predicted', 'actual', 'Price', 'bedrooms', 'bathrooms']].astype(int)\n",
    "combined['bedrooms'] = combined['bedrooms'].astype(int)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:52:44.521241Z",
     "iopub.status.busy": "2022-12-01T11:52:44.521009Z",
     "iopub.status.idle": "2022-12-01T11:52:45.007152Z",
     "shell.execute_reply": "2022-12-01T11:52:45.006473Z",
     "shell.execute_reply.started": "2022-12-01T11:52:44.521221Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "best_model_fig, best_model_ax = plt.subplots()\n",
    "best_model_ax.scatter(y_test, y_pred, edgecolors=(0, 0, 1))\n",
    "best_model_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "best_model_ax.set_ylabel('Predicted')\n",
    "best_model_ax.set_xlabel('Actual')\n",
    "#ax.title.set_text(f'CV Chosen best option ({calculated_best_pipe[1]})')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Evaluate the model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:52:45.008345Z",
     "iopub.status.busy": "2022-12-01T11:52:45.008104Z",
     "iopub.status.idle": "2022-12-01T11:52:45.399964Z",
     "shell.execute_reply": "2022-12-01T11:52:45.399218Z",
     "shell.execute_reply.started": "2022-12-01T11:52:45.008324Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cv_best_model_fit_time = estimated_time\n",
    "\n",
    "DD2 = \"(\" + \",\".join(DATA_DETAIL) + \")\" if len(DATA_DETAIL) >= 1 else \"\"\n",
    "key = f'{ALGORITHM} (v{VERSION})'.lower()\n",
    "\n",
    "method = f\"{ALGORITHM_DETAIL}{DD2}\"\n",
    "\n",
    "new_results = {\n",
    "    #'_score': score,\n",
    "    '_score': R2,\n",
    "    'R square Accuracy': R2,\n",
    "    'Mean Absolute Error Accuracy': MAE * price_divisor,\n",
    "    'Mean Squared Error Accuracy': MSE * price_divisor,\n",
    "    'Root Mean Squared Error': RMSE * price_divisor,\n",
    "    '_train time': cv_best_model_fit_time,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'date': str(datetime.now()),\n",
    "    #'_params': crossval_runner.best_params_ if not_catboost else cat_params,\n",
    "    #'_params': 'not available', # REPLACED - can't have different models all saying params not available\n",
    "    '_params': ALGORITHM_DETAIL,\n",
    "    '_method': more_detail, #ALGORITHM_DETAIL,\n",
    "    'run_env': run_env\n",
    "}\n",
    "\n",
    "if run_env not in ['colab']:\n",
    "    old_results_json = get_results()\n",
    "    try:\n",
    "        old_best_score = old_results_json[key]['best score']\n",
    "    except:\n",
    "        print(f\"haven't scored this model yet: {ALGORITHM}\")\n",
    "        old_best_score = -999\n",
    "    this_model_is_best = update_results(old_results_json, new_results, key)\n",
    "\n",
    "print(key)\n",
    "print(ALGORITHM_DETAIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T11:52:45.401555Z",
     "iopub.status.busy": "2022-12-01T11:52:45.401011Z",
     "iopub.status.idle": "2022-12-01T11:52:48.308923Z",
     "shell.execute_reply": "2022-12-01T11:52:48.307992Z",
     "shell.execute_reply.started": "2022-12-01T11:52:45.401531Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if this_model_is_best:\n",
    "    with open(f'../../../models/optimised_model_{ALGORITHM}_v{VERSION}{DD2}.pkl', 'wb') as f:\n",
    "        pickle.dump(trainable_model, f)\n",
    "        new_model_decision = f\"pickled new version of model\\n{old_results_json[key]['_score']} is new best score (it's better than {old_best_score})\"\n",
    "        #print(results_json[key]['_score'], 'is an improvement on', results_json[key]['second best score'])\n",
    "else:\n",
    "    new_model_decision = f\"not updated saved model, the previous run was better\\n{old_results_json[key]['_score']} is worse than or equal to {old_best_score}\"\n",
    "\n",
    "print(new_model_decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Write the final report for this algorithm and dataset version"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def include_in_html_report(type, section_header=None, section_figure=None, section_content=None, section_content_list=None):\n",
    "\n",
    "    # writePath_html = r'model_results/%s (html).html' % key\n",
    "    # writePath_md = r'model_results/%s (md).md' % key\n",
    "    results_root = '../../F_evaluate_model'\n",
    "    writePath_html = f'{results_root}/html/{key}.html'.replace(\" \", \"_\").replace(\"(\", \"_\").replace(\")\", \"_\")\n",
    "    writePath_md = f'{results_root}/markdown/{key}.md'\n",
    "\n",
    "#isinstance(ini_list2, list)\n",
    "    if not section_content_list:\n",
    "        section_content_list = [section_content]\n",
    "\n",
    "    if type == 'header':\n",
    "        w = 'w' if section_figure <= 1 else 'a'\n",
    "        with open(writePath_html, w) as f1:\n",
    "            headers = f'<h{section_figure}>{section_content}</h{section_figure}>'\n",
    "            f1.write(headers)\n",
    "        with open(writePath_md, w) as f2:\n",
    "            headers = f'{\"#\" * int(section_figure)} {section_content }\\n'\n",
    "            f2.write(headers)\n",
    "    else:\n",
    "        if section_header:\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                f1.write(f'<h3>{section_header}</h3>')\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                f2.write(f'### {section_header}\\n')\n",
    "\n",
    "        if type=='dataframe':\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                dfAsString = section_content.to_html()\n",
    "                f1.write(dfAsString)\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                dfAsString = section_content.to_markdown()\n",
    "                f2.write(dfAsString + '\\n\\n')\n",
    "        elif type=='graph':\n",
    "            filename = key + \"_\" + section_content\n",
    "            #section_figure.savefig(f'model_results/artifacts/{filename.replace(\" \", \"_\")}')\n",
    "            section_figure.savefig(f'{results_root}/artifacts/{filename.replace(\" \", \"_\").replace(\"(\", \"_\").replace(\")\", \"_\")}')\n",
    "\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                dfAsString = f'<img src=\"../artifacts/{filename.replace(\" \",\"_\").replace(\"(\", \"_\").replace(\")\", \"_\")}\"/>'\n",
    "                f1.write(dfAsString)\n",
    "\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                #dfAsString = f'(./model_results/artifacts/{filename}) \\n'\n",
    "                #dfAsString = f'![detail](./artifacts/{filename.replace(\" \",\"_\")})'\n",
    "                dfAsString = f'![detail](../artifacts/{filename.replace(\" \",\"_\").replace(\"(\", \"_\").replace(\")\", \"_\")})'\n",
    "                f2.write(dfAsString)\n",
    "                f2.write('\\n\\n')\n",
    "        elif type=='json':\n",
    "\n",
    "            # html_content_parsed = [[cell.text for cell in row(\"td\")]\n",
    "            #              for row in BeautifulSoup(content,features=\"html.parser\")(\"tr\")]\n",
    "            #\n",
    "            # html_content_dictionary = {element[0]:element[1:] for element in html_content_parsed}\n",
    "\n",
    "            #xxxprint(json.dumps(html_content_dictionary, indent=4))\n",
    "\n",
    "\n",
    "\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                #f.write(json.dumps(html_content_dictionary, indent=4))\n",
    "                soup = BeautifulSoup(section_content, \"html.parser\")\n",
    "                f1.write(str(soup.prettify()))\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                #f.write(json.dumps(html_content_dictionary, indent=4))\n",
    "                soup = BeautifulSoup(section_content, \"html.parser\")\n",
    "                #f2.write(str(soup.prettify()))\n",
    "\n",
    "\n",
    "                # html_content_dictionary = {element[0]:element[1:] for element in html_content_parsed}\n",
    "                # f2.write(json.dumps(html_content_dictionary, indent=4))\n",
    "\n",
    "                import ast\n",
    "                loads = ast.literal_eval(section_content)\n",
    "                #df = pd.DataFrame.from_dict(loads)\n",
    "                #df.drop(['dont'], axis=1, inplace=True)\n",
    "                #print(df.to_markdown(index=False,tablefmt='fancy_grid'))\n",
    "                for each in loads:\n",
    "                    f2.write(each + \" = \" + str(loads[each]) + \"\\n\\n\")\n",
    "\n",
    "        elif type=='dict':\n",
    "\n",
    "            for section_content in section_content_list:\n",
    "                if isinstance(section_content, str):\n",
    "                    import ast\n",
    "                    section_content = ast.literal_eval(section_content)\n",
    "\n",
    "                with open(writePath_html, 'a') as f1:\n",
    "                    soup = BeautifulSoup(str(section_content), \"html.parser\")\n",
    "                    f1.write(str(soup.prettify()))\n",
    "                with open(writePath_md, 'a') as f2:\n",
    "                    for each in section_content:\n",
    "                        f2.write(each + \" = \" + str(section_content[each]) + \"\\n\\n\")\n",
    "\n",
    "        elif type=='text':\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                for each_line in section_content_list:\n",
    "                    f1.write(each_line + '<br>')\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                for each_line in section_content_list:\n",
    "                    f2.write(each_line + '\\n\\n')\n",
    "\n",
    "        with open(writePath_html, 'a') as f1:\n",
    "            f1.write('<hr>')\n",
    "\n",
    "\n",
    "include_in_html_report(\"header\", section_content=f\"Results from {ALGORITHM}\", section_figure=1)\n",
    "\n",
    "end_timestamp = datetime.now()\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=f\"Dataset Version: {VERSION}\", section_content_list=[\n",
    "    f\"Date run: {datetime.now()}\"\n",
    "    \"\",\n",
    "    f\"Start time: {start_timestamp}\",\n",
    "    f\"End time: {end_timestamp}\",\n",
    "])\n",
    "\n",
    "include_in_html_report(\"header\", section_content=f\"Results\", section_figure=2)\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=\"Summary\", section_content=new_model_decision)\n",
    "\n",
    "\n",
    "include_in_html_report(type='graph', section_header=\"Best Model: Comparing model predictions to actual property values\", section_figure=best_model_fig, section_content='best_ann_model.png')\n",
    "\n",
    "#include_in_html_report(type=\"dataframe\",text_single=\"Tuned Models ranked by performance\", content=cv_results_df_sorted)\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=\"Model Specific Notes\", section_content_list=[\"can't display hyperparameter comparison for neural network\",\"can't display model performance graphs for neural network\",\"can't display model performance graphs for neural network\"])\n",
    "\n",
    "include_in_html_report(type=\"dataframe\", section_header=\"Neural Network Loss - Head\", section_content=hist.head())\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=None, section_content='')\n",
    "\n",
    "include_in_html_report(type=\"dataframe\", section_header=\"Neural Network Loss - Tail\", section_content=hist.tail())\n",
    "\n",
    "\n",
    "include_in_html_report(type='graph', section_header=None, section_figure=loss_fig, section_content='end_loss.png')\n",
    "\n",
    "import io\n",
    "def get_model_summary(model):\n",
    "    stream = io.StringIO()\n",
    "    model.summary(line_length=160, print_fn=lambda x: stream.write('>' + x.replace('-','').replace('=','') + '\\n'))\n",
    "    summary_string = stream.getvalue()\n",
    "    stream.close()\n",
    "    return summary_string\n",
    "\n",
    "short_model_summary = get_model_summary(trainable_model)\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=\"Model Structure\", section_content=short_model_summary)\n",
    "\n",
    "include_in_html_report(\"header\", section_content=f\"Comparison with other models\", section_figure=2)\n",
    "\n",
    "\n",
    "dff = pd.read_json('../../../results/results.json')\n",
    "\n",
    "version = VERSION\n",
    "\n",
    "\n",
    "all_models_df = dff[dff.columns].T.sort_values(\"best score\", ascending=False)\n",
    "version_models_df = dff[[c for c in dff.columns if version in c]].T.sort_values(\"best score\", ascending=False)\n",
    "\n",
    "version_models_summary = version_models_df[['best score', 'best time', 'Mean Absolute Error Accuracy', 'Mean Squared Error Accuracy', 'R square Accuracy', 'Root Mean Squared Error', 'best run date', 'best method']]\n",
    "all_models_summary = all_models_df[['best score', 'best time', 'Mean Absolute Error Accuracy', 'Mean Squared Error Accuracy', 'R square Accuracy', 'Root Mean Squared Error', 'best run date', 'best method']]\n",
    "\n",
    "include_in_html_report(type=\"dataframe\", section_header=f\"Comparison with version {VERSION} performances\", section_content=version_models_summary)\n",
    "include_in_html_report(type=\"dataframe\", section_header=\"Comparison with all model performances\", section_content=all_models_summary)\n",
    "\n",
    "\n",
    "include_in_html_report(\"header\", section_content=f\"Appendix\", section_figure=2)\n",
    "\n",
    "include_in_html_report(type=\"dataframe\", section_header=\"Data Sample\", section_content=df.head(5))\n",
    "\n",
    "if False:\n",
    "    include_in_html_report(type=\"json\", section_header=\"Hyperparameter options for Randomized Grid Search\", section_content=f\"{param_options if not using_catboost else options_block}\")\n",
    "else:\n",
    "\n",
    "    include_in_html_report(type=\"text\", section_header=\"FIX THIS!!\", section_content=\"FIX THIS!\")\n",
    "\n",
    "include_in_html_report(type=\"dict\", section_header=\"Environment Variables\", section_content=env_vars)\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=\"Useful info\",\n",
    "                       section_content_list=[f\"Tensorflow version: {tf.__version__}\"\n",
    "                                        ])\n",
    "\n",
    "\n",
    "def print_and_report(text_single, title):\n",
    "    include_in_html_report(\"text\", section_content=title)\n",
    "    for each in text_single:\n",
    "        print(each)\n",
    "        include_in_html_report(\"text\", section_header=\"\", section_content=each)\n",
    "\n",
    "# if not catboost:\n",
    "#     print_and_report([\n",
    "#         'Best Index:' + str(crossval_runner.best_index_) + '<br>',\n",
    "#         'Best Score:' + str(crossval_runner.best_score_) + '<br>',\n",
    "#         'Best Params: ' + str(crossval_runner.best_params_) + '<br>'\n",
    "#     ], \"Best Model Details\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Nearly finished...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if create_python_script and is_jupyter:\n",
    "    !jupyter nbconvert --to script 'it10_ann_neural_model__20221203.ipynb'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Finished!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
