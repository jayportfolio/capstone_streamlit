{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Decide which algorithm and version of the data we are going to use for model training\n",
    "(it'll be neural network in this file)\n",
    "\n",
    "Additionally, choose:\n",
    "* if we'll skip scaling the data\n",
    "* if we'll use full categories instead of dummies\n",
    "* what fraction of the data we'll use for testing (0.1)\n",
    "* if the data split will be randomised (it won't!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-07T14:05:06.592418Z",
     "iopub.status.busy": "2022-12-07T14:05:06.591775Z",
     "iopub.status.idle": "2022-12-07T14:05:06.602072Z",
     "shell.execute_reply": "2022-12-07T14:05:06.601361Z",
     "shell.execute_reply.started": "2022-12-07T14:05:06.592327Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#ALGORITHM = 'Neural Network'\n",
    "ALGORITHM = 'Neural Network [TYPE]'\n",
    "ALGORITHM_DETAIL = ''\n",
    "ALGORITHM_DETAIL_ORIG = ALGORITHM_DETAIL\n",
    "#ALGORITHM_DETAIL += ' tbc'\n",
    "DATA_DETAIL = []\n",
    "#DATA_DETAIL = ['no scale','no dummies']\n",
    "VERSION = '09'\n",
    "\n",
    "RANDOM_STATE = 101\n",
    "TRAINING_SIZE = 0.9\n",
    "\n",
    "CROSS_VALIDATION_SCORING = 'r2'\n",
    "\n",
    "price_divisor = 1\n",
    "\n",
    "\n",
    "#selected_neural_network='simplest'\n",
    "#selected_neural_network='quite simple'\n",
    "#selected_neural_network='recommended simple v2'\n",
    "#selected_neural_network='adapted v3'\n",
    "\n",
    "\n",
    "# ---- FIRST NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = 'recommended simple v1'\n",
    "#selected_nn_code = 'm01 simple'\n",
    "\n",
    "# ---- 2nd NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m02 two layers\"\n",
    "\n",
    "\n",
    "# ---- 3rd NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m03 2 layers+wider\"\n",
    "\n",
    "\n",
    "# ---- 4th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m04 3 layers+wider\"\n",
    "\n",
    "# ---- 5th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m05 rec deep\"\n",
    "\n",
    "# ---- 6th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m05 my deep\"\n",
    "\n",
    "#selected_neural_network = selected_nn_code = \"\"\n",
    "\n",
    "# ---- 7th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m11 mega\"\n",
    "\n",
    "# ---- 8th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m12 mega\"\n",
    "\n",
    "# ---- 9th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m13 mega\"\n",
    "\n",
    "# ---- 10th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m14 mega\"\n",
    "\n",
    "# ---- 10th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "selected_neural_network = selected_nn_code = \"m15 mega + dropout\"\n",
    "\n",
    "\n",
    "\n",
    "ALGORITHM = ALGORITHM.replace(\"[TYPE]\", selected_nn_code)\n",
    "\n",
    "create_python_script = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: loading all dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:52:18.573801Z",
     "iopub.status.busy": "2022-12-07T14:52:18.573463Z",
     "iopub.status.idle": "2022-12-07T14:52:21.551851Z",
     "shell.execute_reply": "2022-12-07T14:52:21.550879Z",
     "shell.execute_reply.started": "2022-12-07T14:52:18.573774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (0.9.0)\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if \"JPY_PARENT_PID\" in os.environ:\n",
    "    is_jupyter = True\n",
    "else:\n",
    "    is_jupyter = False\n",
    "\n",
    "\n",
    "if is_jupyter:\n",
    "    #! pip install scikeras\n",
    "    !pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-07T14:05:06.607583Z",
     "iopub.status.busy": "2022-12-07T14:05:06.607393Z",
     "iopub.status.idle": "2022-12-07T14:05:08.350118Z",
     "shell.execute_reply": "2022-12-07T14:05:08.349107Z",
     "shell.execute_reply.started": "2022-12-07T14:05:06.607565Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'notebook_environment': 'gradient', 'use_gpu': True, 'debug_mode': False, 'quick_mode': False, 'quick_override_cv_splits': 2, 'quick_override_n_iter': 10, 'quick_override_n_jobs': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "from termcolor import colored\n",
    "from time import time\n",
    "import sklearn\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "start_timestamp = datetime.now()\n",
    "\n",
    "with open('../../z_envs/_envs.json') as f:\n",
    "    env_vars = json.loads(f.read())\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    run_env = 'colab'\n",
    "except:\n",
    "    try:\n",
    "        run_env = env_vars['notebook_environment']\n",
    "    except:\n",
    "        run_env = 'unknown'\n",
    "\n",
    "if \"JPY_PARENT_PID\" in os.environ:\n",
    "    is_jupyter = True\n",
    "else:\n",
    "    is_jupyter = False\n",
    "\n",
    "use_gpu = env_vars.get('use_gpu', False)\n",
    "debug_mode = env_vars.get('debug_mode', False)\n",
    "quick_mode = env_vars.get('quick_mode', False)\n",
    "OVERRIDE_CV = env_vars.get('quick_override_cv_splits', None) if quick_mode else None\n",
    "OVERRIDE_N_ITER = env_vars.get('quick_override_n_iter', None) if quick_mode else None\n",
    "OVERRIDE_JOBS = env_vars.get('quick_override_n_jobs', None) if quick_mode else None\n",
    "OVERRIDE_VERBOSE = 1\n",
    "#if quick_mode:OVERRIDE_CV, OVERRIDE_N_ITER = 2, 10\n",
    "\n",
    "already_timed = False\n",
    "no_dummies = 'no dummies' in DATA_DETAIL\n",
    "no_scaling = 'no scaling' in DATA_DETAIL\n",
    "#not_catboost = 'catboost' not in ALGORITHM.lower() or not no_dummies\n",
    "using_catboost = 'catboost' in ALGORITHM.lower()\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..', '..', '..'))\n",
    "if module_path not in sys.path:\n",
    "    #sys.path.append(module_path+\"\\\\zfunctions\")\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "if run_env not in ['colab', 'gradient', 'cloud']:\n",
    "    cloud_run = False\n",
    "    from functions_b__get_the_data_20221116 import set_csv_directory\n",
    "    set_csv_directory('final_split')\n",
    "else:\n",
    "    cloud_run = True\n",
    "\n",
    "from functions_0__common_20221116 import get_columns\n",
    "from functions_b__get_the_data_20221116 import get_combined_dataset, get_source_dataframe\n",
    "from functions_d1__prepare_cleanse_data_20221116 import tidy_dataset\n",
    "from functions_d2__transform_enrich_data_20221116 import preprocess, feature_engineer\n",
    "from functions_d3__prepare_store_data_20221116 import create_train_test_data\n",
    "from functions_e__train_model_20221116 import get_chosen_model, make_modelling_pipeline, get_cv_params, fit_model_with_cross_validation, get_hyperparameters\n",
    "from functions_f_evaluate_model_20221116 import get_best_estimator_average_time, get_results, update_results\n",
    "\n",
    "print(env_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include any overrides specific to the algorthm / python environment being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-07T14:05:08.351758Z",
     "iopub.status.busy": "2022-12-07T14:05:08.351382Z",
     "iopub.status.idle": "2022-12-07T14:05:08.355841Z",
     "shell.execute_reply": "2022-12-07T14:05:08.354812Z",
     "shell.execute_reply.started": "2022-12-07T14:05:08.351732Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#running_locally = True\n",
    "running_locally = run_env == 'local'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: creating the ANN model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-07T14:05:08.358371Z",
     "iopub.status.busy": "2022-12-07T14:05:08.358157Z",
     "iopub.status.idle": "2022-12-07T14:05:10.449885Z",
     "shell.execute_reply": "2022-12-07T14:05:10.449187Z",
     "shell.execute_reply.started": "2022-12-07T14:05:08.358351Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "#from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "\n",
    "loss_dict = {\n",
    "    \"mean_squared_error\":'mse',\n",
    "    \"mean_absolute_error\":'mae'\n",
    "            }\n",
    "\n",
    "def make_simple_ann(key, inputs=-1):\n",
    "    if False:\n",
    "        pass\n",
    "    elif key == 'quite simple':\n",
    "\n",
    "        new_algorithm_detail = ALGORITHM_DETAIL_ORIG + 'quite simple model + normalise, mse'\n",
    "\n",
    "        learn_rate = 0.1\n",
    "        epochs, chosen_loss = 100, 'mean_squared_error'\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'recommended simple v1':\n",
    "\n",
    "        learn_rate = 0.003 #0.3\n",
    "        epochs, chosen_loss = 50, 'mean_squared_error'\n",
    "\n",
    "        new_algorithm_detail = ALGORITHM_DETAIL_ORIG + 'recommended simple model/mse'\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'm02 two layers':\n",
    "\n",
    "        learn_rate = 0.003 #0.3\n",
    "        epochs, chosen_loss = 500, 'mean_squared_error'\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(X_train.shape[1], activation='relu'),\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "\n",
    "    elif key == 'm03 2 layers+wider':\n",
    "\n",
    "        learn_rate = 0.0003 # 0.003 #0.3\n",
    "        epochs, chosen_loss = 500, 'mean_squared_error'\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(30, activation='relu'),\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'm04 3 layers+wider':\n",
    "\n",
    "        learn_rate = 0.003\n",
    "        epochs, chosen_loss = 500, 'mean_squared_error'\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(30, activation='relu'),\n",
    "            layers.Dense(40, activation='relu'),\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'm0x four layers,wider,batchnorm':\n",
    "\n",
    "        learn_rate = 0.0003 #0.3\n",
    "        epochs, chosen_loss = 500, 'mean_squared_error'\n",
    "\n",
    "        #from layers.normalization import BatchNormalization\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        batchnorm = layers.BatchNormalization()\n",
    "        activation = layers.Activation('relu')\n",
    "\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "        #new_algorithm_detail += ' +norm'\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            #normalizer,\n",
    "            layers.Dense(30, activation='relu'),\n",
    "            batchnorm,\n",
    "            activation,\n",
    "            layers.Dense(40, activation='relu'),\n",
    "            layers.Dense(30, activation='relu'),\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'm05 rec deep':\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        # Compile the network :\n",
    "        #chosen_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "        learn_rate = 0.0003 #0.3\n",
    "        epochs, chosen_loss = 500, 'mean_squared_error'\n",
    "\n",
    "    elif key == 'm11 mega':\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(2148, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(2148, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        # Compile the network :\n",
    "        #chosen_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "        learn_rate = 0.0003\n",
    "        epochs, chosen_loss = 400, 'mean_squared_error'\n",
    "\n",
    "    elif key == 'm12 mega':\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        # Compile the network :\n",
    "        #chosen_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "        learn_rate = 0.0003\n",
    "        epochs, chosen_loss = 400, 'mean_squared_error'\n",
    "    elif key == 'm13 mega':\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "        #normalizer.adapt(np.array(128))\n",
    "\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(normalizer),\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        learn_rate = 0.0003\n",
    "        epochs = 400\n",
    "        chosen_loss = 'mean_absolute_error' # 'mean_squared_error'\n",
    "\n",
    "    elif key == 'm14 mega':\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "        batchnorm = layers.BatchNormalization()\n",
    "        activation = layers.Activation('relu')\n",
    "\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(normalizer)\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        learn_rate = 0.0003\n",
    "        epochs = 400\n",
    "        chosen_loss = 'mean_absolute_error' # 'mean_squared_error'\n",
    "\n",
    "    elif key == \"m15 mega + dropout\":\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "        batchnorm = layers.BatchNormalization()\n",
    "        activation = layers.Activation('relu')\n",
    "\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(normalizer)\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "\n",
    "        chosen_model.add(keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal'))\n",
    "\n",
    "        chosen_model.add(keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        learn_rate = 0.0003\n",
    "        epochs = 400\n",
    "        chosen_loss = 'mean_absolute_error' # 'mean_squared_error'\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"make_simple_ann: no entry for key:\", key)\n",
    "\n",
    "    if running_locally:\n",
    "        epochs = 8\n",
    "\n",
    "    # Compile the network :\n",
    "    chosen_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learn_rate),\n",
    "        loss=chosen_loss)\n",
    "\n",
    "\n",
    "    new_algorithm_detail = ALGORITHM_DETAIL_ORIG + loss_dict[chosen_loss]\n",
    "    new_algorithm_detail += f' +epochs={epochs}'\n",
    "    new_algorithm_detail += f' +learn={learn_rate}'\n",
    "\n",
    "    return chosen_model, new_algorithm_detail, epochs, {'learning_rate':learn_rate}\n",
    "\n",
    "#make_simple_ann('m04 four layers,wider,batchnorm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: get the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:05:10.451452Z",
     "iopub.status.busy": "2022-12-07T14:05:10.450990Z",
     "iopub.status.idle": "2022-12-07T14:05:10.455099Z",
     "shell.execute_reply": "2022-12-07T14:05:10.454474Z",
     "shell.execute_reply.started": "2022-12-07T14:05:10.451427Z"
    }
   },
   "outputs": [],
   "source": [
    "columns, booleans, floats, categories, custom, wildcard = get_columns(version=VERSION)\n",
    "LABEL = 'Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:05:10.456195Z",
     "iopub.status.busy": "2022-12-07T14:05:10.455983Z",
     "iopub.status.idle": "2022-12-07T14:05:11.107767Z",
     "shell.execute_reply": "2022-12-07T14:05:11.107128Z",
     "shell.execute_reply.started": "2022-12-07T14:05:10.456175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data from ../../../https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/df_listings_v09.csv\n"
     ]
    }
   ],
   "source": [
    "df, retrieval_type = get_source_dataframe(cloud_run, VERSION, folder_prefix='../../../', row_limit=None)\n",
    "df_orig = df.copy()\n",
    "\n",
    "if retrieval_type != 'tidy':\n",
    "    df = tidy_dataset(df, version=int(VERSION))\n",
    "    df = feature_engineer(df, version=int(VERSION))\n",
    "\n",
    "\n",
    "    df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:05:11.108943Z",
     "iopub.status.busy": "2022-12-07T14:05:11.108690Z",
     "iopub.status.idle": "2022-12-07T14:05:11.113380Z",
     "shell.execute_reply": "2022-12-07T14:05:11.112760Z",
     "shell.execute_reply.started": "2022-12-07T14:05:11.108920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34mfeatures\u001B[0m ->  ['bedrooms', 'bathrooms', 'nearestStation', 'location.latitude', 'location.longitude', 'latitude_deviation', 'longitude_deviation', 'tenure.tenureType']\n",
      "\u001B[1m\u001B[32mlabel\u001B[0m ->  Price\n"
     ]
    }
   ],
   "source": [
    "print(colored(f\"features\", \"blue\"), \"-> \", columns)\n",
    "columns.insert(0, LABEL)\n",
    "print(colored(f\"label\", \"green\", None, ['bold']), \"-> \", LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-07T14:05:11.114368Z",
     "iopub.status.busy": "2022-12-07T14:05:11.114163Z",
     "iopub.status.idle": "2022-12-07T14:05:11.147575Z",
     "shell.execute_reply": "2022-12-07T14:05:11.146653Z",
     "shell.execute_reply.started": "2022-12-07T14:05:11.114349Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = preprocess(df, version=VERSION)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:05:11.148796Z",
     "iopub.status.busy": "2022-12-07T14:05:11.148563Z",
     "iopub.status.idle": "2022-12-07T14:05:11.173891Z",
     "shell.execute_reply": "2022-12-07T14:05:11.173199Z",
     "shell.execute_reply.started": "2022-12-07T14:05:11.148775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             Price  bedrooms  bathrooms  nearestStation  location.latitude  \\\n14520525  550000.0       3.0        1.0        0.274316          51.529950   \n27953107  400000.0       2.0        2.0        0.305845          51.549390   \n33593487  579950.0       2.0        1.0        0.438045          51.447180   \n35271294  370000.0       2.0        1.0        0.399307          51.449568   \n44749111  475000.0       2.0        1.0        0.410550          51.370050   \n46204665  435000.0       3.0        2.0        0.314779          51.539070   \n49020666  200000.0       1.0        1.0        0.875911          51.539959   \n49036279  275000.0       2.0        1.0        0.474368          51.541780   \n49303873  450000.0       3.0        2.0        0.577040          51.524880   \n52064391  349950.0       2.0        2.0        0.212734          51.470800   \n52187854  450000.0       1.0        1.0        0.446802          51.527199   \n52845963  200000.0       2.0        1.0        0.650562          51.398040   \n52913496  220000.0       1.0        1.0        0.945991          51.539383   \n53609433  489995.0       1.0        1.0        0.087081          51.532620   \n53938989  450000.0       2.0        1.0        0.775203          51.658287   \n54713232  332000.0       2.0        1.0        0.319226          51.612300   \n54904122  365000.0       2.0        1.0        0.260722          51.593595   \n54991934  430000.0       3.0        1.0        0.497268          51.528720   \n55043230  260000.0       1.0        1.0        0.384607          51.544430   \n55187658  430000.0       2.0        2.0        0.289033          51.507570   \n55805965  280000.0       2.0        1.0        0.742859          51.520910   \n55839051  599950.0       2.0        1.0        0.259168          51.579186   \n55940994  385000.0       2.0        2.0        0.403987          51.376930   \n56449305  380000.0       2.0        1.0        0.310271          51.600483   \n57221413  475000.0       3.0        2.0        0.409784          51.497260   \n57878227  490000.0       2.0        1.0        0.052498          51.580270   \n59258796  475000.0       3.0        1.0        0.424573          51.536335   \n59658138  499995.0       1.0        1.0        0.396544          51.462211   \n60741240  435000.0       2.0        1.0        0.162014          51.612150   \n61387062  375000.0       2.0        1.0        0.493102          51.448697   \n\n          location.longitude  latitude_deviation  longitude_deviation  \\\n14520525           -0.207020            0.030230             0.102600   \n27953107           -0.482600            0.049670             0.378180   \n33593487           -0.338770            0.052540             0.234350   \n35271294           -0.140154            0.050152             0.035734   \n44749111           -0.212410            0.129670             0.107990   \n46204665           -0.198935            0.039350             0.094515   \n49020666           -0.380863            0.040239             0.276443   \n49036279            0.037890            0.042060             0.142310   \n49303873            0.187200            0.025160             0.291620   \n52064391           -0.361820            0.028920             0.257400   \n52187854           -0.202898            0.027479             0.098478   \n52845963           -0.076812            0.101680             0.027608   \n52913496           -0.382239            0.039663             0.277819   \n53609433           -0.107860            0.032900             0.003440   \n53938989           -0.207902            0.158567             0.103482   \n54713232           -0.119860            0.112580             0.015440   \n54904122            0.022046            0.093875             0.126466   \n54991934            0.039180            0.029000             0.143600   \n55043230            0.014500            0.044710             0.118920   \n55187658            0.078030            0.007850             0.182450   \n55805965            0.022680            0.021190             0.127100   \n55839051           -0.209020            0.079466             0.104600   \n55940994           -0.238870            0.122790             0.134450   \n56449305           -0.062096            0.100763             0.042324   \n57221413           -0.422530            0.002460             0.318110   \n57878227            0.022290            0.080550             0.126710   \n59258796           -0.068537            0.036615             0.035883   \n59658138           -0.196876            0.037509             0.092456   \n60741240           -0.277430            0.112430             0.173010   \n61387062           -0.174068            0.051023             0.069648   \n\n          tenure.tenureType  feature__balcony  feature__chain free  \\\n14520525          LEASEHOLD                 0                    0   \n27953107          LEASEHOLD                 1                    0   \n33593487           FREEHOLD                 0                    0   \n35271294          LEASEHOLD                 1                    0   \n44749111           FREEHOLD                 0                    0   \n46204665          LEASEHOLD                 0                    0   \n49020666          LEASEHOLD                 0                    0   \n49036279          LEASEHOLD                 0                    0   \n49303873           FREEHOLD                 0                    0   \n52064391          LEASEHOLD                 0                    0   \n52187854          LEASEHOLD                 0                    0   \n52845963          LEASEHOLD                 0                    0   \n52913496          LEASEHOLD                 0                    1   \n53609433          LEASEHOLD                 0                    0   \n53938989           FREEHOLD                 0                    0   \n54713232  SHARE_OF_FREEHOLD                 0                    0   \n54904122  SHARE_OF_FREEHOLD                 0                    0   \n54991934           FREEHOLD                 0                    0   \n55043230          LEASEHOLD                 0                    0   \n55187658          LEASEHOLD                 0                    0   \n55805965          LEASEHOLD                 0                    0   \n55839051          LEASEHOLD                 0                    0   \n55940994          LEASEHOLD                 0                    0   \n56449305           FREEHOLD                 0                    0   \n57221413           FREEHOLD                 0                    0   \n57878227  SHARE_OF_FREEHOLD                 0                    0   \n59258796          LEASEHOLD                 0                    0   \n59658138          LEASEHOLD                 0                    0   \n60741240          LEASEHOLD                 1                    0   \n61387062          LEASEHOLD                 0                    0   \n\n          feature__no onward chain  feature__off street parking  \\\n14520525                         0                            0   \n27953107                         0                            0   \n33593487                         1                            0   \n35271294                         0                            0   \n44749111                         0                            0   \n46204665                         0                            0   \n49020666                         0                            0   \n49036279                         0                            0   \n49303873                         0                            0   \n52064391                         0                            0   \n52187854                         0                            0   \n52845963                         0                            0   \n52913496                         0                            0   \n53609433                         0                            0   \n53938989                         0                            0   \n54713232                         0                            0   \n54904122                         0                            0   \n54991934                         0                            0   \n55043230                         0                            0   \n55187658                         0                            0   \n55805965                         0                            0   \n55839051                         0                            0   \n55940994                         0                            0   \n56449305                         0                            0   \n57221413                         0                            0   \n57878227                         0                            0   \n59258796                         0                            0   \n59658138                         0                            0   \n60741240                         0                            0   \n61387062                         0                            0   \n\n          feature__one bedroom  feature__private balcony  \\\n14520525                     0                         1   \n27953107                     0                         0   \n33593487                     0                         0   \n35271294                     0                         0   \n44749111                     0                         0   \n46204665                     0                         0   \n49020666                     1                         0   \n49036279                     0                         0   \n49303873                     0                         0   \n52064391                     0                         1   \n52187854                     0                         0   \n52845963                     0                         0   \n52913496                     0                         0   \n53609433                     0                         0   \n53938989                     0                         0   \n54713232                     0                         0   \n54904122                     0                         0   \n54991934                     0                         0   \n55043230                     0                         0   \n55187658                     0                         0   \n55805965                     0                         0   \n55839051                     0                         0   \n55940994                     0                         0   \n56449305                     0                         0   \n57221413                     0                         0   \n57878227                     0                         0   \n59258796                     0                         0   \n59658138                     0                         0   \n60741240                     0                         0   \n61387062                     0                         0   \n\n          feature__share of freehold  feature__three bedrooms  \\\n14520525                           0                        0   \n27953107                           0                        0   \n33593487                           0                        0   \n35271294                           0                        0   \n44749111                           0                        0   \n46204665                           0                        1   \n49020666                           0                        0   \n49036279                           0                        0   \n49303873                           0                        0   \n52064391                           0                        0   \n52187854                           0                        0   \n52845963                           0                        0   \n52913496                           0                        0   \n53609433                           0                        0   \n53938989                           0                        0   \n54713232                           0                        0   \n54904122                           1                        0   \n54991934                           0                        0   \n55043230                           0                        0   \n55187658                           0                        0   \n55805965                           0                        0   \n55839051                           0                        0   \n55940994                           0                        0   \n56449305                           0                        0   \n57221413                           0                        1   \n57878227                           0                        0   \n59258796                           0                        1   \n59658138                           0                        0   \n60741240                           0                        0   \n61387062                           0                        0   \n\n          feature__two bedrooms  feature__two double bedrooms  \n14520525                      0                             0  \n27953107                      0                             1  \n33593487                      0                             0  \n35271294                      0                             0  \n44749111                      0                             0  \n46204665                      0                             0  \n49020666                      0                             0  \n49036279                      0                             0  \n49303873                      0                             0  \n52064391                      1                             0  \n52187854                      0                             0  \n52845963                      0                             0  \n52913496                      0                             0  \n53609433                      0                             0  \n53938989                      0                             0  \n54713232                      0                             0  \n54904122                      0                             0  \n54991934                      0                             0  \n55043230                      0                             0  \n55187658                      0                             0  \n55805965                      0                             0  \n55839051                      0                             0  \n55940994                      1                             0  \n56449305                      1                             0  \n57221413                      0                             0  \n57878227                      0                             0  \n59258796                      0                             0  \n59658138                      0                             0  \n60741240                      0                             1  \n61387062                      0                             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>nearestStation</th>\n      <th>location.latitude</th>\n      <th>location.longitude</th>\n      <th>latitude_deviation</th>\n      <th>longitude_deviation</th>\n      <th>tenure.tenureType</th>\n      <th>feature__balcony</th>\n      <th>feature__chain free</th>\n      <th>feature__no onward chain</th>\n      <th>feature__off street parking</th>\n      <th>feature__one bedroom</th>\n      <th>feature__private balcony</th>\n      <th>feature__share of freehold</th>\n      <th>feature__three bedrooms</th>\n      <th>feature__two bedrooms</th>\n      <th>feature__two double bedrooms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14520525</th>\n      <td>550000.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.274316</td>\n      <td>51.529950</td>\n      <td>-0.207020</td>\n      <td>0.030230</td>\n      <td>0.102600</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27953107</th>\n      <td>400000.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.305845</td>\n      <td>51.549390</td>\n      <td>-0.482600</td>\n      <td>0.049670</td>\n      <td>0.378180</td>\n      <td>LEASEHOLD</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33593487</th>\n      <td>579950.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.438045</td>\n      <td>51.447180</td>\n      <td>-0.338770</td>\n      <td>0.052540</td>\n      <td>0.234350</td>\n      <td>FREEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35271294</th>\n      <td>370000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.399307</td>\n      <td>51.449568</td>\n      <td>-0.140154</td>\n      <td>0.050152</td>\n      <td>0.035734</td>\n      <td>LEASEHOLD</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>44749111</th>\n      <td>475000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.410550</td>\n      <td>51.370050</td>\n      <td>-0.212410</td>\n      <td>0.129670</td>\n      <td>0.107990</td>\n      <td>FREEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46204665</th>\n      <td>435000.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.314779</td>\n      <td>51.539070</td>\n      <td>-0.198935</td>\n      <td>0.039350</td>\n      <td>0.094515</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49020666</th>\n      <td>200000.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.875911</td>\n      <td>51.539959</td>\n      <td>-0.380863</td>\n      <td>0.040239</td>\n      <td>0.276443</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49036279</th>\n      <td>275000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.474368</td>\n      <td>51.541780</td>\n      <td>0.037890</td>\n      <td>0.042060</td>\n      <td>0.142310</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49303873</th>\n      <td>450000.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.577040</td>\n      <td>51.524880</td>\n      <td>0.187200</td>\n      <td>0.025160</td>\n      <td>0.291620</td>\n      <td>FREEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52064391</th>\n      <td>349950.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.212734</td>\n      <td>51.470800</td>\n      <td>-0.361820</td>\n      <td>0.028920</td>\n      <td>0.257400</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52187854</th>\n      <td>450000.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.446802</td>\n      <td>51.527199</td>\n      <td>-0.202898</td>\n      <td>0.027479</td>\n      <td>0.098478</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52845963</th>\n      <td>200000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.650562</td>\n      <td>51.398040</td>\n      <td>-0.076812</td>\n      <td>0.101680</td>\n      <td>0.027608</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>52913496</th>\n      <td>220000.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.945991</td>\n      <td>51.539383</td>\n      <td>-0.382239</td>\n      <td>0.039663</td>\n      <td>0.277819</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>53609433</th>\n      <td>489995.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.087081</td>\n      <td>51.532620</td>\n      <td>-0.107860</td>\n      <td>0.032900</td>\n      <td>0.003440</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>53938989</th>\n      <td>450000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.775203</td>\n      <td>51.658287</td>\n      <td>-0.207902</td>\n      <td>0.158567</td>\n      <td>0.103482</td>\n      <td>FREEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>54713232</th>\n      <td>332000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.319226</td>\n      <td>51.612300</td>\n      <td>-0.119860</td>\n      <td>0.112580</td>\n      <td>0.015440</td>\n      <td>SHARE_OF_FREEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>54904122</th>\n      <td>365000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.260722</td>\n      <td>51.593595</td>\n      <td>0.022046</td>\n      <td>0.093875</td>\n      <td>0.126466</td>\n      <td>SHARE_OF_FREEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>54991934</th>\n      <td>430000.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.497268</td>\n      <td>51.528720</td>\n      <td>0.039180</td>\n      <td>0.029000</td>\n      <td>0.143600</td>\n      <td>FREEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>55043230</th>\n      <td>260000.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.384607</td>\n      <td>51.544430</td>\n      <td>0.014500</td>\n      <td>0.044710</td>\n      <td>0.118920</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>55187658</th>\n      <td>430000.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.289033</td>\n      <td>51.507570</td>\n      <td>0.078030</td>\n      <td>0.007850</td>\n      <td>0.182450</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>55805965</th>\n      <td>280000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.742859</td>\n      <td>51.520910</td>\n      <td>0.022680</td>\n      <td>0.021190</td>\n      <td>0.127100</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>55839051</th>\n      <td>599950.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.259168</td>\n      <td>51.579186</td>\n      <td>-0.209020</td>\n      <td>0.079466</td>\n      <td>0.104600</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>55940994</th>\n      <td>385000.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.403987</td>\n      <td>51.376930</td>\n      <td>-0.238870</td>\n      <td>0.122790</td>\n      <td>0.134450</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>56449305</th>\n      <td>380000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.310271</td>\n      <td>51.600483</td>\n      <td>-0.062096</td>\n      <td>0.100763</td>\n      <td>0.042324</td>\n      <td>FREEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57221413</th>\n      <td>475000.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.409784</td>\n      <td>51.497260</td>\n      <td>-0.422530</td>\n      <td>0.002460</td>\n      <td>0.318110</td>\n      <td>FREEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>57878227</th>\n      <td>490000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.052498</td>\n      <td>51.580270</td>\n      <td>0.022290</td>\n      <td>0.080550</td>\n      <td>0.126710</td>\n      <td>SHARE_OF_FREEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>59258796</th>\n      <td>475000.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.424573</td>\n      <td>51.536335</td>\n      <td>-0.068537</td>\n      <td>0.036615</td>\n      <td>0.035883</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>59658138</th>\n      <td>499995.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.396544</td>\n      <td>51.462211</td>\n      <td>-0.196876</td>\n      <td>0.037509</td>\n      <td>0.092456</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>60741240</th>\n      <td>435000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.162014</td>\n      <td>51.612150</td>\n      <td>-0.277430</td>\n      <td>0.112430</td>\n      <td>0.173010</td>\n      <td>LEASEHOLD</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>61387062</th>\n      <td>375000.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.493102</td>\n      <td>51.448697</td>\n      <td>-0.174068</td>\n      <td>0.051023</td>\n      <td>0.069648</td>\n      <td>LEASEHOLD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Price'] = df['Price'] / price_divisor # potentially making the price smaller to make the ANN perform better\n",
    "\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:05:11.175019Z",
     "iopub.status.busy": "2022-12-07T14:05:11.174797Z",
     "iopub.status.idle": "2022-12-07T14:05:11.211907Z",
     "shell.execute_reply": "2022-12-07T14:05:11.211335Z",
     "shell.execute_reply.started": "2022-12-07T14:05:11.174998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44127, 19)\n",
      "(39714, 21) (4413, 21) (39714, 1) (4413, 1) (39714, 1) (4413, 1) (39714, 1) (4413, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_train_index, X_test_index, y_train_index, y_test_index, df_features, df_labels = create_train_test_data(\n",
    "    df,\n",
    "    categories=categories,\n",
    "    RANDOM_STATE=RANDOM_STATE, return_index=True,\n",
    "    drop_nulls=True,\n",
    "    no_dummies=no_dummies\n",
    ")\n",
    "\n",
    "#print(X_train[0])\n",
    "print(df.shape)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_train_index.shape, X_test_index.shape,\n",
    "      y_train_index.shape, y_test_index.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 17:50:24.130446: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-12-14 17:50:24.130495: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/400\n",
      "2483/2483 - 10s - loss: 0.0237 - val_loss: 0.0044 - 10s/epoch - 4ms/step\n",
      "Epoch 2/400\n",
      "2483/2483 - 9s - loss: 0.0070 - val_loss: 0.0022 - 9s/epoch - 4ms/step\n",
      "Epoch 3/400\n",
      "2483/2483 - 9s - loss: 0.0050 - val_loss: 0.0024 - 9s/epoch - 4ms/step\n",
      "Epoch 4/400\n",
      "2483/2483 - 9s - loss: 0.0042 - val_loss: 0.0012 - 9s/epoch - 4ms/step\n",
      "Epoch 5/400\n"
     ]
    }
   ],
   "source": [
    "# train autoencoder for regression with no compression in the bottleneck layer\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import ReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import plot_model\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "#X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "# number of input columns\n",
    "n_inputs = X_train.shape[1]\n",
    "# split into train test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(X_train)\n",
    "X_train = t.transform(X_train)\n",
    "X_test = t.transform(X_test)\n",
    "# define encoder\n",
    "visible = Input(shape=(n_inputs,))\n",
    "e = Dense(n_inputs*2)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = ReLU()(e)\n",
    "# define bottleneck\n",
    "n_bottleneck = n_inputs\n",
    "bottleneck = Dense(n_bottleneck)(e)\n",
    "# define decoder\n",
    "d = Dense(n_inputs*2)(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = ReLU()(d)\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(d)\n",
    "# define autoencoder model\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# plot the autoencoder\n",
    "plot_model(model, 'autoencoder.png', show_shapes=True)\n",
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=400, batch_size=16, verbose=2, validation_data=(X_test,X_test))\n",
    "# plot loss\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "# define an encoder model (without the decoder)\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "plot_model(encoder, 'encoder.png', show_shapes=True)\n",
    "# save the encoder to file\n",
    "encoder.save('encoder.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "# support vector regression performance with encoded input\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import load_model\n",
    "# define dataset\n",
    "#???X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1, random_state=1)\n",
    "# split into train test sets\n",
    "#???X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(\"Before:\")\n",
    "print(y_train[0:5])\n",
    "print(y_test[0:5])\n",
    "# reshape target variables so that we can transform them\n",
    "y_train = y_train.reshape((len(y_train), 1))\n",
    "y_test = y_test.reshape((len(y_test), 1))\n",
    "# scale input data\n",
    "trans_in = MinMaxScaler()\n",
    "trans_in.fit(X_train)\n",
    "X_train = trans_in.transform(X_train)\n",
    "X_test = trans_in.transform(X_test)\n",
    "# scale output data\n",
    "trans_out = MinMaxScaler()\n",
    "trans_out.fit(y_train)\n",
    "y_train = trans_out.transform(y_train)\n",
    "y_test = trans_out.transform(y_test)\n",
    "print(\"Scaled:\")\n",
    "print(y_train[0:5])\n",
    "print(y_test[0:5])\n",
    "# load the model from file\n",
    "encoder = load_model('encoder.h5')\n",
    "# encode the train data\n",
    "X_train_encode = encoder.predict(X_train)\n",
    "# encode the test data\n",
    "X_test_encode = encoder.predict(X_test)\n",
    "# define model\n",
    "model = SVR()\n",
    "# fit model on the training dataset\n",
    "model.fit(X_train_encode, y_train)\n",
    "# make prediction on test set\n",
    "yhat = model.predict(X_test_encode)\n",
    "# invert transforms so we can calculate errors\n",
    "yhat = yhat.reshape((len(yhat), 1))\n",
    "yhat = trans_out.inverse_transform(yhat)\n",
    "y_test = trans_out.inverse_transform(y_test)\n",
    "# calculate error\n",
    "score = mean_absolute_error(y_test, yhat)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from keras.saving.save import load_model\n",
    "\n",
    "# load the model from file\n",
    "encoder = load_model('encoder.h5')\n",
    "\n",
    "# encode the train data\n",
    "X_train_encode = encoder.predict(X_train)\n",
    "# encode the test data\n",
    "X_test_encode = encoder.predict(X_test)\n",
    "\n",
    "# define model\n",
    "model = SVR()\n",
    "# fit model on the training dataset\n",
    "model.fit(X_train_encode, y_train)\n",
    "# make prediction on test set\n",
    "yhat = model.predict(X_test_encode)\n",
    "\n",
    "yhat = model.predict(X_test_encode)\n",
    "# invert transforms so we can calculate errors\n",
    "yhat = yhat.reshape((len(yhat), 1))\n",
    "yhat = trans_out.inverse_transform(yhat)\n",
    "y_test = trans_out.inverse_transform(y_test)\n",
    "# calculate error\n",
    "score = mean_absolute_error(y_test, yhat)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage:\n",
    "* #### retrieve the hyperparameters for this model, and\n",
    "* #### train the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:05:11.213435Z",
     "iopub.status.busy": "2022-12-07T14:05:11.212918Z",
     "iopub.status.idle": "2022-12-07T14:05:12.601138Z",
     "shell.execute_reply": "2022-12-07T14:05:12.600488Z",
     "shell.execute_reply.started": "2022-12-07T14:05:11.213410Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trainable_model, ALGORITHM_DETAIL, chosen_epochs, chosen_params = make_simple_ann(selected_neural_network)\n",
    "\n",
    "ALGORITHM_DETAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:05:12.602626Z",
     "iopub.status.busy": "2022-12-07T14:05:12.602064Z",
     "iopub.status.idle": "2022-12-07T14:05:12.617161Z",
     "shell.execute_reply": "2022-12-07T14:05:12.616542Z",
     "shell.execute_reply.started": "2022-12-07T14:05:12.602602Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"selected_neural_network\",selected_neural_network)\n",
    "trainable_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:05:12.621501Z",
     "iopub.status.busy": "2022-12-07T14:05:12.621019Z",
     "iopub.status.idle": "2022-12-07T14:16:30.291615Z",
     "shell.execute_reply": "2022-12-07T14:16:30.290697Z",
     "shell.execute_reply.started": "2022-12-07T14:05:12.621480Z"
    },
    "pycharm": {
     "name": "#%%time\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "val_split = 0.1\n",
    "min_delta=0 #10, #50, #10, #50,\n",
    "val_delta_patience = 25 # 10\n",
    "\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", #\"loss\", #\"val_loss\",\n",
    "    min_delta=min_delta, \n",
    "    patience=val_delta_patience,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True # False,\n",
    ")\n",
    "\n",
    "pipe_start = time()\n",
    "\n",
    "history = trainable_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=chosen_epochs,\n",
    "    # verbose=0 to suppress logging.\n",
    "    verbose=1,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split=val_split,  #0.2,\n",
    "    callbacks=[callback],\n",
    ")\n",
    "pipe_end = time()\n",
    "estimated_time = round((pipe_end - pipe_start), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:16:30.293337Z",
     "iopub.status.busy": "2022-12-07T14:16:30.292573Z",
     "iopub.status.idle": "2022-12-07T14:16:30.296473Z",
     "shell.execute_reply": "2022-12-07T14:16:30.295872Z",
     "shell.execute_reply.started": "2022-12-07T14:16:30.293311Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#ALGORITHM_DETAIL.replace(\"epochs=\", f\"epochs={len(hist)}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Get the results and print some graphs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:51:36.528561Z",
     "iopub.status.busy": "2022-12-07T14:51:36.527933Z",
     "iopub.status.idle": "2022-12-07T14:51:36.543328Z",
     "shell.execute_reply": "2022-12-07T14:51:36.542380Z",
     "shell.execute_reply.started": "2022-12-07T14:51:36.528531Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "early_end_lossX = hist.iloc[-1]['loss']\n",
    "early_end_loss = hist['loss'].min()\n",
    "early_end_valloss = hist['val_loss'].min()\n",
    "\n",
    "#more_detail = f\"loss={round(early_end_loss,2)} valloss={round(early_end_valloss,2)}\"\n",
    "more_detail = f\"loss={early_end_loss:.2e} valloss={early_end_valloss:.2e}\"\n",
    "more_detail += f' +valsplit={val_split} +patn={val_delta_patience}'\n",
    "\n",
    "# f\"{x:.2e}\"\n",
    "\n",
    "if len(hist) != chosen_epochs:\n",
    "    print(f'stopped at {len(hist)}, loss={round(early_end_loss,2)} valloss={round(early_end_valloss,2)}')\n",
    "    #ALGORITHM_DETAIL += f\" +stop={len(hist)}\"\n",
    "    more_detail += f\" stop={len(hist)}/{chosen_epochs} \"\n",
    "    #more_detail += ALGORITHM_DETAIL.replace(\"epochs=\", f\"epochs={len(hist)}/\")\n",
    "\n",
    "\n",
    "if price_divisor!=1:\n",
    "    print('in preprocessing, divided all Prices by ', price_divisor)\n",
    "    more_detail += f' div={price_divisor}'\n",
    "\n",
    "\n",
    "print(more_detail)\n",
    "print(ALGORITHM_DETAIL)\n",
    "    \n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:51:36.545715Z",
     "iopub.status.busy": "2022-12-07T14:51:36.544947Z",
     "iopub.status.idle": "2022-12-07T14:51:36.688602Z",
     "shell.execute_reply": "2022-12-07T14:51:36.687744Z",
     "shell.execute_reply.started": "2022-12-07T14:51:36.545690Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    loss_fig, loss_ax = plt.subplots()\n",
    "    loss_ax.plot(history.history['loss'], label='loss')\n",
    "    loss_ax.plot(history.history['val_loss'], label='val_loss')\n",
    "    #plt.ylim([0, 10])\n",
    "    min_y = min(min(history.history['val_loss']),min(history.history['loss'])) - 100\n",
    "    #max_y = min(max(history.history['val_loss']),max(history.history['loss'])) + 500\n",
    "    #max_y = min(sorted(history.history['val_loss'])[-3],sorted(history.history['loss'])[-3]) + 100\n",
    "    max_y = min(sorted(history.history['val_loss'])[-1],sorted(history.history['val_loss'])[-1])\n",
    "    \n",
    "    print(max_y - min_y)\n",
    "    ticks = (max_y - min_y)/10\n",
    "    print(ticks)\n",
    "    \n",
    "    plt.ylim([min_y, max_y])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [Property Price]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.yticks(np.arange(min_y, max_y, ticks))  # JHJH\n",
    "    return loss_fig, loss_ax\n",
    "\n",
    "loss_fig, loss_ax = plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:51:36.689854Z",
     "iopub.status.busy": "2022-12-07T14:51:36.689607Z",
     "iopub.status.idle": "2022-12-07T14:51:37.078758Z",
     "shell.execute_reply": "2022-12-07T14:51:37.077837Z",
     "shell.execute_reply.started": "2022-12-07T14:51:36.689832Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = trainable_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:51:37.081734Z",
     "iopub.status.busy": "2022-12-07T14:51:37.081387Z",
     "iopub.status.idle": "2022-12-07T14:51:37.090508Z",
     "shell.execute_reply": "2022-12-07T14:51:37.089530Z",
     "shell.execute_reply.started": "2022-12-07T14:51:37.081700Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = y_pred.reshape((-1, 1))\n",
    "\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = math.sqrt(MSE)\n",
    "print('-' * 10 + ALGORITHM + '-' * 10)\n",
    "print('R square Accuracy', R2)\n",
    "print('Mean Absolute Error Accuracy', MAE)\n",
    "print('Mean Squared Error Accuracy', MSE)\n",
    "print('Root Mean Squared Error', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:51:37.091753Z",
     "iopub.status.busy": "2022-12-07T14:51:37.091525Z",
     "iopub.status.idle": "2022-12-07T14:51:37.095934Z",
     "shell.execute_reply": "2022-12-07T14:51:37.095157Z",
     "shell.execute_reply.started": "2022-12-07T14:51:37.091734Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    print(y_test_index.reshape((-1, 1)).shape);\n",
    "    print(y_pred.reshape((-1, 1)).shape);\n",
    "    print(y_test.shape);\n",
    "    print(y_test_index.shape);\n",
    "    print(y_pred.shape);\n",
    "    print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:51:37.096842Z",
     "iopub.status.busy": "2022-12-07T14:51:37.096647Z",
     "iopub.status.idle": "2022-12-07T14:51:37.131204Z",
     "shell.execute_reply": "2022-12-07T14:51:37.130413Z",
     "shell.execute_reply.started": "2022-12-07T14:51:37.096824Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "compare = np.hstack((y_test_index, y_test, y_pred))\n",
    "compare_df = DataFrame(compare, columns=['reference', 'actual', 'predicted'])\n",
    "compare_df['difference'] = abs(compare_df['actual'] - compare_df['predicted'])\n",
    "compare_df['diff 1 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['actual'] * 100)\n",
    "compare_df['diff 2 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['predicted']) * 100\n",
    "compare_df['reference'] = compare_df['reference'].astype(int)\n",
    "compare_df.set_index('reference', inplace=True)\n",
    "\n",
    "combined = compare_df.merge(df[columns], how='inner', left_index=True, right_index=True).sort_values(['diff 1 %'],\n",
    "                                                                                                     ascending=False)\n",
    "#pd.options.display.float_format = '{:.4f}'.format\n",
    "combined[['predicted', 'actual', 'Price', 'bedrooms', 'bathrooms']] = combined[\n",
    "    ['predicted', 'actual', 'Price', 'bedrooms', 'bathrooms']].astype(int)\n",
    "combined['bedrooms'] = combined['bedrooms'].astype(int)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:51:37.132382Z",
     "iopub.status.busy": "2022-12-07T14:51:37.132155Z",
     "iopub.status.idle": "2022-12-07T14:51:37.267074Z",
     "shell.execute_reply": "2022-12-07T14:51:37.266314Z",
     "shell.execute_reply.started": "2022-12-07T14:51:37.132361Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "best_model_fig, best_model_ax = plt.subplots()\n",
    "best_model_ax.scatter(y_test, y_pred, edgecolors=(0, 0, 1))\n",
    "best_model_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "best_model_ax.set_ylabel('Predicted')\n",
    "best_model_ax.set_xlabel('Actual')\n",
    "#ax.title.set_text(f'CV Chosen best option ({calculated_best_pipe[1]})')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Evaluate the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:51:37.268497Z",
     "iopub.status.busy": "2022-12-07T14:51:37.268238Z",
     "iopub.status.idle": "2022-12-07T14:51:37.638274Z",
     "shell.execute_reply": "2022-12-07T14:51:37.637596Z",
     "shell.execute_reply.started": "2022-12-07T14:51:37.268474Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cv_best_model_fit_time = estimated_time\n",
    "\n",
    "DD2 = \"(\" + \",\".join(DATA_DETAIL) + \")\" if len(DATA_DETAIL) >= 1 else \"\"\n",
    "key = f'{ALGORITHM} (v{VERSION})'.lower()\n",
    "\n",
    "method = f\"{ALGORITHM_DETAIL}{DD2}\"\n",
    "\n",
    "new_results = {\n",
    "    #'_score': score,\n",
    "    '_score': R2,\n",
    "    'R square Accuracy': R2,\n",
    "    'Mean Absolute Error Accuracy': MAE * price_divisor,\n",
    "    'Mean Squared Error Accuracy': MSE * price_divisor,\n",
    "    'Root Mean Squared Error': RMSE * price_divisor,\n",
    "    '_train time': cv_best_model_fit_time,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'date': str(datetime.now()),\n",
    "    #'_params': crossval_runner.best_params_ if not_catboost else cat_params,\n",
    "    #'_params': 'not available', # REPLACED - can't have different models all saying params not available\n",
    "    '_params': ALGORITHM_DETAIL,\n",
    "    '_method': more_detail, #ALGORITHM_DETAIL,\n",
    "    'run_env': run_env\n",
    "}\n",
    "\n",
    "if run_env not in ['colab']:\n",
    "    old_results_json = get_results()\n",
    "    try:\n",
    "        old_best_score = old_results_json[key]['best score']\n",
    "    except:\n",
    "        print(f\"haven't scored this model yet: {ALGORITHM}\")\n",
    "        old_best_score = -999\n",
    "    this_model_is_best = update_results(old_results_json, new_results, key)\n",
    "\n",
    "print(key)\n",
    "print(ALGORITHM_DETAIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T14:51:37.639406Z",
     "iopub.status.busy": "2022-12-07T14:51:37.639158Z",
     "iopub.status.idle": "2022-12-07T14:51:37.644860Z",
     "shell.execute_reply": "2022-12-07T14:51:37.644222Z",
     "shell.execute_reply.started": "2022-12-07T14:51:37.639382Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if this_model_is_best:\n",
    "    with open(f'../../../models/optimised_model_{ALGORITHM}_v{VERSION}{DD2}.pkl', 'wb') as f:\n",
    "        pickle.dump(trainable_model, f)\n",
    "        new_model_decision = f\"pickled new version of model\\n{old_results_json[key]['_score']} is new best score (it's better than {old_best_score})\"\n",
    "        #print(results_json[key]['_score'], 'is an improvement on', results_json[key]['second best score'])\n",
    "else:\n",
    "    new_model_decision = f\"not updated saved model, the previous run was better\\n{old_results_json[key]['_score']} is worse than or equal to {old_best_score}\"\n",
    "\n",
    "print(new_model_decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Write the final report for this algorithm and dataset version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-07T14:52:26.522741Z",
     "iopub.status.busy": "2022-12-07T14:52:26.522245Z",
     "iopub.status.idle": "2022-12-07T14:52:27.862657Z",
     "shell.execute_reply": "2022-12-07T14:52:27.861880Z",
     "shell.execute_reply.started": "2022-12-07T14:52:26.522708Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def include_in_html_report(type, section_header=None, section_figure=None, section_content=None, section_content_list=None):\n",
    "\n",
    "    # writePath_html = r'model_results/%s (html).html' % key\n",
    "    # writePath_md = r'model_results/%s (md).md' % key\n",
    "    results_root = '../../F_evaluate_model'\n",
    "    writePath_html = f'{results_root}/html/{key}.html'.replace(\" \", \"_\").replace(\"(\", \"_\").replace(\")\", \"_\")\n",
    "    writePath_md = f'{results_root}/markdown/{key}.md'\n",
    "\n",
    "#isinstance(ini_list2, list)\n",
    "    if not section_content_list:\n",
    "        section_content_list = [section_content]\n",
    "\n",
    "    if type == 'header':\n",
    "        w = 'w' if section_figure <= 1 else 'a'\n",
    "        with open(writePath_html, w) as f1:\n",
    "            headers = f'<h{section_figure}>{section_content}</h{section_figure}>'\n",
    "            f1.write(headers)\n",
    "        with open(writePath_md, w) as f2:\n",
    "            headers = f'{\"#\" * int(section_figure)} {section_content }\\n'\n",
    "            f2.write(headers)\n",
    "    else:\n",
    "        if section_header:\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                f1.write(f'<h3>{section_header}</h3>')\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                f2.write(f'### {section_header}\\n')\n",
    "\n",
    "        if type=='dataframe':\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                dfAsString = section_content.to_html()\n",
    "                f1.write(dfAsString)\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                dfAsString = section_content.to_markdown()\n",
    "                f2.write(dfAsString + '\\n\\n')\n",
    "        elif type=='graph':\n",
    "            filename = key + \"_\" + section_content\n",
    "            #section_figure.savefig(f'model_results/artifacts/{filename.replace(\" \", \"_\")}')\n",
    "            section_figure.savefig(f'{results_root}/artifacts/{filename.replace(\" \", \"_\").replace(\"(\", \"_\").replace(\")\", \"_\")}')\n",
    "\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                dfAsString = f'<img src=\"../artifacts/{filename.replace(\" \",\"_\").replace(\"(\", \"_\").replace(\")\", \"_\")}\"/>'\n",
    "                f1.write(dfAsString)\n",
    "\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                #dfAsString = f'(./model_results/artifacts/{filename}) \\n'\n",
    "                #dfAsString = f'![detail](./artifacts/{filename.replace(\" \",\"_\")})'\n",
    "                dfAsString = f'![detail](../artifacts/{filename.replace(\" \",\"_\").replace(\"(\", \"_\").replace(\")\", \"_\")})'\n",
    "                f2.write(dfAsString)\n",
    "                f2.write('\\n\\n')\n",
    "        elif type=='json':\n",
    "\n",
    "            # html_content_parsed = [[cell.text for cell in row(\"td\")]\n",
    "            #              for row in BeautifulSoup(content,features=\"html.parser\")(\"tr\")]\n",
    "            #\n",
    "            # html_content_dictionary = {element[0]:element[1:] for element in html_content_parsed}\n",
    "\n",
    "            #xxxprint(json.dumps(html_content_dictionary, indent=4))\n",
    "\n",
    "\n",
    "\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                #f.write(json.dumps(html_content_dictionary, indent=4))\n",
    "                soup = BeautifulSoup(section_content, \"html.parser\")\n",
    "                f1.write(str(soup.prettify()))\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                #f.write(json.dumps(html_content_dictionary, indent=4))\n",
    "                soup = BeautifulSoup(section_content, \"html.parser\")\n",
    "                #f2.write(str(soup.prettify()))\n",
    "\n",
    "\n",
    "                # html_content_dictionary = {element[0]:element[1:] for element in html_content_parsed}\n",
    "                # f2.write(json.dumps(html_content_dictionary, indent=4))\n",
    "\n",
    "                import ast\n",
    "                loads = ast.literal_eval(section_content)\n",
    "                #df = pd.DataFrame.from_dict(loads)\n",
    "                #df.drop(['dont'], axis=1, inplace=True)\n",
    "                #print(df.to_markdown(index=False,tablefmt='fancy_grid'))\n",
    "                for each in loads:\n",
    "                    f2.write(each + \" = \" + str(loads[each]) + \"\\n\\n\")\n",
    "\n",
    "        elif type=='dict':\n",
    "\n",
    "            for section_content in section_content_list:\n",
    "                if isinstance(section_content, str):\n",
    "                    import ast\n",
    "                    section_content = ast.literal_eval(section_content)\n",
    "\n",
    "                with open(writePath_html, 'a') as f1:\n",
    "                    soup = BeautifulSoup(str(section_content), \"html.parser\")\n",
    "                    f1.write(str(soup.prettify()))\n",
    "                with open(writePath_md, 'a') as f2:\n",
    "                    for each in section_content:\n",
    "                        f2.write(each + \" = \" + str(section_content[each]) + \"\\n\\n\")\n",
    "\n",
    "        elif type=='text':\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                for each_line in section_content_list:\n",
    "                    f1.write(each_line + '<br>')\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                for each_line in section_content_list:\n",
    "                    f2.write(each_line + '\\n\\n')\n",
    "\n",
    "        with open(writePath_html, 'a') as f1:\n",
    "            f1.write('<hr>')\n",
    "\n",
    "\n",
    "include_in_html_report(\"header\", section_content=f\"Results from {ALGORITHM}\", section_figure=1)\n",
    "\n",
    "end_timestamp = datetime.now()\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=f\"Dataset Version: {VERSION}\", section_content_list=[\n",
    "    f\"Date run: {datetime.now()}\"\n",
    "    \"\",\n",
    "    f\"Start time: {start_timestamp}\",\n",
    "    f\"End time: {end_timestamp}\",\n",
    "])\n",
    "\n",
    "include_in_html_report(\"header\", section_content=f\"Results\", section_figure=2)\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=\"Summary\", section_content=new_model_decision)\n",
    "\n",
    "\n",
    "include_in_html_report(type='graph', section_header=\"Best Model: Comparing model predictions to actual property values\", section_figure=best_model_fig, section_content='best_ann_model.png')\n",
    "\n",
    "#include_in_html_report(type=\"dataframe\",text_single=\"Tuned Models ranked by performance\", content=cv_results_df_sorted)\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=\"Model Specific Notes\", section_content_list=[\"can't display hyperparameter comparison for neural network\",\"can't display model performance graphs for neural network\",\"can't display model performance graphs for neural network\"])\n",
    "\n",
    "include_in_html_report(type=\"dataframe\", section_header=\"Neural Network Loss - Head\", section_content=hist.head())\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=None, section_content='')\n",
    "\n",
    "include_in_html_report(type=\"dataframe\", section_header=\"Neural Network Loss - Tail\", section_content=hist.tail())\n",
    "\n",
    "\n",
    "include_in_html_report(type='graph', section_header=None, section_figure=loss_fig, section_content='end_loss.png')\n",
    "\n",
    "import io\n",
    "def get_model_summary(model):\n",
    "    stream = io.StringIO()\n",
    "    model.summary(line_length=160, print_fn=lambda x: stream.write('>' + x.replace('-','').replace('=','') + '\\n'))\n",
    "    summary_string = stream.getvalue()\n",
    "    stream.close()\n",
    "    return summary_string\n",
    "\n",
    "short_model_summary = get_model_summary(trainable_model)\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=\"Model Structure\", section_content=short_model_summary)\n",
    "\n",
    "include_in_html_report(\"header\", section_content=f\"Comparison with other models\", section_figure=2)\n",
    "\n",
    "\n",
    "dff = pd.read_json('../../../results/results.json')\n",
    "\n",
    "version = VERSION\n",
    "\n",
    "\n",
    "all_models_df = dff[dff.columns].T.sort_values(\"best score\", ascending=False)\n",
    "version_models_df = dff[[c for c in dff.columns if version in c]].T.sort_values(\"best score\", ascending=False)\n",
    "\n",
    "version_models_summary = version_models_df[['best score', 'best time', 'Mean Absolute Error Accuracy', 'Mean Squared Error Accuracy', 'R square Accuracy', 'Root Mean Squared Error', 'best run date', 'best method']]\n",
    "all_models_summary = all_models_df[['best score', 'best time', 'Mean Absolute Error Accuracy', 'Mean Squared Error Accuracy', 'R square Accuracy', 'Root Mean Squared Error', 'best run date', 'best method']]\n",
    "\n",
    "include_in_html_report(type=\"dataframe\", section_header=f\"Comparison with version {VERSION} performances\", section_content=version_models_summary)\n",
    "include_in_html_report(type=\"dataframe\", section_header=\"Comparison with all model performances\", section_content=all_models_summary)\n",
    "\n",
    "\n",
    "include_in_html_report(\"header\", section_content=f\"Appendix\", section_figure=2)\n",
    "\n",
    "include_in_html_report(type=\"dataframe\", section_header=\"Data Sample\", section_content=df.head(5))\n",
    "\n",
    "if False:\n",
    "    include_in_html_report(type=\"json\", section_header=\"Hyperparameter options for Randomized Grid Search\", section_content=f\"{param_options if not using_catboost else options_block}\")\n",
    "else:\n",
    "\n",
    "    include_in_html_report(type=\"text\", section_header=\"FIX THIS!!\", section_content=\"FIX THIS!\")\n",
    "\n",
    "include_in_html_report(type=\"dict\", section_header=\"Environment Variables\", section_content=env_vars)\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=\"Useful info\",\n",
    "                       section_content_list=[f\"Tensorflow version: {tf.__version__}\"\n",
    "                                        ])\n",
    "\n",
    "\n",
    "def print_and_report(text_single, title):\n",
    "    include_in_html_report(\"text\", section_content=title)\n",
    "    for each in text_single:\n",
    "        print(each)\n",
    "        include_in_html_report(\"text\", section_header=\"\", section_content=each)\n",
    "\n",
    "# if not catboost:\n",
    "#     print_and_report([\n",
    "#         'Best Index:' + str(crossval_runner.best_index_) + '<br>',\n",
    "#         'Best Score:' + str(crossval_runner.best_score_) + '<br>',\n",
    "#         'Best Params: ' + str(crossval_runner.best_params_) + '<br>'\n",
    "#     ], \"Best Model Details\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-07T14:52:35.954615Z",
     "iopub.status.busy": "2022-12-07T14:52:35.953737Z",
     "iopub.status.idle": "2022-12-07T14:52:35.958648Z",
     "shell.execute_reply": "2022-12-07T14:52:35.958014Z",
     "shell.execute_reply.started": "2022-12-07T14:52:35.954570Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Nearly finished...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-07T14:56:27.642256Z",
     "iopub.status.busy": "2022-12-07T14:56:27.641373Z",
     "iopub.status.idle": "2022-12-07T14:56:30.717635Z",
     "shell.execute_reply": "2022-12-07T14:56:30.716528Z",
     "shell.execute_reply.started": "2022-12-07T14:56:27.642218Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if create_python_script and is_jupyter:\n",
    "    !jupyter nbconvert --to script 'neural_networks_model.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-07T14:52:39.054084Z",
     "iopub.status.busy": "2022-12-07T14:52:39.053800Z",
     "iopub.status.idle": "2022-12-07T14:52:39.059415Z",
     "shell.execute_reply": "2022-12-07T14:52:39.058466Z",
     "shell.execute_reply.started": "2022-12-07T14:52:39.054055Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
