{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.9/dist-packages (0.20.1)\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0mRequirement already satisfied: pydot in /usr/local/lib/python3.9/dist-packages (1.4.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.9/dist-packages (from pydot) (3.0.9)\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 101\n",
    "VERSION = '11'\n",
    "\n",
    "no_dummies = False # 'no dummies' in DATA_DETAIL\n",
    "no_dummies = True\n",
    "\n",
    "AUTOENCODE_EPOCHS = 400\n",
    "AUTOENCODE_EPOCHS = 80\n",
    "#AUTOENCODE_EPOCHS = 10\n",
    "\n",
    "!pip install graphviz\n",
    "!pip install pydot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..', '..', '..'))\n",
    "if module_path not in sys.path:\n",
    "    #sys.path.append(module_path+\"\\\\zfunctions\")\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "#with open('../../z_envs/_envs.json') as f:\n",
    "#    env_vars = json.loads(f.read())\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    run_env = 'colab'\n",
    "except:\n",
    "    try:\n",
    "        run_env = env_vars['notebook_environment']\n",
    "    except:\n",
    "        run_env = 'unknown'\n",
    "\n",
    "if \"JPY_PARENT_PID\" in os.environ:\n",
    "    is_jupyter = True\n",
    "else:\n",
    "    is_jupyter = False\n",
    "\n",
    "\n",
    "\n",
    "if run_env not in ['colab', 'gradient', 'cloud','unknown']:\n",
    "    cloud_run = False\n",
    "    from functions_b__get_the_data_20221116 import set_csv_directory\n",
    "    set_csv_directory('final_split')\n",
    "else:\n",
    "    cloud_run = True\n",
    "\n",
    "from functions_0__common_20221116 import get_columns\n",
    "from functions_b__get_the_data_20221116 import get_combined_dataset, get_source_dataframe\n",
    "from functions_d1__prepare_cleanse_data_20221116 import tidy_dataset\n",
    "from functions_d2__transform_enrich_data_20221116 import preprocess, feature_engineer\n",
    "from functions_d3__prepare_store_data_20221116 import create_train_test_data\n",
    "from functions_e__train_model_20221116 import get_chosen_model, make_modelling_pipeline, get_cv_params, fit_model_with_cross_validation, get_hyperparameters\n",
    "from functions_f_evaluate_model_20221116 import get_best_estimator_average_time, get_results, update_results\n",
    "\n",
    "#print(env_vars)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "columns, booleans, floats, categories, custom, wildcard = get_columns(version=VERSION)\n",
    "LABEL = 'Price'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data from ../../../https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/df_listings_v11.csv\n"
     ]
    }
   ],
   "source": [
    "df, retrieval_type = get_source_dataframe(cloud_run, VERSION, folder_prefix='../../../', row_limit=None)\n",
    "df_orig = df.copy()\n",
    "\n",
    "if retrieval_type != 'tidy':\n",
    "    df = tidy_dataset(df, version=int(VERSION))\n",
    "    df = feature_engineer(df, version=int(VERSION))\n",
    "\n",
    "\n",
    "    df = df[columns]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46871, 81)\n",
      "(39714, 80) (4413, 80) (39714, 1) (4413, 1) (39714, 1) (4413, 1) (39714, 1) (4413, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig, X_train_index, X_test_index, y_train_index, y_test_index, df_features, df_labels = create_train_test_data(\n",
    "    df,\n",
    "    categories=categories,\n",
    "    RANDOM_STATE=RANDOM_STATE, return_index=True,\n",
    "    drop_nulls=True,\n",
    "    no_dummies=no_dummies\n",
    ")\n",
    "\n",
    "#print(X_train[0])\n",
    "print(df.shape)\n",
    "print(X_train_orig.shape, X_test_orig.shape, y_train_orig.shape, y_test_orig.shape, X_train_index.shape, X_test_index.shape,\n",
    "      y_train_index.shape, y_test_index.shape)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "X_train = X_train_orig.copy()\n",
    "X_test = X_test_orig.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/Keras: 2.9.0\n",
      "pandas: 1.4.3\n",
      "sklearn: 1.1.1\n",
      "matplotlib: 3.5.2\n",
      "graphviz: 0.20.1\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow / Keras\n",
    "from tensorflow import keras # for building Neural Networks\n",
    "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
    "from keras.models import Model, load_model # for creating a Neural Network Autoencoder model\n",
    "from keras import Input # for instantiating a keras tensor\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization # for adding layers to AE model\n",
    "from tensorflow.keras.utils import plot_model # for plotting model diagram\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "print('pandas: %s' % pd.__version__) # print version\n",
    "\n",
    "# Sklearn\n",
    "import sklearn # for model evaluation\n",
    "print('sklearn: %s' % sklearn.__version__) # print version\n",
    "from sklearn.preprocessing import MinMaxScaler # For rescaling metrics to fit into 0 to 1 range\n",
    "from sklearn.model_selection import train_test_split # for splitting the data into train and test samples\n",
    "\n",
    "# Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt # for plotting model loss\n",
    "print('matplotlib: %s' % matplotlib.__version__) # print version\n",
    "import graphviz # for showing model diagram\n",
    "print('graphviz: %s' % graphviz.__version__) # print version\n",
    "\n",
    "# Other utilities\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Assign main directory to a variable\n",
    "main_dir=os.path.dirname(sys.path[0])\n",
    "#print(main_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Autoencoder-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input-Layer (InputLayer)    [(None, 80)]              0         \n",
      "                                                                 \n",
      " Encoder-Layer (Dense)       (None, 80)                6480      \n",
      "                                                                 \n",
      " Encoder-Layer-Normalization  (None, 80)               320       \n",
      "  (BatchNormalization)                                           \n",
      "                                                                 \n",
      " Encoder-Layer-Activation (L  (None, 80)               0         \n",
      " eakyReLU)                                                       \n",
      "                                                                 \n",
      " Bottleneck-Layer (Dense)    (None, 40)                3240      \n",
      "                                                                 \n",
      " Decoder-Layer (Dense)       (None, 80)                3280      \n",
      "                                                                 \n",
      " Decoder-Layer-Normalization  (None, 80)               320       \n",
      "  (BatchNormalization)                                           \n",
      "                                                                 \n",
      " Decoder-Layer-Activation (L  (None, 80)               0         \n",
      " eakyReLU)                                                       \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 80)                6480      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,120\n",
      "Trainable params: 19,800\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "#--- Define Shapes\n",
    "n_inputs=X_train.shape[1] # number of input neurons = the number of features in X_train\n",
    "n_bottleneck=(round(float(n_inputs) / 2.0)) # bottleneck to have half the number of neurons\n",
    "\n",
    "#--- Input Layer\n",
    "visible = Input(shape=(n_inputs,), name='Input-Layer') # Specify input shape\n",
    "\n",
    "#--- Encoder Layer\n",
    "e = Dense(units=n_inputs, name='Encoder-Layer')(visible)\n",
    "e = BatchNormalization(name='Encoder-Layer-Normalization')(e)\n",
    "e = LeakyReLU(name='Encoder-Layer-Activation')(e)\n",
    "\n",
    "#--- Bottleneck\n",
    "bottleneck = Dense(units=n_bottleneck, name='Bottleneck-Layer')(e)\n",
    "\n",
    "#--- Decoder Layer\n",
    "d = Dense(units=n_inputs, name='Decoder-Layer')(bottleneck)\n",
    "d = BatchNormalization(name='Decoder-Layer-Normalization')(d)\n",
    "d = LeakyReLU(name='Decoder-Layer-Activation')(d)\n",
    "\n",
    "#--- Output layer\n",
    "output = Dense(units=n_inputs, activation='linear', name='Output-Layer')(d)\n",
    "\n",
    "# Define autoencoder model\n",
    "model = Model(inputs=visible, outputs=output, name='Autoencoder-Model')\n",
    "\n",
    "# Compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Plot the autoencoder model diagram\n",
    "try:\n",
    "    plot_model(model, to_file=main_dir+'/pics/Autoencoder.png', show_shapes=True, dpi=300)\n",
    "except:\n",
    "    plot_model(model, to_file='./pics/Autoencoder.png', show_shapes=True, dpi=300)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [21]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Fit the autoencoder model to reconstruct input\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Plot a loss chart\u001B[39;00m\n\u001B[1;32m      5\u001B[0m fig, ax \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39msubplots(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m16\u001B[39m,\u001B[38;5;241m9\u001B[39m), dpi\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/constant_op.py:102\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m    100\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[1;32m    101\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "# Fit the autoencoder model to reconstruct input\n",
    "history = model.fit(X_train, X_train, epochs=50, batch_size=16, verbose=1, validation_data=(X_test, X_test))\n",
    "\n",
    "# Plot a loss chart\n",
    "fig, ax = plt.subplots(figsize=(16,9), dpi=300)\n",
    "plt.title(label='Model Loss by Epoch', loc='center')\n",
    "\n",
    "ax.plot(history.history['loss'], label='Training Data', color='black')\n",
    "ax.plot(history.history['val_loss'], label='Test Data', color='red')\n",
    "ax.set(xlabel='Epoch', ylabel='Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "suffix = '_no_dummies' if no_dummies else ''\n",
    "suffix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performed operation to main_dir: SAVE\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# Define an encoder model without the decoder\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "\n",
    "# Compile encoder model\n",
    "encoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "# Save the encoder model to file\n",
    "try:\n",
    "    main_dir=os.path.dirname(sys.path[0])\n",
    "    encoder.save(main_dir+f'/data/encoder_v{VERSION}{suffix}.h5')\n",
    "    print('performed operation to main_dir: SAVE')\n",
    "except:\n",
    "    print('failed to perform operation to main_dir: SAVE')\n",
    "    main_dir = '.'\n",
    "    encoder.save(main_dir+f'/data/encoder_v{VERSION}.h5')\n",
    "    print('performed operation to local/relative: SAVE')\n",
    "\n",
    "# Plot the autoencoder model diagram\n",
    "plot_model(encoder, to_file=main_dir+'/pics/Encoder_only.png', show_shapes=True, dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242/1242 [==============================] - 1s 1ms/step\n",
      "138/138 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load the model from file\n",
    "encoder = load_model(main_dir+f'/data/encoder_v{VERSION}.h5')\n",
    "\n",
    "# Encode train and test data\n",
    "X_train_encoded = encoder.predict(X_train)\n",
    "X_test_encoded = encoder.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 3.00000000e+00,  3.00000000e+00,  3.16613257e-01,\n         5.14597600e+01,  1.29390000e-01,  3.99600000e-02,\n         2.33810000e-01,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n         0.00000000e+00,  0.00000000e+00],\n       [ 1.00000000e+00,  1.00000000e+00,  5.30933747e-01,\n         5.15326700e+01,  7.54000000e-02,  3.29500000e-02,\n         1.79820000e-01,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         1.00000000e+00,  0.00000000e+00],\n       [ 1.00000000e+00,  1.00000000e+00,  2.85509374e-01,\n         5.15140500e+01, -6.13600000e-02,  1.43300000e-02,\n         4.30600000e-02,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  1.00000000e+00]])"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_orig[0:3]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 3.00000000e+00,  3.00000000e+00,  3.16613257e-01,\n         5.14597600e+01,  1.29390000e-01,  3.99600000e-02,\n         2.33810000e-01,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n         0.00000000e+00,  0.00000000e+00],\n       [ 1.00000000e+00,  1.00000000e+00,  5.30933747e-01,\n         5.15326700e+01,  7.54000000e-02,  3.29500000e-02,\n         1.79820000e-01,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         1.00000000e+00,  0.00000000e+00],\n       [ 1.00000000e+00,  1.00000000e+00,  2.85509374e-01,\n         5.15140500e+01, -6.13600000e-02,  1.43300000e-02,\n         4.30600000e-02,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  1.00000000e+00]])"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  6.614075  , -10.00087   ,   2.0106304 ,  10.822067  ,\n         -8.197215  ,   0.0887069 ,  -4.333485  ,  -1.5984313 ,\n         -6.916433  , -10.046262  ,  -7.6852107 ,   2.119754  ,\n         -8.780337  ,  -2.89051   ,   3.41351   ,   3.6929772 ,\n          5.875437  ,   3.61391   ,  -1.549049  ,  -3.780601  ,\n         -1.7301445 ,   9.872017  ,  -2.232491  ,  -4.7083654 ,\n         -4.614657  ,  -6.096317  ,   2.7854896 ,   6.265664  ,\n          9.170942  ,   4.5868783 ,   0.7995242 ,   6.702379  ,\n          1.5992277 ,   4.859478  ,   1.641658  ,   5.9614625 ,\n          2.6014006 ,  -0.5302769 ,  -5.540656  ,   8.198903  ,\n          5.8713994 ,  -6.3346806 ],\n       [  6.452407  ,  -7.552716  ,   0.8782065 ,   9.054948  ,\n         -8.954256  ,  -0.715046  ,  -6.8363    ,   1.9834826 ,\n         -7.8510723 ,  -4.2933545 ,  -3.4465954 ,   7.1777143 ,\n         -8.305194  ,  -6.9156885 ,   2.9866521 ,   2.400256  ,\n         -0.0485765 ,  -0.716206  ,   0.1656414 ,  -3.6421177 ,\n          1.937007  ,   6.6502805 ,  -1.5500461 ,  -4.712632  ,\n         -3.5622277 ,  -6.2353835 ,   0.9311385 ,   8.544425  ,\n          8.901029  ,   4.7367496 ,   4.5950665 ,   1.0115502 ,\n          2.3972769 ,   5.1870866 ,   0.6039187 ,   1.4760336 ,\n         -0.33978128,  -1.4039261 ,  -3.659336  ,   8.216341  ,\n          2.0075161 ,  -0.64244694],\n       [  4.915657  ,  -8.41824   ,   1.4131806 ,  11.280864  ,\n        -12.047227  ,  -1.8809782 ,  -5.269283  ,  -0.5884238 ,\n         -7.8324404 ,  -2.753819  ,  -3.1261039 ,   3.011916  ,\n         -7.5132523 ,  -4.311067  ,   3.0126693 ,   2.1634843 ,\n          0.07289968,  -0.6347899 ,   4.6692257 ,  -2.443367  ,\n          0.6502083 ,   6.6166444 ,  -0.03813417,  -4.4537077 ,\n         -5.876414  ,  -4.831777  ,   0.61501086,   8.318823  ,\n          9.603359  ,   1.6549995 ,   4.247009  ,   4.4731994 ,\n          2.5236661 ,   7.1250286 ,   4.516938  ,   3.339279  ,\n          1.3476422 ,  -3.0684764 ,  -4.0128984 ,   8.153574  ,\n          3.9746683 ,  -6.387586  ]], dtype=float32)"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded[0:3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "y_train = y_train_orig\n",
    "y_test = y_test_orig"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "KNeighborsRegressor()",
      "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# define model\n",
    "#model = SVR()\n",
    "#model = LinearRegression()\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "# fit model on the training dataset\n",
    "model.fit(X_train_encoded, y_train)\n",
    "# make prediction on test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_encoded)\n",
    "y_pred_orig = y_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# invert transforms so we can calculate errors\n",
    "y_pred = y_pred.reshape((len(y_pred), 1))\n",
    "\n",
    "\n",
    "#trans_out = MinMaxScaler()\n",
    "#trans_out.fit(y_train)\n",
    "\n",
    "#y_pred = trans_out.inverse_transform(y_pred)\n",
    "#??? y_test = trans_out.inverse_transform(y_test)\n",
    "# calculate error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68165.35041921595\n",
      "0.34463715278837204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "mae_score = mean_absolute_error(y_test, y_pred)\n",
    "score = r2_score(y_test, y_pred)\n",
    "print(mae_score)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400000.] [358100.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0], y_pred[0])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (mean absolute error): 68165.35041921595 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "        actual  predicted   diff 1 %   diff 2 %\n0     400000.0   358100.0  10.475000  11.700642\n1     369950.0   374000.0   1.094743   1.082888\n2     350000.0   296000.0  15.428571  18.243243\n3     549000.0   528590.0   3.717668   3.861216\n4     495000.0   436000.0  11.919192  13.532110\n...        ...        ...        ...        ...\n4408  475000.0   472000.0   0.631579   0.635593\n4409  575000.0   555990.0   3.306087   3.419126\n4410  400000.0   340000.0  15.000000  17.647059\n4411  450000.0   505000.0  12.222222  10.891089\n4412  275000.0   397499.0  44.545091  30.817436\n\n[4413 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>actual</th>\n      <th>predicted</th>\n      <th>diff 1 %</th>\n      <th>diff 2 %</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>400000.0</td>\n      <td>358100.0</td>\n      <td>10.475000</td>\n      <td>11.700642</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>369950.0</td>\n      <td>374000.0</td>\n      <td>1.094743</td>\n      <td>1.082888</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>350000.0</td>\n      <td>296000.0</td>\n      <td>15.428571</td>\n      <td>18.243243</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>549000.0</td>\n      <td>528590.0</td>\n      <td>3.717668</td>\n      <td>3.861216</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>495000.0</td>\n      <td>436000.0</td>\n      <td>11.919192</td>\n      <td>13.532110</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4408</th>\n      <td>475000.0</td>\n      <td>472000.0</td>\n      <td>0.631579</td>\n      <td>0.635593</td>\n    </tr>\n    <tr>\n      <th>4409</th>\n      <td>575000.0</td>\n      <td>555990.0</td>\n      <td>3.306087</td>\n      <td>3.419126</td>\n    </tr>\n    <tr>\n      <th>4410</th>\n      <td>400000.0</td>\n      <td>340000.0</td>\n      <td>15.000000</td>\n      <td>17.647059</td>\n    </tr>\n    <tr>\n      <th>4411</th>\n      <td>450000.0</td>\n      <td>505000.0</td>\n      <td>12.222222</td>\n      <td>10.891089</td>\n    </tr>\n    <tr>\n      <th>4412</th>\n      <td>275000.0</td>\n      <td>397499.0</td>\n      <td>44.545091</td>\n      <td>30.817436</td>\n    </tr>\n  </tbody>\n</table>\n<p>4413 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Score (mean absolute error):\", mean_absolute_error(y_test, y_pred), \"\\n\")\n",
    "compare_np = np.hstack((y_test, y_pred))\n",
    "compare_df = pd.DataFrame(compare_np, columns=['actual', 'predicted'])\n",
    "compare_df['diff 1 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['actual'] * 100)\n",
    "compare_df['diff 2 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['predicted']) * 100\n",
    "\n",
    "compare_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "best_model_fig, best_model_ax = plt.subplots()\n",
    "best_model_ax.scatter(y_test, y_pred, edgecolors=(0, 0, 1))\n",
    "best_model_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "best_model_ax.set_ylabel('Predicted')\n",
    "best_model_ax.set_xlabel('Actual')\n",
    "#ax.title.set_text(f'CV Chosen best option ({calculated_best_pipe[1]})')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
