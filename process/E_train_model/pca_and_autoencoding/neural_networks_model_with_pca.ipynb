{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Decide which algorithm and version of the data we are going to use for model training\n",
    "(it'll be neural network in this file)\n",
    "\n",
    "Additionally, choose:\n",
    "* if we'll skip scaling the data\n",
    "* if we'll use full categories instead of dummies\n",
    "* what fraction of the data we'll use for testing (0.1)\n",
    "* if the data split will be randomised (it won't!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:34.027850Z",
     "iopub.status.busy": "2023-01-03T20:29:34.027436Z",
     "iopub.status.idle": "2023-01-03T20:29:34.034332Z",
     "shell.execute_reply": "2023-01-03T20:29:34.033543Z",
     "shell.execute_reply.started": "2023-01-03T20:29:34.027819Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "FILENAME = 'neural_networks_model_with_pca'\n",
    "\n",
    "#ALGORITHM = 'Neural Network'\n",
    "ALGORITHM = 'Neural Network [TYPE]'\n",
    "ALGORITHM_DETAIL = ''\n",
    "ALGORITHM_DETAIL_ORIG = ALGORITHM_DETAIL\n",
    "#ALGORITHM_DETAIL += ' tbc'\n",
    "DATA_DETAIL = []\n",
    "#DATA_DETAIL = ['no scale','no dummies']\n",
    "VERSION = '11'\n",
    "\n",
    "use_dimension_reduction = True\n",
    "pca_data_retain = 0.9999999\n",
    "pca_data_retain = 0.95\n",
    "\n",
    "\n",
    "force_quick_mode = False #True\n",
    "\n",
    "RANDOM_STATE = 101\n",
    "TRAINING_SIZE = 0.9\n",
    "\n",
    "CROSS_VALIDATION_SCORING = 'r2'\n",
    "\n",
    "price_divisor = 1\n",
    "\n",
    "\n",
    "#selected_neural_network='simplest'\n",
    "#selected_neural_network='quite simple'\n",
    "#selected_neural_network='recommended simple v2'\n",
    "#selected_neural_network='adapted v3'\n",
    "\n",
    "\n",
    "# ---- FIRST NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = 'recommended simple v1'\n",
    "#selected_nn_code = 'm01 simple'\n",
    "\n",
    "# ---- 2nd NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m02 two layers\"\n",
    "\n",
    "\n",
    "# ---- 3rd NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m03 2 layers+wider\"\n",
    "\n",
    "\n",
    "# ---- 4th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m04 3 layers+wider\"\n",
    "\n",
    "# ---- 5th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m05 rec deep\"\n",
    "\n",
    "# ---- 6th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m05 my deep\"\n",
    "\n",
    "#selected_neural_network = selected_nn_code = \"\"\n",
    "\n",
    "# ---- 7th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m11 mega\"\n",
    "\n",
    "# ---- 8th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m12 mega\"\n",
    "\n",
    "# ---- 9th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m13 mega\"\n",
    "\n",
    "# ---- 10th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "#selected_neural_network = selected_nn_code = \"m14 mega\"\n",
    "\n",
    "# ---- 10th NEURAL NETWORK STRUCTURE DEFINITION ---- #\n",
    "selected_neural_network = selected_nn_code = \"m15 mega + dropout\"\n",
    "\n",
    "\n",
    "\n",
    "ALGORITHM = ALGORITHM.replace(\"[TYPE]\", selected_nn_code)\n",
    "\n",
    "create_python_script = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: loading all dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:34.035889Z",
     "iopub.status.busy": "2023-01-03T20:29:34.035642Z",
     "iopub.status.idle": "2023-01-03T20:29:36.949503Z",
     "shell.execute_reply": "2023-01-03T20:29:36.948070Z",
     "shell.execute_reply.started": "2023-01-03T20:29:34.035868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (0.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if \"JPY_PARENT_PID\" in os.environ:\n",
    "    is_jupyter = True\n",
    "else:\n",
    "    is_jupyter = False\n",
    "\n",
    "\n",
    "if is_jupyter:\n",
    "    #! pip install scikeras\n",
    "    !pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:36.952135Z",
     "iopub.status.busy": "2023-01-03T20:29:36.951656Z",
     "iopub.status.idle": "2023-01-03T20:29:36.968974Z",
     "shell.execute_reply": "2023-01-03T20:29:36.968233Z",
     "shell.execute_reply.started": "2023-01-03T20:29:36.952105Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'notebook_environment': 'gradient', 'use_gpu': True, 'debug_mode': False, 'quick_mode': False, 'quick_override_cv_splits': 2, 'quick_override_n_iter': 10, 'quick_override_n_jobs': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "from termcolor import colored\n",
    "from time import time\n",
    "import sklearn\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "start_timestamp = datetime.now()\n",
    "\n",
    "with open('../../z_envs/_envs.json') as f:\n",
    "    env_vars = json.loads(f.read())\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    run_env = 'colab'\n",
    "except:\n",
    "    try:\n",
    "        run_env = env_vars['notebook_environment']\n",
    "    except:\n",
    "        run_env = 'unknown'\n",
    "\n",
    "if \"JPY_PARENT_PID\" in os.environ:\n",
    "    is_jupyter = True\n",
    "else:\n",
    "    is_jupyter = False\n",
    "\n",
    "use_gpu = env_vars.get('use_gpu', False)\n",
    "debug_mode = env_vars.get('debug_mode', False)\n",
    "quick_mode = env_vars.get('quick_mode', False) | force_quick_mode\n",
    "OVERRIDE_CV = env_vars.get('quick_override_cv_splits', None) if quick_mode else None\n",
    "OVERRIDE_N_ITER = env_vars.get('quick_override_n_iter', None) if quick_mode else None\n",
    "OVERRIDE_JOBS = env_vars.get('quick_override_n_jobs', None) if quick_mode else None\n",
    "OVERRIDE_VERBOSE = 1\n",
    "#if quick_mode:OVERRIDE_CV, OVERRIDE_N_ITER = 2, 10\n",
    "\n",
    "already_timed = False\n",
    "no_dummies = 'no dummies' in DATA_DETAIL\n",
    "no_scaling = 'no scaling' in DATA_DETAIL\n",
    "#not_catboost = 'catboost' not in ALGORITHM.lower() or not no_dummies\n",
    "using_catboost = 'catboost' in ALGORITHM.lower()\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..', '..', '..'))\n",
    "if module_path not in sys.path:\n",
    "    #sys.path.append(module_path+\"\\\\zfunctions\")\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "if run_env not in ['colab', 'gradient', 'cloud']:\n",
    "    cloud_run = False\n",
    "    from functions_b__get_the_data_20221116 import set_csv_directory\n",
    "    set_csv_directory('final_split')\n",
    "else:\n",
    "    cloud_run = True\n",
    "\n",
    "from functions_0__common_20221116 import get_columns\n",
    "from functions_b__get_the_data_20221116 import get_combined_dataset, get_source_dataframe\n",
    "from functions_d1__prepare_cleanse_data_20221116 import tidy_dataset\n",
    "from functions_d2__transform_enrich_data_20221116 import preprocess, feature_engineer\n",
    "from functions_d3__prepare_store_data_20221116 import create_train_test_data\n",
    "from functions_e__train_model_20221116 import get_chosen_model, make_modelling_pipeline, get_cv_params, fit_model_with_cross_validation, get_hyperparameters\n",
    "from functions_f_evaluate_model_20221116 import get_best_estimator_average_time, get_results, update_results\n",
    "\n",
    "print(env_vars)\n",
    "start = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include any overrides specific to the algorthm / python environment being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:36.970713Z",
     "iopub.status.busy": "2023-01-03T20:29:36.969878Z",
     "iopub.status.idle": "2023-01-03T20:29:36.973733Z",
     "shell.execute_reply": "2023-01-03T20:29:36.973055Z",
     "shell.execute_reply.started": "2023-01-03T20:29:36.970688Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#running_locally = True\n",
    "running_locally = run_env == 'local'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: creating the ANN model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:36.976496Z",
     "iopub.status.busy": "2023-01-03T20:29:36.976115Z",
     "iopub.status.idle": "2023-01-03T20:29:37.010237Z",
     "shell.execute_reply": "2023-01-03T20:29:37.009684Z",
     "shell.execute_reply.started": "2023-01-03T20:29:36.976475Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "#from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "\n",
    "loss_dict = {\n",
    "    \"mean_squared_error\":'mse',\n",
    "    \"mean_absolute_error\":'mae'\n",
    "            }\n",
    "\n",
    "def make_simple_ann(key, inputs=-1):\n",
    "    \n",
    "    batch_size = 32\n",
    "    epochs = 400\n",
    "    learn_rate = 0.0003 # 0.003 #0.3\n",
    "    chosen_loss = 'mean_squared_error'\n",
    "    \n",
    "    if False:\n",
    "        pass\n",
    "    elif key == 'quite simple':\n",
    "\n",
    "        new_algorithm_detail = ALGORITHM_DETAIL_ORIG + 'quite simple model + normalise, mse'\n",
    "\n",
    "        learn_rate = 0.1\n",
    "        chosen_loss ='mean_squared_error'\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'recommended simple v1':\n",
    "\n",
    "        new_algorithm_detail = ALGORITHM_DETAIL_ORIG + 'recommended simple model/mse'\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'm02 two layers':\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(X_train.shape[1], activation='relu'),\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "\n",
    "    elif key == 'm03 2 layers+wider':\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(30, activation='relu'),\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'm04 3 layers+wider':\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            normalizer,\n",
    "            layers.Dense(30, activation='relu'),\n",
    "            layers.Dense(40, activation='relu'),\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'm0x four layers,wider,batchnorm':\n",
    "\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        batchnorm = layers.BatchNormalization()\n",
    "        activation = layers.Activation('relu')\n",
    "\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "\n",
    "        chosen_model = tf.keras.Sequential([\n",
    "            layers.Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'),\n",
    "            layers.Dense(30, activation='relu'),\n",
    "            batchnorm,\n",
    "            activation,\n",
    "            layers.Dense(40, activation='relu'),\n",
    "            layers.Dense(30, activation='relu'),\n",
    "            layers.Dense(units=1)\n",
    "        ])\n",
    "\n",
    "    elif key == 'm05 rec deep':\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "    elif key == 'm11 mega':\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(2148, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(2148, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "    elif key == 'm12 mega':\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        # Compile the network :\n",
    "        #chosen_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "    elif key == 'm13 mega':\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "        #normalizer.adapt(np.array(128))\n",
    "\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(normalizer),\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal',activation='relu'))\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        chosen_loss = 'mean_absolute_error' # 'mean_squared_error'\n",
    "\n",
    "    elif key == 'm14 mega':\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "        batchnorm = layers.BatchNormalization()\n",
    "        activation = layers.Activation('relu')\n",
    "\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(normalizer)\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        chosen_loss = 'mean_absolute_error' # 'mean_squared_error'\n",
    "\n",
    "    elif key == \"m15 mega + dropout\":\n",
    "        normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "        normalizer.adapt(np.array(X_train))\n",
    "        batchnorm = layers.BatchNormalization()\n",
    "        activation = layers.Activation('relu')\n",
    "\n",
    "        chosen_model = Sequential()\n",
    "\n",
    "        # The Input Layer :\n",
    "        chosen_model.add(normalizer)\n",
    "        chosen_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "\n",
    "        # The Hidden Layers :\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "\n",
    "        chosen_model.add(keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(1024, kernel_initializer='normal'))\n",
    "\n",
    "        chosen_model.add(keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(512, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "        chosen_model.add(Dense(256, kernel_initializer='normal'))\n",
    "        chosen_model.add(layers.BatchNormalization())\n",
    "        chosen_model.add(activation)\n",
    "\n",
    "        # The Output Layer :\n",
    "        chosen_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "        learn_rate = 0.0003\n",
    "        epochs = 800\n",
    "        batch_size = 64 #128\n",
    "        chosen_loss = 'mean_absolute_error' # 'mean_squared_error'\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"make_simple_ann: no entry for key:\", key)\n",
    "\n",
    "    if running_locally:\n",
    "        epochs = 8\n",
    "\n",
    "    # Compile the network :\n",
    "    chosen_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learn_rate),\n",
    "        loss=chosen_loss)\n",
    "\n",
    "\n",
    "    new_algorithm_detail = ALGORITHM_DETAIL_ORIG + loss_dict[chosen_loss]\n",
    "    new_algorithm_detail += f' +epochs={epochs}'\n",
    "    new_algorithm_detail += f' +learn={learn_rate}'\n",
    "    new_algorithm_detail += f' +batch={batch_size}'\n",
    "\n",
    "    return chosen_model, new_algorithm_detail, {'learning_rate':learn_rate, 'epochs':epochs, 'batch_size': batch_size}\n",
    "\n",
    "#make_simple_ann('m04 four layers,wider,batchnorm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: get the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:37.011725Z",
     "iopub.status.busy": "2023-01-03T20:29:37.011047Z",
     "iopub.status.idle": "2023-01-03T20:29:37.015217Z",
     "shell.execute_reply": "2023-01-03T20:29:37.014697Z",
     "shell.execute_reply.started": "2023-01-03T20:29:37.011699Z"
    }
   },
   "outputs": [],
   "source": [
    "columns, booleans, floats, categories, custom, wildcard = get_columns(version=VERSION)\n",
    "LABEL = 'Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:37.016798Z",
     "iopub.status.busy": "2023-01-03T20:29:37.016011Z",
     "iopub.status.idle": "2023-01-03T20:29:50.403946Z",
     "shell.execute_reply": "2023-01-03T20:29:50.403006Z",
     "shell.execute_reply.started": "2023-01-03T20:29:37.016775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data from ../../../https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/df_listings_v11.csv\n"
     ]
    }
   ],
   "source": [
    "df, retrieval_type = get_source_dataframe(cloud_run, VERSION, folder_prefix='../../../', row_limit=None)\n",
    "df_orig = df.copy()\n",
    "\n",
    "if retrieval_type != 'tidy':\n",
    "    df = tidy_dataset(df, version=int(VERSION))\n",
    "    df = feature_engineer(df, version=int(VERSION))\n",
    "\n",
    "\n",
    "    df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:50.405234Z",
     "iopub.status.busy": "2023-01-03T20:29:50.404984Z",
     "iopub.status.idle": "2023-01-03T20:29:50.410075Z",
     "shell.execute_reply": "2023-01-03T20:29:50.409397Z",
     "shell.execute_reply.started": "2023-01-03T20:29:50.405212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfeatures\u001b[0m ->  ['bedrooms', 'bathrooms', 'nearestStation', 'location.latitude', 'location.longitude', 'latitude_deviation', 'longitude_deviation', 'tenure.tenureType']\n",
      "\u001b[1m\u001b[32mlabel\u001b[0m ->  Price\n"
     ]
    }
   ],
   "source": [
    "print(colored(f\"features\", \"blue\"), \"-> \", columns)\n",
    "columns.insert(0, LABEL)\n",
    "print(colored(f\"label\", \"green\", None, ['bold']), \"-> \", LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:50.411054Z",
     "iopub.status.busy": "2023-01-03T20:29:50.410846Z",
     "iopub.status.idle": "2023-01-03T20:29:50.503357Z",
     "shell.execute_reply": "2023-01-03T20:29:50.502281Z",
     "shell.execute_reply.started": "2023-01-03T20:29:50.411036Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = preprocess(df, version=VERSION)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:50.505049Z",
     "iopub.status.busy": "2023-01-03T20:29:50.504808Z",
     "iopub.status.idle": "2023-01-03T20:29:50.531587Z",
     "shell.execute_reply": "2023-01-03T20:29:50.530804Z",
     "shell.execute_reply.started": "2023-01-03T20:29:50.505028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>nearestStation</th>\n",
       "      <th>location.latitude</th>\n",
       "      <th>location.longitude</th>\n",
       "      <th>latitude_deviation</th>\n",
       "      <th>longitude_deviation</th>\n",
       "      <th>tenure.tenureType</th>\n",
       "      <th>feature__1 bedroom</th>\n",
       "      <th>...</th>\n",
       "      <th>feature__2__en suite</th>\n",
       "      <th>feature__2__penthouse</th>\n",
       "      <th>feature__2__balcony</th>\n",
       "      <th>feature__2__double-glazing</th>\n",
       "      <th>feature__2__double glazing</th>\n",
       "      <th>feature__2__off-road parking</th>\n",
       "      <th>feature__2__security</th>\n",
       "      <th>feature__2__patio</th>\n",
       "      <th>feature__2__underfloor heating</th>\n",
       "      <th>feature__2__marble</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iddd</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14520525</th>\n",
       "      <td>550000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.274316</td>\n",
       "      <td>51.529950</td>\n",
       "      <td>-0.207020</td>\n",
       "      <td>0.030230</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27953107</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.305845</td>\n",
       "      <td>51.549390</td>\n",
       "      <td>-0.482600</td>\n",
       "      <td>0.049670</td>\n",
       "      <td>0.378180</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33593487</th>\n",
       "      <td>579950.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.438045</td>\n",
       "      <td>51.447180</td>\n",
       "      <td>-0.338770</td>\n",
       "      <td>0.052540</td>\n",
       "      <td>0.234350</td>\n",
       "      <td>FREEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35271294</th>\n",
       "      <td>370000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399307</td>\n",
       "      <td>51.449568</td>\n",
       "      <td>-0.140154</td>\n",
       "      <td>0.050152</td>\n",
       "      <td>0.035734</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44749111</th>\n",
       "      <td>475000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.410550</td>\n",
       "      <td>51.370050</td>\n",
       "      <td>-0.212410</td>\n",
       "      <td>0.129670</td>\n",
       "      <td>0.107990</td>\n",
       "      <td>FREEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46204665</th>\n",
       "      <td>435000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.314779</td>\n",
       "      <td>51.539070</td>\n",
       "      <td>-0.198935</td>\n",
       "      <td>0.039350</td>\n",
       "      <td>0.094515</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49020666</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875911</td>\n",
       "      <td>51.539959</td>\n",
       "      <td>-0.380863</td>\n",
       "      <td>0.040239</td>\n",
       "      <td>0.276443</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49036279</th>\n",
       "      <td>275000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.474368</td>\n",
       "      <td>51.541780</td>\n",
       "      <td>0.037890</td>\n",
       "      <td>0.042060</td>\n",
       "      <td>0.142310</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49303873</th>\n",
       "      <td>450000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.577040</td>\n",
       "      <td>51.524880</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.025160</td>\n",
       "      <td>0.291620</td>\n",
       "      <td>FREEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52064391</th>\n",
       "      <td>349950.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.212734</td>\n",
       "      <td>51.470800</td>\n",
       "      <td>-0.361820</td>\n",
       "      <td>0.028920</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52187854</th>\n",
       "      <td>450000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.446802</td>\n",
       "      <td>51.527199</td>\n",
       "      <td>-0.202898</td>\n",
       "      <td>0.027479</td>\n",
       "      <td>0.098478</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52845963</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.650562</td>\n",
       "      <td>51.398040</td>\n",
       "      <td>-0.076812</td>\n",
       "      <td>0.101680</td>\n",
       "      <td>0.027608</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52913496</th>\n",
       "      <td>220000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945991</td>\n",
       "      <td>51.539383</td>\n",
       "      <td>-0.382239</td>\n",
       "      <td>0.039663</td>\n",
       "      <td>0.277819</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53609433</th>\n",
       "      <td>489995.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087081</td>\n",
       "      <td>51.532620</td>\n",
       "      <td>-0.107860</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938989</th>\n",
       "      <td>450000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775203</td>\n",
       "      <td>51.658287</td>\n",
       "      <td>-0.207902</td>\n",
       "      <td>0.158567</td>\n",
       "      <td>0.103482</td>\n",
       "      <td>FREEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54713232</th>\n",
       "      <td>332000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.319226</td>\n",
       "      <td>51.612300</td>\n",
       "      <td>-0.119860</td>\n",
       "      <td>0.112580</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>SHARE_OF_FREEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54904122</th>\n",
       "      <td>365000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.260722</td>\n",
       "      <td>51.593595</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.093875</td>\n",
       "      <td>0.126466</td>\n",
       "      <td>SHARE_OF_FREEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54991934</th>\n",
       "      <td>430000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.497268</td>\n",
       "      <td>51.528720</td>\n",
       "      <td>0.039180</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.143600</td>\n",
       "      <td>FREEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55043230</th>\n",
       "      <td>260000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.384607</td>\n",
       "      <td>51.544430</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.044710</td>\n",
       "      <td>0.118920</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55187658</th>\n",
       "      <td>430000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.289033</td>\n",
       "      <td>51.507570</td>\n",
       "      <td>0.078030</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>0.182450</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55805965</th>\n",
       "      <td>280000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.742859</td>\n",
       "      <td>51.520910</td>\n",
       "      <td>0.022680</td>\n",
       "      <td>0.021190</td>\n",
       "      <td>0.127100</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55839051</th>\n",
       "      <td>599950.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.259168</td>\n",
       "      <td>51.579186</td>\n",
       "      <td>-0.209020</td>\n",
       "      <td>0.079466</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55940994</th>\n",
       "      <td>385000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.403987</td>\n",
       "      <td>51.376930</td>\n",
       "      <td>-0.238870</td>\n",
       "      <td>0.122790</td>\n",
       "      <td>0.134450</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56449305</th>\n",
       "      <td>380000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310271</td>\n",
       "      <td>51.600483</td>\n",
       "      <td>-0.062096</td>\n",
       "      <td>0.100763</td>\n",
       "      <td>0.042324</td>\n",
       "      <td>FREEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57221413</th>\n",
       "      <td>475000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.409784</td>\n",
       "      <td>51.497260</td>\n",
       "      <td>-0.422530</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.318110</td>\n",
       "      <td>FREEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57878227</th>\n",
       "      <td>490000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052498</td>\n",
       "      <td>51.580270</td>\n",
       "      <td>0.022290</td>\n",
       "      <td>0.080550</td>\n",
       "      <td>0.126710</td>\n",
       "      <td>SHARE_OF_FREEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59258796</th>\n",
       "      <td>475000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.424573</td>\n",
       "      <td>51.536335</td>\n",
       "      <td>-0.068537</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.035883</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59658138</th>\n",
       "      <td>499995.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.396544</td>\n",
       "      <td>51.462211</td>\n",
       "      <td>-0.196876</td>\n",
       "      <td>0.037509</td>\n",
       "      <td>0.092456</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60741240</th>\n",
       "      <td>435000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162014</td>\n",
       "      <td>51.612150</td>\n",
       "      <td>-0.277430</td>\n",
       "      <td>0.112430</td>\n",
       "      <td>0.173010</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61387062</th>\n",
       "      <td>375000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.493102</td>\n",
       "      <td>51.448697</td>\n",
       "      <td>-0.174068</td>\n",
       "      <td>0.051023</td>\n",
       "      <td>0.069648</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows  81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price  bedrooms  bathrooms  nearestStation  location.latitude  \\\n",
       "iddd                                                                         \n",
       "14520525  550000.0       3.0        1.0        0.274316          51.529950   \n",
       "27953107  400000.0       2.0        2.0        0.305845          51.549390   \n",
       "33593487  579950.0       2.0        1.0        0.438045          51.447180   \n",
       "35271294  370000.0       2.0        1.0        0.399307          51.449568   \n",
       "44749111  475000.0       2.0        1.0        0.410550          51.370050   \n",
       "46204665  435000.0       3.0        2.0        0.314779          51.539070   \n",
       "49020666  200000.0       1.0        1.0        0.875911          51.539959   \n",
       "49036279  275000.0       2.0        1.0        0.474368          51.541780   \n",
       "49303873  450000.0       3.0        2.0        0.577040          51.524880   \n",
       "52064391  349950.0       2.0        2.0        0.212734          51.470800   \n",
       "52187854  450000.0       1.0        1.0        0.446802          51.527199   \n",
       "52845963  200000.0       2.0        1.0        0.650562          51.398040   \n",
       "52913496  220000.0       1.0        1.0        0.945991          51.539383   \n",
       "53609433  489995.0       1.0        1.0        0.087081          51.532620   \n",
       "53938989  450000.0       2.0        1.0        0.775203          51.658287   \n",
       "54713232  332000.0       2.0        1.0        0.319226          51.612300   \n",
       "54904122  365000.0       2.0        1.0        0.260722          51.593595   \n",
       "54991934  430000.0       3.0        1.0        0.497268          51.528720   \n",
       "55043230  260000.0       1.0        1.0        0.384607          51.544430   \n",
       "55187658  430000.0       2.0        2.0        0.289033          51.507570   \n",
       "55805965  280000.0       2.0        1.0        0.742859          51.520910   \n",
       "55839051  599950.0       2.0        1.0        0.259168          51.579186   \n",
       "55940994  385000.0       2.0        2.0        0.403987          51.376930   \n",
       "56449305  380000.0       2.0        1.0        0.310271          51.600483   \n",
       "57221413  475000.0       3.0        2.0        0.409784          51.497260   \n",
       "57878227  490000.0       2.0        1.0        0.052498          51.580270   \n",
       "59258796  475000.0       3.0        1.0        0.424573          51.536335   \n",
       "59658138  499995.0       1.0        1.0        0.396544          51.462211   \n",
       "60741240  435000.0       2.0        1.0        0.162014          51.612150   \n",
       "61387062  375000.0       2.0        1.0        0.493102          51.448697   \n",
       "\n",
       "          location.longitude  latitude_deviation  longitude_deviation  \\\n",
       "iddd                                                                    \n",
       "14520525           -0.207020            0.030230             0.102600   \n",
       "27953107           -0.482600            0.049670             0.378180   \n",
       "33593487           -0.338770            0.052540             0.234350   \n",
       "35271294           -0.140154            0.050152             0.035734   \n",
       "44749111           -0.212410            0.129670             0.107990   \n",
       "46204665           -0.198935            0.039350             0.094515   \n",
       "49020666           -0.380863            0.040239             0.276443   \n",
       "49036279            0.037890            0.042060             0.142310   \n",
       "49303873            0.187200            0.025160             0.291620   \n",
       "52064391           -0.361820            0.028920             0.257400   \n",
       "52187854           -0.202898            0.027479             0.098478   \n",
       "52845963           -0.076812            0.101680             0.027608   \n",
       "52913496           -0.382239            0.039663             0.277819   \n",
       "53609433           -0.107860            0.032900             0.003440   \n",
       "53938989           -0.207902            0.158567             0.103482   \n",
       "54713232           -0.119860            0.112580             0.015440   \n",
       "54904122            0.022046            0.093875             0.126466   \n",
       "54991934            0.039180            0.029000             0.143600   \n",
       "55043230            0.014500            0.044710             0.118920   \n",
       "55187658            0.078030            0.007850             0.182450   \n",
       "55805965            0.022680            0.021190             0.127100   \n",
       "55839051           -0.209020            0.079466             0.104600   \n",
       "55940994           -0.238870            0.122790             0.134450   \n",
       "56449305           -0.062096            0.100763             0.042324   \n",
       "57221413           -0.422530            0.002460             0.318110   \n",
       "57878227            0.022290            0.080550             0.126710   \n",
       "59258796           -0.068537            0.036615             0.035883   \n",
       "59658138           -0.196876            0.037509             0.092456   \n",
       "60741240           -0.277430            0.112430             0.173010   \n",
       "61387062           -0.174068            0.051023             0.069648   \n",
       "\n",
       "          tenure.tenureType  feature__1 bedroom  ...  feature__2__en suite  \\\n",
       "iddd                                             ...                         \n",
       "14520525          LEASEHOLD                   0  ...                     0   \n",
       "27953107          LEASEHOLD                   0  ...                     0   \n",
       "33593487           FREEHOLD                   0  ...                     0   \n",
       "35271294          LEASEHOLD                   0  ...                     0   \n",
       "44749111           FREEHOLD                   0  ...                     0   \n",
       "46204665          LEASEHOLD                   0  ...                     1   \n",
       "49020666          LEASEHOLD                   0  ...                     0   \n",
       "49036279          LEASEHOLD                   0  ...                     0   \n",
       "49303873           FREEHOLD                   0  ...                     0   \n",
       "52064391          LEASEHOLD                   0  ...                     1   \n",
       "52187854          LEASEHOLD                   0  ...                     0   \n",
       "52845963          LEASEHOLD                   0  ...                     0   \n",
       "52913496          LEASEHOLD                   0  ...                     0   \n",
       "53609433          LEASEHOLD                   0  ...                     0   \n",
       "53938989           FREEHOLD                   0  ...                     0   \n",
       "54713232  SHARE_OF_FREEHOLD                   0  ...                     0   \n",
       "54904122  SHARE_OF_FREEHOLD                   0  ...                     0   \n",
       "54991934           FREEHOLD                   0  ...                     0   \n",
       "55043230          LEASEHOLD                   0  ...                     0   \n",
       "55187658          LEASEHOLD                   0  ...                     1   \n",
       "55805965          LEASEHOLD                   0  ...                     0   \n",
       "55839051          LEASEHOLD                   0  ...                     0   \n",
       "55940994          LEASEHOLD                   0  ...                     0   \n",
       "56449305           FREEHOLD                   0  ...                     0   \n",
       "57221413           FREEHOLD                   0  ...                     0   \n",
       "57878227  SHARE_OF_FREEHOLD                   0  ...                     0   \n",
       "59258796          LEASEHOLD                   0  ...                     0   \n",
       "59658138          LEASEHOLD                   0  ...                     0   \n",
       "60741240          LEASEHOLD                   0  ...                     0   \n",
       "61387062          LEASEHOLD                   0  ...                     0   \n",
       "\n",
       "          feature__2__penthouse  feature__2__balcony  \\\n",
       "iddd                                                   \n",
       "14520525                      0                    1   \n",
       "27953107                      0                    1   \n",
       "33593487                      0                    0   \n",
       "35271294                      0                    1   \n",
       "44749111                      0                    0   \n",
       "46204665                      0                    0   \n",
       "49020666                      0                    0   \n",
       "49036279                      0                    0   \n",
       "49303873                      0                    0   \n",
       "52064391                      0                    1   \n",
       "52187854                      0                    0   \n",
       "52845963                      0                    0   \n",
       "52913496                      0                    0   \n",
       "53609433                      0                    0   \n",
       "53938989                      0                    0   \n",
       "54713232                      0                    0   \n",
       "54904122                      0                    0   \n",
       "54991934                      0                    0   \n",
       "55043230                      0                    0   \n",
       "55187658                      0                    0   \n",
       "55805965                      0                    0   \n",
       "55839051                      0                    0   \n",
       "55940994                      0                    0   \n",
       "56449305                      0                    0   \n",
       "57221413                      0                    0   \n",
       "57878227                      0                    1   \n",
       "59258796                      0                    0   \n",
       "59658138                      0                    0   \n",
       "60741240                      0                    1   \n",
       "61387062                      0                    0   \n",
       "\n",
       "          feature__2__double-glazing  feature__2__double glazing  \\\n",
       "iddd                                                               \n",
       "14520525                           0                           0   \n",
       "27953107                           0                           0   \n",
       "33593487                           0                           0   \n",
       "35271294                           0                           1   \n",
       "44749111                           0                           1   \n",
       "46204665                           0                           0   \n",
       "49020666                           0                           0   \n",
       "49036279                           0                           0   \n",
       "49303873                           0                           0   \n",
       "52064391                           0                           0   \n",
       "52187854                           0                           0   \n",
       "52845963                           0                           0   \n",
       "52913496                           0                           0   \n",
       "53609433                           0                           0   \n",
       "53938989                           0                           0   \n",
       "54713232                           0                           0   \n",
       "54904122                           0                           0   \n",
       "54991934                           0                           0   \n",
       "55043230                           0                           0   \n",
       "55187658                           0                           0   \n",
       "55805965                           0                           1   \n",
       "55839051                           0                           0   \n",
       "55940994                           0                           1   \n",
       "56449305                           0                           0   \n",
       "57221413                           0                           0   \n",
       "57878227                           0                           0   \n",
       "59258796                           0                           0   \n",
       "59658138                           0                           0   \n",
       "60741240                           0                           0   \n",
       "61387062                           0                           0   \n",
       "\n",
       "          feature__2__off-road parking  feature__2__security  \\\n",
       "iddd                                                           \n",
       "14520525                             0                     0   \n",
       "27953107                             0                     0   \n",
       "33593487                             0                     0   \n",
       "35271294                             0                     0   \n",
       "44749111                             0                     0   \n",
       "46204665                             0                     0   \n",
       "49020666                             0                     0   \n",
       "49036279                             0                     0   \n",
       "49303873                             0                     0   \n",
       "52064391                             0                     0   \n",
       "52187854                             0                     0   \n",
       "52845963                             0                     0   \n",
       "52913496                             0                     0   \n",
       "53609433                             0                     0   \n",
       "53938989                             0                     0   \n",
       "54713232                             0                     0   \n",
       "54904122                             0                     0   \n",
       "54991934                             0                     0   \n",
       "55043230                             0                     0   \n",
       "55187658                             0                     1   \n",
       "55805965                             0                     0   \n",
       "55839051                             0                     0   \n",
       "55940994                             0                     0   \n",
       "56449305                             0                     0   \n",
       "57221413                             0                     0   \n",
       "57878227                             0                     0   \n",
       "59258796                             0                     0   \n",
       "59658138                             0                     0   \n",
       "60741240                             0                     0   \n",
       "61387062                             0                     0   \n",
       "\n",
       "          feature__2__patio  feature__2__underfloor heating  \\\n",
       "iddd                                                          \n",
       "14520525                  0                               0   \n",
       "27953107                  0                               0   \n",
       "33593487                  0                               0   \n",
       "35271294                  0                               0   \n",
       "44749111                  0                               0   \n",
       "46204665                  0                               0   \n",
       "49020666                  0                               0   \n",
       "49036279                  0                               0   \n",
       "49303873                  0                               0   \n",
       "52064391                  0                               0   \n",
       "52187854                  0                               0   \n",
       "52845963                  0                               0   \n",
       "52913496                  0                               0   \n",
       "53609433                  0                               0   \n",
       "53938989                  0                               0   \n",
       "54713232                  0                               0   \n",
       "54904122                  0                               0   \n",
       "54991934                  0                               0   \n",
       "55043230                  0                               0   \n",
       "55187658                  0                               0   \n",
       "55805965                  0                               0   \n",
       "55839051                  0                               0   \n",
       "55940994                  0                               0   \n",
       "56449305                  0                               0   \n",
       "57221413                  0                               0   \n",
       "57878227                  0                               0   \n",
       "59258796                  0                               0   \n",
       "59658138                  0                               0   \n",
       "60741240                  0                               0   \n",
       "61387062                  0                               0   \n",
       "\n",
       "          feature__2__marble  \n",
       "iddd                          \n",
       "14520525                   0  \n",
       "27953107                   0  \n",
       "33593487                   0  \n",
       "35271294                   0  \n",
       "44749111                   0  \n",
       "46204665                   0  \n",
       "49020666                   0  \n",
       "49036279                   0  \n",
       "49303873                   0  \n",
       "52064391                   0  \n",
       "52187854                   0  \n",
       "52845963                   0  \n",
       "52913496                   0  \n",
       "53609433                   0  \n",
       "53938989                   0  \n",
       "54713232                   0  \n",
       "54904122                   0  \n",
       "54991934                   0  \n",
       "55043230                   0  \n",
       "55187658                   0  \n",
       "55805965                   0  \n",
       "55839051                   0  \n",
       "55940994                   0  \n",
       "56449305                   0  \n",
       "57221413                   0  \n",
       "57878227                   0  \n",
       "59258796                   0  \n",
       "59658138                   0  \n",
       "60741240                   0  \n",
       "61387062                   0  \n",
       "\n",
       "[30 rows x 81 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Price'] = df['Price'] / price_divisor # potentially making the price smaller to make the ANN perform better\n",
    "\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code\n",
    "style = \"background:red;color:red\" > ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** </code>\n",
    "\n",
    "## NEW Stage: do autoencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:50.534403Z",
     "iopub.status.busy": "2023-01-03T20:29:50.534157Z",
     "iopub.status.idle": "2023-01-03T20:29:50.715238Z",
     "shell.execute_reply": "2023-01-03T20:29:50.714561Z",
     "shell.execute_reply.started": "2023-01-03T20:29:50.534382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44127, 81)\n",
      "(39714, 83) (4413, 83) (39714, 1) (4413, 1) (39714, 1) (4413, 1) (39714, 1) (4413, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig, X_train_index, X_test_index, y_train_index, y_test_index, df_features, df_labels = create_train_test_data(\n",
    "    df,\n",
    "    categories=categories,\n",
    "    RANDOM_STATE=RANDOM_STATE, return_index=True,\n",
    "    drop_nulls=True,\n",
    "    no_dummies=no_dummies\n",
    ")\n",
    "\n",
    "if 'forest' in ALGORITHM.lower() or ALGORITHM.lower() == 'light gradient boosting':\n",
    "    #y_train_orig = y_train\n",
    "    y_train_orig = y_train_orig.ravel()\n",
    "\n",
    "#print(X_train[0])\n",
    "print(df.shape)\n",
    "print(X_train_orig.shape, X_test_orig.shape, y_train_orig.shape, y_test_orig.shape, X_train_index.shape,\n",
    "      X_test_index.shape,\n",
    "      y_train_index.shape, y_test_index.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:50.716916Z",
     "iopub.status.busy": "2023-01-03T20:29:50.716667Z",
     "iopub.status.idle": "2023-01-03T20:29:51.234725Z",
     "shell.execute_reply": "2023-01-03T20:29:51.233988Z",
     "shell.execute_reply.started": "2023-01-03T20:29:50.716895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['pca', '0.95% retain']\n",
      "preserve this many features: 55 out of 83\n"
     ]
    }
   ],
   "source": [
    "if not use_dimension_reduction:\n",
    "    print(DATA_DETAIL)\n",
    "    DATA_DETAIL = [] # DATA_DETAIL.remove('pca')\n",
    "    print(DATA_DETAIL)\n",
    "else:\n",
    "    print(DATA_DETAIL)\n",
    "    DATA_DETAIL = ['pca'] # DATA_DETAIL.append('pca')\n",
    "    DATA_DETAIL.append(str(round(pca_data_retain,4))+\"% retain\")\n",
    "    print(DATA_DETAIL)\n",
    "\n",
    "if use_dimension_reduction:\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    pca = PCA()\n",
    "    pca.fit(X_train_orig)\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "    d = np.argmax(cumsum >= pca_data_retain) + 1\n",
    "    print(\"preserve this many features:\", d, \"out of\", X_train_orig.shape[1])\n",
    "\n",
    "    pca = PCA(n_components=pca_data_retain)\n",
    "    X_train = pca.fit_transform(X_train_orig)\n",
    "    X_test =  pca.transform(X_test_orig)\n",
    "    y_train = y_train_orig\n",
    "    y_test = y_test_orig\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = X_train_orig, X_test_orig, y_train_orig, y_test_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of dimensionality reduction segment\n",
    "\n",
    "<code\n",
    "style = \"background:black;color:black\" > ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** </code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage:\n",
    "* #### retrieve the hyperparameters for this model, and\n",
    "* #### train the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:51.236008Z",
     "iopub.status.busy": "2023-01-03T20:29:51.235726Z",
     "iopub.status.idle": "2023-01-03T20:29:52.957097Z",
     "shell.execute_reply": "2023-01-03T20:29:52.956238Z",
     "shell.execute_reply.started": "2023-01-03T20:29:51.235986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mae +epochs=800 +learn=0.0003 +batch=64'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_model, ALGORITHM_DETAIL, chosen_params = make_simple_ann(selected_neural_network)\n",
    "\n",
    "chosen_epochs = chosen_params['epochs']\n",
    "chosen_batch_size = chosen_params['batch_size']\n",
    "\n",
    "if quick_mode: chosen_epochs=20\n",
    "ALGORITHM_DETAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:52.958362Z",
     "iopub.status.busy": "2023-01-03T20:29:52.958119Z",
     "iopub.status.idle": "2023-01-03T20:29:52.989618Z",
     "shell.execute_reply": "2023-01-03T20:29:52.988713Z",
     "shell.execute_reply.started": "2023-01-03T20:29:52.958341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_neural_network m15 mega + dropout\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_1 (Normalizat  (None, 55)               111       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               7168      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   multiple                  0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 1024)             4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,417,520\n",
      "Trainable params: 2,410,241\n",
      "Non-trainable params: 7,279\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"selected_neural_network\",selected_neural_network)\n",
    "trainable_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-03T20:29:52.990854Z",
     "iopub.status.busy": "2023-01-03T20:29:52.990616Z"
    },
    "pycharm": {
     "name": "#%%time\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "559/559 [==============================] - 5s 7ms/step - loss: 425146.8750 - val_loss: 425938.8750\n",
      "Epoch 2/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 425097.3750 - val_loss: 425859.5625\n",
      "Epoch 3/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 425010.0938 - val_loss: 425735.5938\n",
      "Epoch 4/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 424891.2500 - val_loss: 425585.7812\n",
      "Epoch 5/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 424745.1875 - val_loss: 425448.2188\n",
      "Epoch 6/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 424574.8125 - val_loss: 425221.3125\n",
      "Epoch 7/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 424380.7812 - val_loss: 425065.8750\n",
      "Epoch 8/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 424165.7812 - val_loss: 424852.6562\n",
      "Epoch 9/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 423929.8438 - val_loss: 424529.7500\n",
      "Epoch 10/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 423674.7188 - val_loss: 424306.3750\n",
      "Epoch 11/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 423399.8125 - val_loss: 423907.0312\n",
      "Epoch 12/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 423103.0312 - val_loss: 423683.8750\n",
      "Epoch 13/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 422787.5938 - val_loss: 423342.6250\n",
      "Epoch 14/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 422454.2188 - val_loss: 423103.3438\n",
      "Epoch 15/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 422101.0312 - val_loss: 422545.3125\n",
      "Epoch 16/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 421730.0625 - val_loss: 422266.5625\n",
      "Epoch 17/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 421339.5625 - val_loss: 421998.5625\n",
      "Epoch 18/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 420929.2812 - val_loss: 421537.1875\n",
      "Epoch 19/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 420501.6562 - val_loss: 421244.5312\n",
      "Epoch 20/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 420055.7188 - val_loss: 420521.0000\n",
      "Epoch 21/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 419590.1875 - val_loss: 419929.0312\n",
      "Epoch 22/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 419108.0625 - val_loss: 419826.1562\n",
      "Epoch 23/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 418606.0938 - val_loss: 418699.4375\n",
      "Epoch 24/800\n",
      "559/559 [==============================] - 4s 6ms/step - loss: 418086.3750 - val_loss: 418747.3750\n",
      "Epoch 25/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 417544.0625 - val_loss: 418293.3750\n",
      "Epoch 26/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 416989.4062 - val_loss: 417406.0625\n",
      "Epoch 27/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 416413.7500 - val_loss: 417354.5000\n",
      "Epoch 28/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 415820.2500 - val_loss: 416418.4062\n",
      "Epoch 29/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 415207.9062 - val_loss: 415280.5625\n",
      "Epoch 30/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 414583.9062 - val_loss: 414997.7500\n",
      "Epoch 31/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 413932.5938 - val_loss: 414296.6875\n",
      "Epoch 32/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 413264.0625 - val_loss: 412423.4375\n",
      "Epoch 33/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 412577.8438 - val_loss: 412878.8438\n",
      "Epoch 34/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 411883.4688 - val_loss: 412495.3750\n",
      "Epoch 35/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 411162.0312 - val_loss: 411330.8750\n",
      "Epoch 36/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 410418.6250 - val_loss: 410430.9375\n",
      "Epoch 37/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 409662.9375 - val_loss: 409841.6875\n",
      "Epoch 38/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 408890.3438 - val_loss: 408987.5000\n",
      "Epoch 39/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 408089.7812 - val_loss: 408248.9062\n",
      "Epoch 40/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 407279.4062 - val_loss: 407830.9375\n",
      "Epoch 41/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 406449.0000 - val_loss: 405806.7812\n",
      "Epoch 42/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 405603.1875 - val_loss: 405315.6562\n",
      "Epoch 43/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 404738.4375 - val_loss: 404761.5312\n",
      "Epoch 44/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 403852.4688 - val_loss: 404295.5938\n",
      "Epoch 45/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 402958.7188 - val_loss: 403177.4375\n",
      "Epoch 46/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 402033.3125 - val_loss: 402384.0938\n",
      "Epoch 47/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 401095.6562 - val_loss: 402338.7812\n",
      "Epoch 48/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 400140.2812 - val_loss: 398834.4375\n",
      "Epoch 49/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 399166.6875 - val_loss: 400693.2500\n",
      "Epoch 50/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 398178.9375 - val_loss: 398771.6250\n",
      "Epoch 51/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 397174.6250 - val_loss: 397001.4062\n",
      "Epoch 52/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 396138.2812 - val_loss: 396377.5625\n",
      "Epoch 53/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 395107.8125 - val_loss: 395522.9062\n",
      "Epoch 54/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 394054.2500 - val_loss: 396342.4688\n",
      "Epoch 55/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 392982.0000 - val_loss: 392896.5938\n",
      "Epoch 56/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 391874.3438 - val_loss: 392235.1250\n",
      "Epoch 57/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 390741.4375 - val_loss: 390085.0000\n",
      "Epoch 58/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 389616.9062 - val_loss: 389206.0938\n",
      "Epoch 59/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 388471.4688 - val_loss: 389561.1562\n",
      "Epoch 60/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 387297.2500 - val_loss: 386640.3750\n",
      "Epoch 61/800\n",
      "559/559 [==============================] - 4s 6ms/step - loss: 386112.2812 - val_loss: 386346.0938\n",
      "Epoch 62/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 384928.8750 - val_loss: 385723.8438\n",
      "Epoch 63/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 383705.5938 - val_loss: 382671.5625\n",
      "Epoch 64/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 382439.5625 - val_loss: 382816.0000\n",
      "Epoch 65/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 381202.1875 - val_loss: 378671.7812\n",
      "Epoch 66/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 379940.0625 - val_loss: 377911.7812\n",
      "Epoch 67/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 378631.9062 - val_loss: 378851.9062\n",
      "Epoch 68/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 377316.5625 - val_loss: 379281.4688\n",
      "Epoch 69/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 375992.7188 - val_loss: 376817.2188\n",
      "Epoch 70/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 374633.1562 - val_loss: 373279.4375\n",
      "Epoch 71/800\n",
      "559/559 [==============================] - 4s 6ms/step - loss: 373277.5938 - val_loss: 373322.0312\n",
      "Epoch 72/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 371905.7188 - val_loss: 372612.3125\n",
      "Epoch 73/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 370533.2500 - val_loss: 369856.1875\n",
      "Epoch 74/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 369081.7500 - val_loss: 368990.6562\n",
      "Epoch 75/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 367631.8750 - val_loss: 364866.6562\n",
      "Epoch 76/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 366180.9375 - val_loss: 367885.7500\n",
      "Epoch 77/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 364715.7188 - val_loss: 361685.4375\n",
      "Epoch 78/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 363232.4062 - val_loss: 364679.5312\n",
      "Epoch 79/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 361727.9688 - val_loss: 364708.9375\n",
      "Epoch 80/800\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 360199.4062 - val_loss: 360770.6875\n",
      "Epoch 81/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 358652.6875 - val_loss: 357890.6562\n",
      "Epoch 82/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 357064.9688 - val_loss: 354736.4688\n",
      "Epoch 83/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 355519.9688 - val_loss: 358043.3125\n",
      "Epoch 84/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 353924.3438 - val_loss: 349263.2188\n",
      "Epoch 85/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 352284.9375 - val_loss: 350630.4688\n",
      "Epoch 86/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 350658.3438 - val_loss: 348543.7188\n",
      "Epoch 87/800\n",
      "559/559 [==============================] - 4s 8ms/step - loss: 349002.5938 - val_loss: 351583.1875\n",
      "Epoch 88/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 347339.0000 - val_loss: 349160.0938\n",
      "Epoch 89/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 345658.3750 - val_loss: 350833.5938\n",
      "Epoch 90/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 343959.5000 - val_loss: 346685.9688\n",
      "Epoch 91/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 342232.2188 - val_loss: 341271.1250\n",
      "Epoch 92/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 340513.5938 - val_loss: 335498.9375\n",
      "Epoch 93/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 338738.5312 - val_loss: 336325.7812\n",
      "Epoch 94/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 336962.7812 - val_loss: 335331.5000\n",
      "Epoch 95/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 335198.8125 - val_loss: 332507.5312\n",
      "Epoch 96/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 333425.5625 - val_loss: 332947.9375\n",
      "Epoch 97/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 331624.9062 - val_loss: 321289.2188\n",
      "Epoch 98/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 329777.0938 - val_loss: 330379.0625\n",
      "Epoch 99/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 327886.1250 - val_loss: 328227.9062\n",
      "Epoch 100/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 326062.5625 - val_loss: 325365.9375\n",
      "Epoch 101/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 324133.8125 - val_loss: 320344.0625\n",
      "Epoch 102/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 322207.0312 - val_loss: 319908.6250\n",
      "Epoch 103/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 320304.9688 - val_loss: 321762.1875\n",
      "Epoch 104/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 318316.3125 - val_loss: 317667.6875\n",
      "Epoch 105/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 316361.9375 - val_loss: 312538.5312\n",
      "Epoch 106/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 314364.0312 - val_loss: 308761.1875\n",
      "Epoch 107/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 312360.5312 - val_loss: 307221.5625\n",
      "Epoch 108/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 310373.2500 - val_loss: 309206.0000\n",
      "Epoch 109/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 308312.6562 - val_loss: 308311.6562\n",
      "Epoch 110/800\n",
      "559/559 [==============================] - 4s 6ms/step - loss: 306273.7500 - val_loss: 306299.4688\n",
      "Epoch 111/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 304210.8125 - val_loss: 300128.0312\n",
      "Epoch 112/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 302108.6562 - val_loss: 301269.1875\n",
      "Epoch 113/800\n",
      "559/559 [==============================] - 4s 6ms/step - loss: 299995.1250 - val_loss: 302336.4375\n",
      "Epoch 114/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 297908.8438 - val_loss: 296865.0312\n",
      "Epoch 115/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 295745.4375 - val_loss: 295148.4375\n",
      "Epoch 116/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 293607.7812 - val_loss: 293119.9062\n",
      "Epoch 117/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 291429.0000 - val_loss: 283893.6562\n",
      "Epoch 118/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 289254.3125 - val_loss: 289406.2500\n",
      "Epoch 119/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 287093.9375 - val_loss: 288986.7812\n",
      "Epoch 120/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 284810.6250 - val_loss: 279071.7500\n",
      "Epoch 121/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 282566.0312 - val_loss: 274399.5625\n",
      "Epoch 122/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 280320.0000 - val_loss: 277333.6875\n",
      "Epoch 123/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 278064.8750 - val_loss: 273103.5000\n",
      "Epoch 124/800\n",
      "559/559 [==============================] - 4s 6ms/step - loss: 275754.2188 - val_loss: 275735.9062\n",
      "Epoch 125/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 273508.4375 - val_loss: 257267.7969\n",
      "Epoch 126/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 271155.5625 - val_loss: 274312.2188\n",
      "Epoch 127/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 268830.7188 - val_loss: 269649.4062\n",
      "Epoch 128/800\n",
      "559/559 [==============================] - 4s 6ms/step - loss: 266485.4375 - val_loss: 271956.4375\n",
      "Epoch 129/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 264128.1250 - val_loss: 263127.8438\n",
      "Epoch 130/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 261721.9844 - val_loss: 255495.8438\n",
      "Epoch 131/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 259337.4062 - val_loss: 256389.7500\n",
      "Epoch 132/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 256927.3281 - val_loss: 243042.0156\n",
      "Epoch 133/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 254499.2031 - val_loss: 245490.5469\n",
      "Epoch 134/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 252082.2656 - val_loss: 255167.3750\n",
      "Epoch 135/800\n",
      "559/559 [==============================] - 4s 6ms/step - loss: 249692.2656 - val_loss: 249209.4375\n",
      "Epoch 136/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 247195.8906 - val_loss: 235562.4219\n",
      "Epoch 137/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 244720.1875 - val_loss: 242951.8438\n",
      "Epoch 138/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 242241.6875 - val_loss: 239728.9375\n",
      "Epoch 139/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 239714.9062 - val_loss: 237470.2188\n",
      "Epoch 140/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 237192.7812 - val_loss: 233613.9844\n",
      "Epoch 141/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 234619.7969 - val_loss: 242240.4531\n",
      "Epoch 142/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 232044.4062 - val_loss: 225567.5312\n",
      "Epoch 143/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 229464.0938 - val_loss: 224866.1250\n",
      "Epoch 144/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 226864.7344 - val_loss: 230873.0469\n",
      "Epoch 145/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 224230.0000 - val_loss: 235160.3594\n",
      "Epoch 146/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 221617.7344 - val_loss: 217289.2188\n",
      "Epoch 147/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 218960.8125 - val_loss: 219116.1094\n",
      "Epoch 148/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 216360.2656 - val_loss: 213855.2344\n",
      "Epoch 149/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 213719.1094 - val_loss: 209536.2500\n",
      "Epoch 150/800\n",
      "559/559 [==============================] - 4s 6ms/step - loss: 211099.6094 - val_loss: 217113.1406\n",
      "Epoch 151/800\n",
      "559/559 [==============================] - 4s 6ms/step - loss: 208355.5469 - val_loss: 205911.8281\n",
      "Epoch 152/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 205684.3594 - val_loss: 213977.9844\n",
      "Epoch 153/800\n",
      "559/559 [==============================] - 4s 6ms/step - loss: 203010.8125 - val_loss: 202455.1719\n",
      "Epoch 154/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 200258.4688 - val_loss: 195994.0312\n",
      "Epoch 155/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 197564.4531 - val_loss: 196570.3438\n",
      "Epoch 156/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 194788.6406 - val_loss: 187663.3906\n",
      "Epoch 157/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 192119.5938 - val_loss: 196855.4688\n",
      "Epoch 158/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 189323.2188 - val_loss: 186667.0000\n",
      "Epoch 159/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 186502.1406 - val_loss: 178049.5312\n",
      "Epoch 160/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 183741.7656 - val_loss: 185597.4531\n",
      "Epoch 161/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 181059.7500 - val_loss: 183860.7969\n",
      "Epoch 162/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 178185.0781 - val_loss: 180329.9375\n",
      "Epoch 163/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 175397.8594 - val_loss: 180253.7656\n",
      "Epoch 164/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 172637.9062 - val_loss: 172921.6250\n",
      "Epoch 165/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 169931.4062 - val_loss: 172656.3125\n",
      "Epoch 166/800\n",
      "559/559 [==============================] - 4s 7ms/step - loss: 167265.1406 - val_loss: 165349.5781\n",
      "Epoch 167/800\n",
      "504/559 [==========================>...] - ETA: 0s - loss: 164395.6875"
     ]
    }
   ],
   "source": [
    "val_split = 0.1\n",
    "min_delta=50 #10 #0 #10, #50, #10, #50,\n",
    "val_delta_patience = 25 # 10\n",
    "\n",
    "# https://keras.io/api/callbacks/early_stopping/\n",
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", #\"loss\", #\"val_loss\",\n",
    "    min_delta=min_delta, \n",
    "    patience=val_delta_patience,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True # False,\n",
    ")\n",
    "\n",
    "pipe_start = time()\n",
    "\n",
    "history = trainable_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=chosen_epochs,\n",
    "    # verbose=0 to suppress logging.\n",
    "    verbose=1,\n",
    "    # Calculate validation results on 20% of the training data.\n",
    "    validation_split=val_split,  #0.2,\n",
    "    callbacks=[callback],\n",
    "    #batch_size=32,\n",
    "    batch_size=chosen_batch_size,\n",
    ")\n",
    "pipe_end = time()\n",
    "estimated_time = round((pipe_end - pipe_start), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALGORITHM_DETAIL.replace(\"epochs=\", f\"epochs={len(hist)}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Get the results and print some graphs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "early_end_lossX = hist.iloc[-1]['loss']\n",
    "early_end_loss = hist['loss'].min()\n",
    "early_end_valloss = hist['val_loss'].min()\n",
    "\n",
    "#more_detail = f\"loss={round(early_end_loss,2)} valloss={round(early_end_valloss,2)}\"\n",
    "more_detail = f\"loss={early_end_loss:.2e} valloss={early_end_valloss:.2e}\"\n",
    "more_detail += f' +valsplit={val_split} +patn={val_delta_patience}'\n",
    "\n",
    "# f\"{x:.2e}\"\n",
    "\n",
    "if len(hist) != chosen_epochs:\n",
    "    print(f'stopped at {len(hist)}, loss={round(early_end_loss,2)} valloss={round(early_end_valloss,2)}')\n",
    "    #ALGORITHM_DETAIL += f\" +stop={len(hist)}\"\n",
    "    more_detail += f\" stop={len(hist)}/{chosen_epochs} \"\n",
    "    #more_detail += ALGORITHM_DETAIL.replace(\"epochs=\", f\"epochs={len(hist)}/\")\n",
    "\n",
    "\n",
    "if price_divisor!=1:\n",
    "    print('in preprocessing, divided all Prices by ', price_divisor)\n",
    "    more_detail += f' div={price_divisor}'\n",
    "\n",
    "\n",
    "print(more_detail)\n",
    "print(ALGORITHM_DETAIL)\n",
    "    \n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    loss_fig, loss_ax = plt.subplots()\n",
    "    loss_ax.plot(history.history['loss'], label='loss')\n",
    "    loss_ax.plot(history.history['val_loss'], label='val_loss')\n",
    "    #plt.ylim([0, 10])\n",
    "    min_y = min(min(history.history['val_loss']),min(history.history['loss'])) - 100\n",
    "    #max_y = min(max(history.history['val_loss']),max(history.history['loss'])) + 500\n",
    "    #max_y = min(sorted(history.history['val_loss'])[-3],sorted(history.history['loss'])[-3]) + 100\n",
    "    max_y = min(sorted(history.history['val_loss'])[-1],sorted(history.history['val_loss'])[-1])\n",
    "    \n",
    "    print(max_y - min_y)\n",
    "    ticks = (max_y - min_y)/10\n",
    "    print(ticks)\n",
    "    \n",
    "    plt.ylim([min_y, max_y])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [Property Price]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.yticks(np.arange(min_y, max_y, ticks))  # JHJH\n",
    "    return loss_fig, loss_ax\n",
    "\n",
    "loss_fig, loss_ax = plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    loss_fig, loss_ax = plt.subplots()\n",
    "    loss_ax.plot(history.history['loss'], label='loss')\n",
    "    loss_ax.plot(history.history['val_loss'], label='val_loss')\n",
    "    #plt.ylim([0, 10])\n",
    "    min_y = min(min(history.history['val_loss']),min(history.history['loss'])) - 100\n",
    "    #max_y = min(max(history.history['val_loss']),max(history.history['loss'])) + 500\n",
    "    #max_y = min(sorted(history.history['val_loss'])[-3],sorted(history.history['loss'])[-3]) + 100\n",
    "    max_y = min(sorted(history.history['val_loss'])[-1],sorted(history.history['val_loss'])[-1])\n",
    "    \n",
    "    print(max_y - min_y)\n",
    "    ticks = (max_y - min_y)/10\n",
    "    print(ticks)\n",
    "    \n",
    "    plt.ylim([min_y, max_y])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [Property Price]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.yticks(np.arange(min_y, max_y, ticks))  # JHJH\n",
    "    return loss_fig, loss_ax\n",
    "\n",
    "loss_fig, loss_ax = plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trainable_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.reshape((-1, 1))\n",
    "\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "RMSE = math.sqrt(MSE)\n",
    "print('-' * 10 + ALGORITHM + '-' * 10)\n",
    "print('R square Accuracy', R2)\n",
    "print('Mean Absolute Error Accuracy', MAE)\n",
    "print('Mean Squared Error Accuracy', MSE)\n",
    "print('Root Mean Squared Error', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    print(y_test_index.reshape((-1, 1)).shape);\n",
    "    print(y_pred.reshape((-1, 1)).shape);\n",
    "    print(y_test.shape);\n",
    "    print(y_test_index.shape);\n",
    "    print(y_pred.shape);\n",
    "    print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = np.hstack((y_test_index, y_test, y_pred))\n",
    "compare_df = DataFrame(compare, columns=['reference', 'actual', 'predicted'])\n",
    "compare_df['difference'] = abs(compare_df['actual'] - compare_df['predicted'])\n",
    "compare_df['diff 1 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['actual'] * 100)\n",
    "compare_df['diff 2 %'] = abs((compare_df['actual'] - compare_df['predicted']) / compare_df['predicted']) * 100\n",
    "compare_df['reference'] = compare_df['reference'].astype(int)\n",
    "compare_df.set_index('reference', inplace=True)\n",
    "\n",
    "combined = compare_df.merge(df[columns], how='inner', left_index=True, right_index=True).sort_values(['diff 1 %'],\n",
    "                                                                                                     ascending=False)\n",
    "#pd.options.display.float_format = '{:.4f}'.format\n",
    "combined[['predicted', 'actual', 'Price', 'bedrooms', 'bathrooms']] = combined[\n",
    "    ['predicted', 'actual', 'Price', 'bedrooms', 'bathrooms']].astype(int)\n",
    "combined['bedrooms'] = combined['bedrooms'].astype(int)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_fig, best_model_ax = plt.subplots()\n",
    "best_model_ax.scatter(y_test, y_pred, edgecolors=(0, 0, 1))\n",
    "best_model_ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=3)\n",
    "best_model_ax.set_ylabel('Predicted')\n",
    "best_model_ax.set_xlabel('Actual')\n",
    "#ax.title.set_text(f'CV Chosen best option ({calculated_best_pipe[1]})')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Evaluate the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_best_model_fit_time = estimated_time\n",
    "\n",
    "DD2 = \"(\" + \",\".join(DATA_DETAIL) + \")\" if len(DATA_DETAIL) >= 1 else \"\"\n",
    "key = f'{ALGORITHM} (v{VERSION})'.lower()\n",
    "\n",
    "method = f\"{ALGORITHM_DETAIL}{DD2}\"\n",
    "\n",
    "new_results = {\n",
    "    #'_score': score,\n",
    "    '_score': R2,\n",
    "    'R square Accuracy': R2,\n",
    "    'Mean Absolute Error Accuracy': MAE * price_divisor,\n",
    "    'Mean Squared Error Accuracy': MSE * price_divisor,\n",
    "    'Root Mean Squared Error': RMSE * price_divisor,\n",
    "    '_train time': cv_best_model_fit_time,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'date': str(datetime.now()),\n",
    "    #'_params': crossval_runner.best_params_ if not_catboost else cat_params,\n",
    "    #'_params': 'not available', # REPLACED - can't have different models all saying params not available\n",
    "    '_params': ALGORITHM_DETAIL,\n",
    "    '_method': more_detail, #ALGORITHM_DETAIL,\n",
    "    'run_env': run_env\n",
    "}\n",
    "\n",
    "if run_env not in ['colab']:\n",
    "    old_results_json = get_results()\n",
    "    try:\n",
    "        old_best_score = old_results_json[key]['best score']\n",
    "    except:\n",
    "        print(f\"haven't scored this model yet: {ALGORITHM}\")\n",
    "        old_best_score = -999\n",
    "    this_model_is_best = update_results(old_results_json, new_results, key)\n",
    "\n",
    "print(key)\n",
    "print(ALGORITHM_DETAIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_score = old_results_json[key]['_score']\n",
    "\n",
    "if this_model_is_best and latest_score > 0.55:\n",
    "    with open(f'../../../models/optimised_model_{ALGORITHM}_v{VERSION}{DD2}.pkl', 'wb') as f:\n",
    "        pickle.dump(trainable_model, f)\n",
    "        new_model_decision = f\"pickled new version of model\\n{latest_score} is new best score (it's better than {old_best_score})\"\n",
    "        #print(results_json[key]['_score'], 'is an improvement on', results_json[key]['second best score'])\n",
    "elif latest_score <= 0.55:\n",
    "    new_model_decision = f\"not updated saved model, the score {latest_score} doesn't exceed the threshold of 0.6 (n.b. best version is/was {old_best_score}))\"\n",
    "else:\n",
    "    new_model_decision = f\"not updated saved model, the previous run was better\\n{old_results_json[key]['_score']} is worse than or equal to {old_best_score}\"\n",
    "\n",
    "print(new_model_decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:blue;color:blue\">**********************************************************************************************************</code>\n",
    "\n",
    "## Stage: Write the final report for this algorithm and dataset version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def include_in_html_report(type, section_header=None, section_figure=None, section_content=None, section_content_list=None):\n",
    "\n",
    "    # writePath_html = r'model_results/%s (html).html' % key\n",
    "    # writePath_md = r'model_results/%s (md).md' % key\n",
    "    results_root = '../../F_evaluate_model'\n",
    "    writePath_html = f'{results_root}/html/{key}.html'.replace(\" \", \"_\").replace(\"(\", \"_\").replace(\")\", \"_\")\n",
    "    writePath_md = f'{results_root}/markdown/{key}.md'\n",
    "\n",
    "#isinstance(ini_list2, list)\n",
    "    if not section_content_list:\n",
    "        section_content_list = [section_content]\n",
    "\n",
    "    if type == 'header':\n",
    "        w = 'w' if section_figure <= 1 else 'a'\n",
    "        with open(writePath_html, w) as f1:\n",
    "            headers = f'<h{section_figure}>{section_content}</h{section_figure}>'\n",
    "            f1.write(headers)\n",
    "        with open(writePath_md, w) as f2:\n",
    "            headers = f'{\"#\" * int(section_figure)} {section_content }\\n'\n",
    "            f2.write(headers)\n",
    "    else:\n",
    "        if section_header:\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                f1.write(f'<h3>{section_header}</h3>')\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                f2.write(f'### {section_header}\\n')\n",
    "\n",
    "        if type=='dataframe':\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                dfAsString = section_content.to_html()\n",
    "                f1.write(dfAsString)\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                dfAsString = section_content.to_markdown()\n",
    "                f2.write(dfAsString + '\\n\\n')\n",
    "        elif type=='graph':\n",
    "            filename = key + \"_\" + section_content\n",
    "            #section_figure.savefig(f'model_results/artifacts/{filename.replace(\" \", \"_\")}')\n",
    "            section_figure.savefig(f'{results_root}/artifacts/{filename.replace(\" \", \"_\").replace(\"(\", \"_\").replace(\")\", \"_\")}')\n",
    "\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                dfAsString = f'<img src=\"../artifacts/{filename.replace(\" \",\"_\").replace(\"(\", \"_\").replace(\")\", \"_\")}\"/>'\n",
    "                f1.write(dfAsString)\n",
    "\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                #dfAsString = f'(./model_results/artifacts/{filename}) \\n'\n",
    "                #dfAsString = f'![detail](./artifacts/{filename.replace(\" \",\"_\")})'\n",
    "                dfAsString = f'![detail](../artifacts/{filename.replace(\" \",\"_\").replace(\"(\", \"_\").replace(\")\", \"_\")})'\n",
    "                f2.write(dfAsString)\n",
    "                f2.write('\\n\\n')\n",
    "        elif type=='json':\n",
    "\n",
    "            # html_content_parsed = [[cell.text for cell in row(\"td\")]\n",
    "            #              for row in BeautifulSoup(content,features=\"html.parser\")(\"tr\")]\n",
    "            #\n",
    "            # html_content_dictionary = {element[0]:element[1:] for element in html_content_parsed}\n",
    "\n",
    "            #xxxprint(json.dumps(html_content_dictionary, indent=4))\n",
    "\n",
    "\n",
    "\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                #f.write(json.dumps(html_content_dictionary, indent=4))\n",
    "                soup = BeautifulSoup(section_content, \"html.parser\")\n",
    "                f1.write(str(soup.prettify()))\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                #f.write(json.dumps(html_content_dictionary, indent=4))\n",
    "                soup = BeautifulSoup(section_content, \"html.parser\")\n",
    "                #f2.write(str(soup.prettify()))\n",
    "\n",
    "\n",
    "                # html_content_dictionary = {element[0]:element[1:] for element in html_content_parsed}\n",
    "                # f2.write(json.dumps(html_content_dictionary, indent=4))\n",
    "\n",
    "                import ast\n",
    "                loads = ast.literal_eval(section_content)\n",
    "                #df = pd.DataFrame.from_dict(loads)\n",
    "                #df.drop(['dont'], axis=1, inplace=True)\n",
    "                #print(df.to_markdown(index=False,tablefmt='fancy_grid'))\n",
    "                for each in loads:\n",
    "                    f2.write(each + \" = \" + str(loads[each]) + \"\\n\\n\")\n",
    "\n",
    "        elif type=='dict':\n",
    "\n",
    "            for section_content in section_content_list:\n",
    "                if isinstance(section_content, str):\n",
    "                    import ast\n",
    "                    section_content = ast.literal_eval(section_content)\n",
    "\n",
    "                with open(writePath_html, 'a') as f1:\n",
    "                    soup = BeautifulSoup(str(section_content), \"html.parser\")\n",
    "                    f1.write(str(soup.prettify()))\n",
    "                with open(writePath_md, 'a') as f2:\n",
    "                    for each in section_content:\n",
    "                        f2.write(each + \" = \" + str(section_content[each]) + \"\\n\\n\")\n",
    "\n",
    "        elif type=='text':\n",
    "            with open(writePath_html, 'a') as f1:\n",
    "                for each_line in section_content_list:\n",
    "                    f1.write(each_line + '<br>')\n",
    "            with open(writePath_md, 'a') as f2:\n",
    "                for each_line in section_content_list:\n",
    "                    f2.write(each_line + '\\n\\n')\n",
    "\n",
    "        with open(writePath_html, 'a') as f1:\n",
    "            f1.write('<hr>')\n",
    "\n",
    "\n",
    "include_in_html_report(\"header\", section_content=f\"Results from {ALGORITHM}\", section_figure=1)\n",
    "\n",
    "end_timestamp = datetime.now()\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=f\"Dataset Version: {VERSION}\", section_content_list=[\n",
    "    f\"Date run: {datetime.now()}\"\n",
    "    \"\",\n",
    "    f\"Start time: {start_timestamp}\",\n",
    "    f\"End time: {end_timestamp}\",\n",
    "])\n",
    "\n",
    "include_in_html_report(\"header\", section_content=f\"Results\", section_figure=2)\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=\"Summary\", section_content=new_model_decision)\n",
    "\n",
    "\n",
    "include_in_html_report(type='graph', section_header=\"Best Model: Comparing model predictions to actual property values\", section_figure=best_model_fig, section_content='best_ann_model.png')\n",
    "\n",
    "#include_in_html_report(type=\"dataframe\",text_single=\"Tuned Models ranked by performance\", content=cv_results_df_sorted)\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=\"Model Specific Notes\", section_content_list=[\"can't display hyperparameter comparison for neural network\",\"can't display model performance graphs for neural network\",\"can't display model performance graphs for neural network\"])\n",
    "\n",
    "include_in_html_report(type=\"dataframe\", section_header=\"Neural Network Loss - Head\", section_content=hist.head())\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=None, section_content='')\n",
    "\n",
    "include_in_html_report(type=\"dataframe\", section_header=\"Neural Network Loss - Tail\", section_content=hist.tail())\n",
    "\n",
    "\n",
    "include_in_html_report(type='graph', section_header=None, section_figure=loss_fig, section_content='end_loss.png')\n",
    "\n",
    "import io\n",
    "def get_model_summary(model):\n",
    "    stream = io.StringIO()\n",
    "    model.summary(line_length=160, print_fn=lambda x: stream.write('>' + x.replace('-','').replace('=','') + '\\n'))\n",
    "    summary_string = stream.getvalue()\n",
    "    stream.close()\n",
    "    return summary_string\n",
    "\n",
    "short_model_summary = get_model_summary(trainable_model)\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=\"Model Structure\", section_content=short_model_summary)\n",
    "\n",
    "include_in_html_report(\"header\", section_content=f\"Comparison with other models\", section_figure=2)\n",
    "\n",
    "\n",
    "dff = pd.read_json('../../../results/results.json')\n",
    "\n",
    "version = VERSION\n",
    "\n",
    "\n",
    "all_models_df = dff[dff.columns].T.sort_values(\"best score\", ascending=False)\n",
    "version_models_df = dff[[c for c in dff.columns if version in c]].T.sort_values(\"best score\", ascending=False)\n",
    "\n",
    "version_models_summary = version_models_df[['best score', 'best time', 'Mean Absolute Error Accuracy', 'Mean Squared Error Accuracy', 'R square Accuracy', 'Root Mean Squared Error', 'best run date', 'best method']]\n",
    "all_models_summary = all_models_df[['best score', 'best time', 'Mean Absolute Error Accuracy', 'Mean Squared Error Accuracy', 'R square Accuracy', 'Root Mean Squared Error', 'best run date', 'best method']]\n",
    "\n",
    "include_in_html_report(type=\"dataframe\", section_header=f\"Comparison with version {VERSION} performances\", section_content=version_models_summary)\n",
    "include_in_html_report(type=\"dataframe\", section_header=\"Comparison with all model performances\", section_content=all_models_summary)\n",
    "\n",
    "\n",
    "include_in_html_report(\"header\", section_content=f\"Appendix\", section_figure=2)\n",
    "\n",
    "include_in_html_report(type=\"dataframe\", section_header=\"Data Sample\", section_content=df.head(5))\n",
    "\n",
    "if False:\n",
    "    include_in_html_report(type=\"json\", section_header=\"Hyperparameter options for Randomized Grid Search\", section_content=f\"{param_options if not using_catboost else options_block}\")\n",
    "else:\n",
    "\n",
    "    include_in_html_report(type=\"text\", section_header=\"FIX THIS!!\", section_content=\"FIX THIS!\")\n",
    "\n",
    "include_in_html_report(type=\"dict\", section_header=\"Environment Variables\", section_content=env_vars)\n",
    "\n",
    "include_in_html_report(type=\"text\", section_header=\"Useful info\",\n",
    "                       section_content_list=[f\"Tensorflow version: {tf.__version__}\"\n",
    "                                        ])\n",
    "\n",
    "\n",
    "def print_and_report(text_single, title):\n",
    "    include_in_html_report(\"text\", section_content=title)\n",
    "    for each in text_single:\n",
    "        print(each)\n",
    "        include_in_html_report(\"text\", section_header=\"\", section_content=each)\n",
    "\n",
    "# if not catboost:\n",
    "#     print_and_report([\n",
    "#         'Best Index:' + str(crossval_runner.best_index_) + '<br>',\n",
    "#         'Best Score:' + str(crossval_runner.best_score_) + '<br>',\n",
    "#         'Best Params: ' + str(crossval_runner.best_params_) + '<br>'\n",
    "#     ], \"Best Model Details\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nearly finished...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_python_script and is_jupyter:\n",
    "    filename = FILENAME+'.ipynb'\n",
    "    get_ipython().system('jupyter nbconvert --to script $filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'ALGORITHM: {ALGORITHM}')\n",
    "print(f'ALGORITHM_DETAIL: {ALGORITHM_DETAIL}')\n",
    "print(f'DATA VERSION: {VERSION}')\n",
    "print(f'DATA_DETAIL: {DATA_DETAIL}')\n",
    "print(f'use_dimension_reduction: {use_dimension_reduction}')\n",
    "print(f'pca_data_retain: {pca_data_retain}')\n",
    "print()\n",
    "print(f'Verdict: {new_model_decision}')\n",
    "print(f'Start Timestamp: {start}')\n",
    "print(f'End Timestamp: {datetime.now()}')\n",
    "\n",
    "print(f'FILENAME: {FILENAME}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
