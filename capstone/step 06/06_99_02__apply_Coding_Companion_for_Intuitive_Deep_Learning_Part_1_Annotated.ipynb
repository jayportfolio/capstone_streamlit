{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCfp-6-jidcI"
   },
   "source": [
    "# APPLIED TO CAPSTONE\n",
    "## Coding Companion for Intuitive Deep Learning Part 1 (Annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PihXPZOFidcL"
   },
   "source": [
    "In this notebook, we'll go through the code for the coding companion for Intuitive Deep Learning Part 1 ([Part 1a](https://medium.com/intuitive-deep-learning/intuitive-deep-learning-part-1a-introduction-to-neural-networks-d7b16ebf6b99), [Part 1b](https://medium.com/intuitive-deep-learning/intuitive-deep-learning-part-1b-introduction-to-neural-networks-8565d97ddd2d)) to create your very first neural network to predict whether the house price is below or above median value. We will go through the following in this notebook:\n",
    "\n",
    "- Exploring and Processing the Data\n",
    "- Building and Training our Neural Network\n",
    "- Visualizing Loss and Accuracy\n",
    "- Adding Regularization to our Neural Network\n",
    "\n",
    "The code is annotated throughout the notebook and you simply need to download the dataset [here](https://drive.google.com/file/d/1GfvKA0qznNVknghV4botnNxyH-KvODOC/view), put the dataset in the same folder as this notebook and run the code cells below. Note that the results you get might differ slightly from the blogpost as there is a degree of randomness in the way we split our dataset as well as the initialization of our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qP4gvzRSidcQ"
   },
   "source": [
    "# Exploring and Processing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-fwzOd9idcS"
   },
   "source": [
    "We first have to read in the CSV file that we've been given. We'll use a package called pandas for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:41.273872Z",
     "iopub.status.busy": "2022-11-17T14:14:41.273548Z",
     "iopub.status.idle": "2022-11-17T14:14:41.278455Z",
     "shell.execute_reply": "2022-11-17T14:14:41.277203Z",
     "shell.execute_reply.started": "2022-11-17T14:14:41.273847Z"
    },
    "id": "fEY1NCe-idcV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:41.293279Z",
     "iopub.status.busy": "2022-11-17T14:14:41.292112Z",
     "iopub.status.idle": "2022-11-17T14:14:43.197639Z",
     "shell.execute_reply": "2022-11-17T14:14:43.196848Z",
     "shell.execute_reply.started": "2022-11-17T14:14:41.293244Z"
    },
    "id": "5IzgLseWidcX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-17 14:14:42--  https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/df_listings_v06.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5116878 (4.9M) [text/plain]\n",
      "Saving to: ‘df_listings_v06.csv.10’\n",
      "\n",
      "df_listings_v06.csv 100%[===================>]   4.88M  6.47MB/s    in 0.8s    \n",
      "\n",
      "2022-11-17 14:14:42 (6.47 MB/s) - ‘df_listings_v06.csv.10’ saved [5116878/5116878]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv('housepricedata.csv')\n",
    "\n",
    "!wget https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/df_listings_v06.csv\n",
    "df = pd.read_csv('df_listings_v06.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.199781Z",
     "iopub.status.busy": "2022-11-17T14:14:43.199193Z",
     "iopub.status.idle": "2022-11-17T14:14:43.275234Z",
     "shell.execute_reply": "2022-11-17T14:14:43.274697Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.199754Z"
    },
    "id": "sXDTin31idcZ",
    "outputId": "a065e957-d7f0-430b-9fc9-e050b13c9fd8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>nearestStation</th>\n",
       "      <th>location.latitude</th>\n",
       "      <th>location.longitude</th>\n",
       "      <th>latitude_deviation</th>\n",
       "      <th>longitude_deviation</th>\n",
       "      <th>tenure.tenureType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14520525</th>\n",
       "      <td>550000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.274316</td>\n",
       "      <td>51.529950</td>\n",
       "      <td>-0.207020</td>\n",
       "      <td>0.030230</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27953107</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.305845</td>\n",
       "      <td>51.549390</td>\n",
       "      <td>-0.482600</td>\n",
       "      <td>0.049670</td>\n",
       "      <td>0.378180</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33593487</th>\n",
       "      <td>579950.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.438045</td>\n",
       "      <td>51.447180</td>\n",
       "      <td>-0.338770</td>\n",
       "      <td>0.052540</td>\n",
       "      <td>0.234350</td>\n",
       "      <td>FREEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35271294</th>\n",
       "      <td>370000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.399307</td>\n",
       "      <td>51.449568</td>\n",
       "      <td>-0.140154</td>\n",
       "      <td>0.050152</td>\n",
       "      <td>0.035734</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44749111</th>\n",
       "      <td>475000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.410550</td>\n",
       "      <td>51.370050</td>\n",
       "      <td>-0.212410</td>\n",
       "      <td>0.129670</td>\n",
       "      <td>0.107990</td>\n",
       "      <td>FREEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46204665</th>\n",
       "      <td>435000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.314779</td>\n",
       "      <td>51.539070</td>\n",
       "      <td>-0.198935</td>\n",
       "      <td>0.039350</td>\n",
       "      <td>0.094515</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49020666</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875911</td>\n",
       "      <td>51.539959</td>\n",
       "      <td>-0.380863</td>\n",
       "      <td>0.040239</td>\n",
       "      <td>0.276443</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49036279</th>\n",
       "      <td>275000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.474368</td>\n",
       "      <td>51.541780</td>\n",
       "      <td>0.037890</td>\n",
       "      <td>0.042060</td>\n",
       "      <td>0.142310</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49303873</th>\n",
       "      <td>450000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.577040</td>\n",
       "      <td>51.524880</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.025160</td>\n",
       "      <td>0.291620</td>\n",
       "      <td>FREEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52064391</th>\n",
       "      <td>349950.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.212734</td>\n",
       "      <td>51.470800</td>\n",
       "      <td>-0.361820</td>\n",
       "      <td>0.028920</td>\n",
       "      <td>0.257400</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52187854</th>\n",
       "      <td>450000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.446802</td>\n",
       "      <td>51.527199</td>\n",
       "      <td>-0.202898</td>\n",
       "      <td>0.027479</td>\n",
       "      <td>0.098478</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52845963</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.650562</td>\n",
       "      <td>51.398040</td>\n",
       "      <td>-0.076812</td>\n",
       "      <td>0.101680</td>\n",
       "      <td>0.027608</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52913496</th>\n",
       "      <td>220000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945991</td>\n",
       "      <td>51.539383</td>\n",
       "      <td>-0.382239</td>\n",
       "      <td>0.039663</td>\n",
       "      <td>0.277819</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53609433</th>\n",
       "      <td>489995.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087081</td>\n",
       "      <td>51.532620</td>\n",
       "      <td>-0.107860</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938989</th>\n",
       "      <td>450000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775203</td>\n",
       "      <td>51.658287</td>\n",
       "      <td>-0.207902</td>\n",
       "      <td>0.158567</td>\n",
       "      <td>0.103482</td>\n",
       "      <td>FREEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54713232</th>\n",
       "      <td>332000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.319226</td>\n",
       "      <td>51.612300</td>\n",
       "      <td>-0.119860</td>\n",
       "      <td>0.112580</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>SHARE_OF_FREEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54904122</th>\n",
       "      <td>365000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.260722</td>\n",
       "      <td>51.593595</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.093875</td>\n",
       "      <td>0.126466</td>\n",
       "      <td>SHARE_OF_FREEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54991934</th>\n",
       "      <td>430000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.497268</td>\n",
       "      <td>51.528720</td>\n",
       "      <td>0.039180</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.143600</td>\n",
       "      <td>FREEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55043230</th>\n",
       "      <td>260000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.384607</td>\n",
       "      <td>51.544430</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.044710</td>\n",
       "      <td>0.118920</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55187658</th>\n",
       "      <td>430000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.289033</td>\n",
       "      <td>51.507570</td>\n",
       "      <td>0.078030</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>0.182450</td>\n",
       "      <td>LEASEHOLD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price  bedrooms  bathrooms  nearestStation  location.latitude  \\\n",
       "14520525  550000.0       3.0        1.0        0.274316          51.529950   \n",
       "27953107  400000.0       2.0        2.0        0.305845          51.549390   \n",
       "33593487  579950.0       2.0        1.0        0.438045          51.447180   \n",
       "35271294  370000.0       2.0        1.0        0.399307          51.449568   \n",
       "44749111  475000.0       2.0        1.0        0.410550          51.370050   \n",
       "46204665  435000.0       3.0        2.0        0.314779          51.539070   \n",
       "49020666  200000.0       1.0        1.0        0.875911          51.539959   \n",
       "49036279  275000.0       2.0        1.0        0.474368          51.541780   \n",
       "49303873  450000.0       3.0        2.0        0.577040          51.524880   \n",
       "52064391  349950.0       2.0        2.0        0.212734          51.470800   \n",
       "52187854  450000.0       1.0        1.0        0.446802          51.527199   \n",
       "52845963  200000.0       2.0        1.0        0.650562          51.398040   \n",
       "52913496  220000.0       1.0        1.0        0.945991          51.539383   \n",
       "53609433  489995.0       1.0        1.0        0.087081          51.532620   \n",
       "53938989  450000.0       2.0        1.0        0.775203          51.658287   \n",
       "54713232  332000.0       2.0        1.0        0.319226          51.612300   \n",
       "54904122  365000.0       2.0        1.0        0.260722          51.593595   \n",
       "54991934  430000.0       3.0        1.0        0.497268          51.528720   \n",
       "55043230  260000.0       1.0        1.0        0.384607          51.544430   \n",
       "55187658  430000.0       2.0        2.0        0.289033          51.507570   \n",
       "\n",
       "          location.longitude  latitude_deviation  longitude_deviation  \\\n",
       "14520525           -0.207020            0.030230             0.102600   \n",
       "27953107           -0.482600            0.049670             0.378180   \n",
       "33593487           -0.338770            0.052540             0.234350   \n",
       "35271294           -0.140154            0.050152             0.035734   \n",
       "44749111           -0.212410            0.129670             0.107990   \n",
       "46204665           -0.198935            0.039350             0.094515   \n",
       "49020666           -0.380863            0.040239             0.276443   \n",
       "49036279            0.037890            0.042060             0.142310   \n",
       "49303873            0.187200            0.025160             0.291620   \n",
       "52064391           -0.361820            0.028920             0.257400   \n",
       "52187854           -0.202898            0.027479             0.098478   \n",
       "52845963           -0.076812            0.101680             0.027608   \n",
       "52913496           -0.382239            0.039663             0.277819   \n",
       "53609433           -0.107860            0.032900             0.003440   \n",
       "53938989           -0.207902            0.158567             0.103482   \n",
       "54713232           -0.119860            0.112580             0.015440   \n",
       "54904122            0.022046            0.093875             0.126466   \n",
       "54991934            0.039180            0.029000             0.143600   \n",
       "55043230            0.014500            0.044710             0.118920   \n",
       "55187658            0.078030            0.007850             0.182450   \n",
       "\n",
       "          tenure.tenureType  \n",
       "14520525          LEASEHOLD  \n",
       "27953107          LEASEHOLD  \n",
       "33593487           FREEHOLD  \n",
       "35271294          LEASEHOLD  \n",
       "44749111           FREEHOLD  \n",
       "46204665          LEASEHOLD  \n",
       "49020666          LEASEHOLD  \n",
       "49036279          LEASEHOLD  \n",
       "49303873           FREEHOLD  \n",
       "52064391          LEASEHOLD  \n",
       "52187854          LEASEHOLD  \n",
       "52845963          LEASEHOLD  \n",
       "52913496          LEASEHOLD  \n",
       "53609433          LEASEHOLD  \n",
       "53938989           FREEHOLD  \n",
       "54713232  SHARE_OF_FREEHOLD  \n",
       "54904122  SHARE_OF_FREEHOLD  \n",
       "54991934           FREEHOLD  \n",
       "55043230          LEASEHOLD  \n",
       "55187658          LEASEHOLD  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RAzi3Y3idca"
   },
   "source": [
    "The dataset that we have now is in what we call a pandas dataframe. To convert it to an array, simply access its values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.276849Z",
     "iopub.status.busy": "2022-11-17T14:14:43.276129Z",
     "iopub.status.idle": "2022-11-17T14:14:43.296531Z",
     "shell.execute_reply": "2022-11-17T14:14:43.295870Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.276826Z"
    },
    "id": "P9VXZChxidcd"
   },
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.298998Z",
     "iopub.status.busy": "2022-11-17T14:14:43.298442Z",
     "iopub.status.idle": "2022-11-17T14:14:43.369042Z",
     "shell.execute_reply": "2022-11-17T14:14:43.368259Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.298967Z"
    },
    "id": "4KYK-ml0idcf",
    "outputId": "0093af7a-4ac5-40bc-9bfc-b754cdec91c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[550000.0, 3.0, 1.0, ..., 0.0302299999999959, 0.1026, 'LEASEHOLD'],\n",
       "       [400000.0, 2.0, 2.0, ..., 0.0496699999999989, 0.3781799999999999,\n",
       "        'LEASEHOLD'],\n",
       "       [579950.0, 2.0, 1.0, ..., 0.0525400000000004, 0.23435, 'FREEHOLD'],\n",
       "       ...,\n",
       "       [419999.0, 2.0, 1.0, ..., 0.0316949999999991, 0.051456,\n",
       "        'LEASEHOLD'],\n",
       "       [475000.0, 2.0, 1.0, ..., 0.043420999999995, 0.115918,\n",
       "        'LEASEHOLD'],\n",
       "       [525000.0, 2.0, 1.0, ..., 0.075131000000006, 0.10237,\n",
       "        'SHARE_OF_FREEHOLD']], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36TiV1Fxidch"
   },
   "source": [
    "Now, we split the dataset into our input features and the label we wish to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.371198Z",
     "iopub.status.busy": "2022-11-17T14:14:43.370344Z",
     "iopub.status.idle": "2022-11-17T14:14:43.383901Z",
     "shell.execute_reply": "2022-11-17T14:14:43.383461Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.371165Z"
    },
    "id": "-r65WmYJidci"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.00000000e+00,  1.00000000e+00,  2.74315588e-01,  5.15299500e+01,\n",
       "        -2.07020000e-01,  3.02300000e-02,  1.02600000e-01]),\n",
       " 550000.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset[:,1:-1]\n",
    "Y = dataset[:,0]\n",
    "\n",
    "X = np.asarray(X).astype('float64')\n",
    "Y = np.asarray(Y).astype('float64')\n",
    "X[0], Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzT2lA6Widcl"
   },
   "source": [
    "Normalizing our data is very important, as we want the input features to be on the same order of magnitude to make our training easier. We'll use a min-max scaler from scikit-learn which scales our data to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.385316Z",
     "iopub.status.busy": "2022-11-17T14:14:43.384704Z",
     "iopub.status.idle": "2022-11-17T14:14:43.388164Z",
     "shell.execute_reply": "2022-11-17T14:14:43.387538Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.385294Z"
    },
    "id": "_tFR9dIKidcn"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.389762Z",
     "iopub.status.busy": "2022-11-17T14:14:43.389028Z",
     "iopub.status.idle": "2022-11-17T14:14:43.468119Z",
     "shell.execute_reply": "2022-11-17T14:14:43.467450Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.389742Z"
    },
    "id": "ltLLHdyJidco",
    "outputId": "1aaff773-0995-4cb2-b5de-aaa97ff8920b"
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "X_scale = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.469773Z",
     "iopub.status.busy": "2022-11-17T14:14:43.469254Z",
     "iopub.status.idle": "2022-11-17T14:14:43.475244Z",
     "shell.execute_reply": "2022-11-17T14:14:43.474758Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.469747Z"
    },
    "id": "8QbvszFkidcq",
    "outputId": "784a458a-98f8-4461-de9f-30dc73de344a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.        ,  1.        ,  0.27431559, ..., -0.20702   ,\n",
       "         0.03023   ,  0.1026    ],\n",
       "       [ 2.        ,  2.        ,  0.30584538, ..., -0.4826    ,\n",
       "         0.04967   ,  0.37818   ],\n",
       "       [ 2.        ,  1.        ,  0.43804471, ..., -0.33877   ,\n",
       "         0.05254   ,  0.23435   ],\n",
       "       ...,\n",
       "       [ 2.        ,  1.        ,  0.19140733, ..., -0.052964  ,\n",
       "         0.031695  ,  0.051456  ],\n",
       "       [ 2.        ,  1.        ,  0.30860852, ...,  0.011498  ,\n",
       "         0.043421  ,  0.115918  ],\n",
       "       [ 2.        ,  1.        ,  0.23848904, ..., -0.20679   ,\n",
       "         0.075131  ,  0.10237   ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqQg2r2zidcr"
   },
   "source": [
    "Lastly, we wish to set aside some parts of our dataset for a validation set and a test set. We use the function train_test_split from scikit-learn to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.476660Z",
     "iopub.status.busy": "2022-11-17T14:14:43.476161Z",
     "iopub.status.idle": "2022-11-17T14:14:43.480062Z",
     "shell.execute_reply": "2022-11-17T14:14:43.479340Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.476636Z"
    },
    "id": "3s0Rqyfyidcs"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.483387Z",
     "iopub.status.busy": "2022-11-17T14:14:43.482724Z",
     "iopub.status.idle": "2022-11-17T14:14:43.492885Z",
     "shell.execute_reply": "2022-11-17T14:14:43.492298Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.483361Z"
    },
    "id": "gffqVQpEidct"
   },
   "outputs": [],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.494635Z",
     "iopub.status.busy": "2022-11-17T14:14:43.493835Z",
     "iopub.status.idle": "2022-11-17T14:14:43.573707Z",
     "shell.execute_reply": "2022-11-17T14:14:43.573058Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.494609Z"
    },
    "id": "eci16ufXidct"
   },
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.575818Z",
     "iopub.status.busy": "2022-11-17T14:14:43.574852Z",
     "iopub.status.idle": "2022-11-17T14:14:43.580004Z",
     "shell.execute_reply": "2022-11-17T14:14:43.579318Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.575790Z"
    },
    "id": "zCnBs5U-idcu",
    "outputId": "b6d636ed-c76c-4103-a13f-eb015e0a510c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30888, 7) (6619, 7) (6620, 7) (30888,) (6619,) (6620,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIZoTnRcidcv"
   },
   "source": [
    "# Building and Training Our First Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpIMKB_1idcw"
   },
   "source": [
    "We will be using Keras to build our architecture. Let's import the code from Keras that we will need to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.581735Z",
     "iopub.status.busy": "2022-11-17T14:14:43.580895Z",
     "iopub.status.idle": "2022-11-17T14:14:43.584739Z",
     "shell.execute_reply": "2022-11-17T14:14:43.584108Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.581712Z"
    },
    "id": "3GlXapNxidcw",
    "outputId": "6d7faec1-08d5-4f4a-bad8-f9a0cdf58a31"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTdZCqn7idcx"
   },
   "source": [
    "We will be using the Sequential model, which means that we merely need to describe the layers above in sequence. Our neural network has three layers:\n",
    "\n",
    "- Hidden layer 1: 30 neurons, ReLU activation\n",
    "- Hidden layer 2: 30 neurons, ReLU activation\n",
    "- Output Layer: 1 neuron, Sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.586402Z",
     "iopub.status.busy": "2022-11-17T14:14:43.585809Z",
     "iopub.status.idle": "2022-11-17T14:14:43.808108Z",
     "shell.execute_reply": "2022-11-17T14:14:43.807457Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.586380Z"
    },
    "id": "dKixB7Hcidcy"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(len(X[0]),)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='relu'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxTRAVaMidcy"
   },
   "source": [
    "Now that we've got our architecture specified, we need to find the best numbers for it. Before we start our training, we have to configure the model by\n",
    "- Telling it what algorithm you want to use to do the optimization (we'll use stochastic gradient descent)\n",
    "- Telling it what loss function to use (for binary classification, we will use binary cross entropy)\n",
    "- Telling it what other metrics you want to track apart from the loss function (we want to track accuracy as well)\n",
    "\n",
    "We do so below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.809798Z",
     "iopub.status.busy": "2022-11-17T14:14:43.809116Z",
     "iopub.status.idle": "2022-11-17T14:14:43.870502Z",
     "shell.execute_reply": "2022-11-17T14:14:43.869856Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.809772Z"
    },
    "id": "iT7c3xADidcz"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              #loss='binary_crossentropy',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EE2gT9ehidc0"
   },
   "source": [
    "Training on the data is pretty straightforward and requires us to write one line of code. The function is called 'fit' as we are fitting the parameters to the data. We specify:\n",
    "- what data we are training on, which is X_train and Y_train\n",
    "- the size of our mini-batch \n",
    "- how long we want to train it for (epochs)\n",
    "- what our validation data is so that the model will tell us how we are doing on the validation data at each point.\n",
    "\n",
    "This function will output a history, which we save under the variable hist. We'll use this variable a little later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.871953Z",
     "iopub.status.busy": "2022-11-17T14:14:43.871564Z",
     "iopub.status.idle": "2022-11-17T14:14:43.877532Z",
     "shell.execute_reply": "2022-11-17T14:14:43.877032Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.871931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00,  1.00000000e+00,  2.84179908e-01,  5.14890300e+01,\n",
       "       -2.70149000e-01,  1.06900000e-02,  1.65729000e-01])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), type(Y_train)\n",
    "Y_train.shape\n",
    "X_train[0]\n",
    "X_val\n",
    "Y_val\n",
    "X_train[1,:]\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.879094Z",
     "iopub.status.busy": "2022-11-17T14:14:43.878396Z",
     "iopub.status.idle": "2022-11-17T14:14:43.885354Z",
     "shell.execute_reply": "2022-11-17T14:14:43.884943Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.879071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([575000., 350000., 600000., ..., 525000., 300000., 450000.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train = np.asarray(X_train).astype('float32')\n",
    "Y_train = np.asarray(Y_train).astype('float32')\n",
    "X_val = np.asarray(X_val).astype('float32')\n",
    "Y_val = np.asarray(Y_val).astype('float32')\n",
    "X_val\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:14:43.886700Z",
     "iopub.status.busy": "2022-11-17T14:14:43.886100Z",
     "iopub.status.idle": "2022-11-17T14:15:17.410976Z",
     "shell.execute_reply": "2022-11-17T14:15:17.410099Z",
     "shell.execute_reply.started": "2022-11-17T14:14:43.886679Z"
    },
    "id": "yTFyeBapidc1",
    "outputId": "de8598b6-b7c5-4554-96ba-aafa36f8b4dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 1s 19ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train,\n",
    "          #batch_size=32, epochs=100,\n",
    "          batch_size=1024, epochs=100,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QH9XahXpidc3"
   },
   "source": [
    "Evaluating our data on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:15:17.412857Z",
     "iopub.status.busy": "2022-11-17T14:15:17.412544Z",
     "iopub.status.idle": "2022-11-17T14:15:17.472488Z",
     "shell.execute_reply": "2022-11-17T14:15:17.471971Z",
     "shell.execute_reply.started": "2022-11-17T14:15:17.412817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 7) <dtype: 'float32'>\n",
      "(None, 1) <dtype: 'float32'>\n",
      "dense_9 (None, 7) float32\n",
      "dense_10 (None, 32) float32\n",
      "dense_11 (None, 32) float32\n",
      "dense_12 (None, 32) float32\n",
      "dense_13 (None, 32) float32\n",
      "dense_14 (None, 32) float32\n",
      "dense_15 (None, 32) float32\n",
      "dense_16 (None, 32) float32\n",
      "dense_17 (None, 32) float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i.shape, i.dtype) for i in model.inputs]\n",
    "[print(o.shape, o.dtype) for o in model.outputs]\n",
    "[print(l.name, l.input_shape, l.dtype) for l in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:15:17.474379Z",
     "iopub.status.busy": "2022-11-17T14:15:17.473472Z",
     "iopub.status.idle": "2022-11-17T14:15:18.082241Z",
     "shell.execute_reply": "2022-11-17T14:15:18.081561Z",
     "shell.execute_reply.started": "2022-11-17T14:15:17.474353Z"
    },
    "id": "h41imUJ2idc4",
    "outputId": "0cc89477-6a14-4b67-9301-2bb0895a8a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207/207 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2KAQ3Ygidc5"
   },
   "source": [
    "# Visualizing Loss and Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiW0QUVFidc6"
   },
   "source": [
    "Import the relevant package we need to do the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:15:18.083559Z",
     "iopub.status.busy": "2022-11-17T14:15:18.083303Z",
     "iopub.status.idle": "2022-11-17T14:15:18.975342Z",
     "shell.execute_reply": "2022-11-17T14:15:18.974715Z",
     "shell.execute_reply.started": "2022-11-17T14:15:18.083530Z"
    },
    "id": "EMtDHCX7idc6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nifpLZ3Nidc7"
   },
   "source": [
    "We want to visualize the training loss and the validation loss like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:15:18.979923Z",
     "iopub.status.busy": "2022-11-17T14:15:18.979232Z",
     "iopub.status.idle": "2022-11-17T14:15:19.219898Z",
     "shell.execute_reply": "2022-11-17T14:15:19.219155Z",
     "shell.execute_reply.started": "2022-11-17T14:15:18.979895Z"
    },
    "id": "E8bmASTNidc8",
    "outputId": "cb989fa6-e4d0-42f6-9581-dad683ebe263"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4jlTmF2idc8"
   },
   "source": [
    "We can also visualize the training accuracy and the validation accuracy like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:15:19.221335Z",
     "iopub.status.busy": "2022-11-17T14:15:19.221050Z",
     "iopub.status.idle": "2022-11-17T14:15:19.481293Z",
     "shell.execute_reply": "2022-11-17T14:15:19.480589Z",
     "shell.execute_reply.started": "2022-11-17T14:15:19.221312Z"
    },
    "id": "Lt9DeQ3bidc-",
    "outputId": "b3752779-8fcf-4fb0-ce57-b7ac26e52765"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UZhFKpyidc-"
   },
   "source": [
    "# Adding Regularization to our Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78PWSp11idc_"
   },
   "source": [
    "We'll train a model which will overfit, which we call Model 2. This might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-17T14:15:19.483000Z",
     "iopub.status.busy": "2022-11-17T14:15:19.482751Z",
     "iopub.status.idle": "2022-11-17T14:25:33.268987Z",
     "shell.execute_reply": "2022-11-17T14:25:33.224803Z",
     "shell.execute_reply.started": "2022-11-17T14:15:19.482978Z"
    },
    "id": "g9YFIMo6iddA",
    "outputId": "9dd6c47c-eda4-4b9e-e3e2-0b9e350fa802"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 19s 603ms/step - loss: 191984631808.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 19s 609ms/step - loss: 191984599040.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 19s 597ms/step - loss: 191984599040.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 19s 603ms/step - loss: 191984631808.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 19s 610ms/step - loss: 191984648192.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 19s 601ms/step - loss: 191984599040.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 18s 597ms/step - loss: 191984631808.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 19s 607ms/step - loss: 191984631808.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 19s 605ms/step - loss: 191984599040.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 19s 626ms/step - loss: 191984599040.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 19s 600ms/step - loss: 191984631808.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 18s 593ms/step - loss: 191984631808.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 19s 610ms/step - loss: 191984631808.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 19s 600ms/step - loss: 191984631808.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 19s 620ms/step - loss: 191984631808.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 19s 603ms/step - loss: 191984648192.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 19s 603ms/step - loss: 191984599040.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 19s 612ms/step - loss: 191984566272.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 19s 603ms/step - loss: 191984599040.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 19s 611ms/step - loss: 191984648192.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 20s 629ms/step - loss: 191984599040.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 19s 628ms/step - loss: 191984599040.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 19s 599ms/step - loss: 191984631808.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 19s 610ms/step - loss: 191984631808.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 19s 600ms/step - loss: 191984599040.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 19s 616ms/step - loss: 191984599040.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 19s 621ms/step - loss: 191984648192.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 21s 669ms/step - loss: 191984599040.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 27s 867ms/step - loss: 191984648192.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 32s 1s/step - loss: 191984631808.0000 - accuracy: 0.0000e+00 - val_loss: 190907777024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "28/31 [==========================>...] - ETA: 2s - loss: 192091209728.0000 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_2 \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m      2\u001b[0m     Dense(\u001b[38;5;241m1000\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X[\u001b[38;5;241m0\u001b[39m]),)),\n\u001b[1;32m      3\u001b[0m     Dense(\u001b[38;5;241m1000\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      8\u001b[0m ])\n\u001b[1;32m      9\u001b[0m model_2\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m               \u001b[38;5;66;03m#loss='binary_crossentropy',\u001b[39;00m\n\u001b[1;32m     11\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m hist_2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;66;43;03m#batch_size=32, epochs=100,\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_2 = Sequential([\n",
    "    Dense(1000, activation='relu', input_shape=(len(X[0]),)),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dense(1000, activation='relu'),\n",
    "    #Dense(1, activation='sigmoid'),\n",
    "    Dense(1, activation='relu'),\n",
    "])\n",
    "model_2.compile(optimizer='adam',\n",
    "              #loss='binary_crossentropy',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "hist_2 = model_2.fit(X_train, Y_train,\n",
    "          #batch_size=32, epochs=100,\n",
    "          batch_size=1024, epochs=100,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2lDoeYFiddA"
   },
   "source": [
    "Let's do the same visualization to see what overfitting looks like in terms of the loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-17T14:25:33.271078Z",
     "iopub.status.idle": "2022-11-17T14:25:33.274743Z",
     "shell.execute_reply": "2022-11-17T14:25:33.274441Z",
     "shell.execute_reply.started": "2022-11-17T14:25:33.274413Z"
    },
    "id": "xPMsyvkCiddB",
    "outputId": "e47fba29-2344-4dd4-b92d-7da5efb0b290"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist_2.history['loss'])\n",
    "plt.plot(hist_2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-17T14:25:33.275861Z",
     "iopub.status.idle": "2022-11-17T14:25:33.276490Z",
     "shell.execute_reply": "2022-11-17T14:25:33.276348Z",
     "shell.execute_reply.started": "2022-11-17T14:25:33.276328Z"
    },
    "id": "mbdBTso6iddC",
    "outputId": "8b946d76-a26c-4955-cb31-c19f66f33cd5"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist_2.history['accuracy'])\n",
    "plt.plot(hist_2.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsIQiZ6_iddD"
   },
   "source": [
    "To address the overfitting we see in Model 2, we'll incorporate L2 regularization and dropout in our third model here (Model 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-17T14:25:33.277640Z",
     "iopub.status.idle": "2022-11-17T14:25:33.282939Z",
     "shell.execute_reply": "2022-11-17T14:25:33.282549Z",
     "shell.execute_reply.started": "2022-11-17T14:25:33.282505Z"
    },
    "id": "qVXT8i08iddD"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-17T14:25:33.284203Z",
     "iopub.status.idle": "2022-11-17T14:25:33.284833Z",
     "shell.execute_reply": "2022-11-17T14:25:33.284699Z",
     "shell.execute_reply.started": "2022-11-17T14:25:33.284682Z"
    },
    "id": "VhAMRf29iddE"
   },
   "outputs": [],
   "source": [
    "model_3 = Sequential([\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(len(X[0]),)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-17T14:25:33.311134Z",
     "iopub.status.idle": "2022-11-17T14:25:33.311523Z",
     "shell.execute_reply": "2022-11-17T14:25:33.311364Z",
     "shell.execute_reply.started": "2022-11-17T14:25:33.311348Z"
    },
    "id": "eFLsCsRCiddF",
    "outputId": "a020d22d-e7cf-4851-b910-ed0cc5dc939f"
   },
   "outputs": [],
   "source": [
    "model_3.compile(optimizer='adam',\n",
    "              #loss='binary_crossentropy',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "hist_3 = model_3.fit(X_train, Y_train,\n",
    "          #batch_size=32, epochs=100,\n",
    "          batch_size=1024, epochs=100,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLkDNUOziddG"
   },
   "source": [
    "We'll now plot the loss and accuracy graphs for Model 3. You'll notice that the loss is a lot higher at the start, and that's because we've changed our loss function. To plot such that the window is zoomed in between 0 and 1.2 for the loss, we add an additional line of code (plt.ylim) when plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-17T14:25:33.312328Z",
     "iopub.status.idle": "2022-11-17T14:25:33.312601Z",
     "shell.execute_reply": "2022-11-17T14:25:33.312490Z",
     "shell.execute_reply.started": "2022-11-17T14:25:33.312477Z"
    },
    "id": "aL8hS6gyiddI",
    "outputId": "62a317ec-eed5-4bb1-9bb6-34ac19693baa"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist_3.history['loss'])\n",
    "plt.plot(hist_3.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.ylim(top=1.2, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-17T14:25:33.313126Z",
     "iopub.status.idle": "2022-11-17T14:25:33.313370Z",
     "shell.execute_reply": "2022-11-17T14:25:33.313260Z",
     "shell.execute_reply.started": "2022-11-17T14:25:33.313248Z"
    },
    "id": "Mf6lmwDeiddI",
    "outputId": "87175be4-19d5-485c-aac0-e4cbbd76de74"
   },
   "outputs": [],
   "source": [
    "plt.plot(hist_3.history['accuracy'])\n",
    "plt.plot(hist_3.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDDrX3cDiddJ"
   },
   "source": [
    "As compared to Model 2, you should see that there's less overfitting!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
